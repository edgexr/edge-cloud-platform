// Code generated by protoc-gen-gogo. DO NOT EDIT.
// source: resources.proto

package edgeproto

import (
	fmt "fmt"
	"github.com/edgexr/edge-cloud-platform/pkg/objstore"
	_ "github.com/edgexr/edge-cloud-platform/tools/protogen"
	_ "github.com/gogo/protobuf/gogoproto"
	proto "github.com/gogo/protobuf/proto"
	io "io"
	math "math"
	math_bits "math/bits"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.GoGoProtoPackageIsVersion3 // please upgrade the proto package

// GPU Resource
type GPUResource struct {
	// GPU model unique identifier
	ModelId string `protobuf:"bytes,1,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`
	// Count of how many of this GPU are required/present
	Count uint32 `protobuf:"varint,2,opt,name=count,proto3" json:"count,omitempty"`
	// GPU vendor (nvidia, amd, etc)
	Vendor string `protobuf:"bytes,3,opt,name=vendor,proto3" json:"vendor,omitempty"`
	// Memory in GB
	Memory uint64 `protobuf:"varint,4,opt,name=memory,proto3" json:"memory,omitempty"`
	// Read-only indication of how many GPUs are in use by tenants for usage APIs
	InUse uint32 `protobuf:"varint,5,opt,name=in_use,json=inUse,proto3" json:"in_use,omitempty"`
}

func (m *GPUResource) Reset()         { *m = GPUResource{} }
func (m *GPUResource) String() string { return proto.CompactTextString(m) }
func (*GPUResource) ProtoMessage()    {}
func (*GPUResource) Descriptor() ([]byte, []int) {
	return fileDescriptor_cf1b13971fe4c19d, []int{0}
}
func (m *GPUResource) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *GPUResource) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_GPUResource.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *GPUResource) XXX_Merge(src proto.Message) {
	xxx_messageInfo_GPUResource.Merge(m, src)
}
func (m *GPUResource) XXX_Size() int {
	return m.Size()
}
func (m *GPUResource) XXX_DiscardUnknown() {
	xxx_messageInfo_GPUResource.DiscardUnknown(m)
}

var xxx_messageInfo_GPUResource proto.InternalMessageInfo

// NodeResources defines the node resources for machines or VMs
type NodeResources struct {
	// Vcpus to be allocated to the VM, must be either 1 or an even number
	Vcpus uint64 `protobuf:"varint,1,opt,name=vcpus,proto3" json:"vcpus,omitempty"`
	// Total RAM in megabytes to be allocated to the VM
	Ram uint64 `protobuf:"varint,2,opt,name=ram,proto3" json:"ram,omitempty"`
	// Total disk space in gigabytes to be allocated to the VM's root partition
	Disk uint64 `protobuf:"varint,3,opt,name=disk,proto3" json:"disk,omitempty"`
	// GPUs
	Gpus []*GPUResource `protobuf:"bytes,7,rep,name=gpus,proto3" json:"gpus,omitempty"`
	// Optional resources request, i.e. optresmap=restype=resname:1
	OptResMap map[string]string `protobuf:"bytes,4,rep,name=opt_res_map,json=optResMap,proto3" json:"opt_res_map,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	// Infrastructure specific node flavor
	InfraNodeFlavor string `protobuf:"bytes,5,opt,name=infra_node_flavor,json=infraNodeFlavor,proto3" json:"infra_node_flavor,omitempty"`
	// Size of external volume to be attached to nodes. This is for the root partition
	ExternalVolumeSize uint64 `protobuf:"varint,6,opt,name=external_volume_size,json=externalVolumeSize,proto3" json:"external_volume_size,omitempty"`
	// node name if using nodes as a resource
	NodeName string `protobuf:"bytes,8,opt,name=node_name,json=nodeName,proto3" json:"node_name,omitempty"`
}

func (m *NodeResources) Reset()         { *m = NodeResources{} }
func (m *NodeResources) String() string { return proto.CompactTextString(m) }
func (*NodeResources) ProtoMessage()    {}
func (*NodeResources) Descriptor() ([]byte, []int) {
	return fileDescriptor_cf1b13971fe4c19d, []int{1}
}
func (m *NodeResources) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *NodeResources) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_NodeResources.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *NodeResources) XXX_Merge(src proto.Message) {
	xxx_messageInfo_NodeResources.Merge(m, src)
}
func (m *NodeResources) XXX_Size() int {
	return m.Size()
}
func (m *NodeResources) XXX_DiscardUnknown() {
	xxx_messageInfo_NodeResources.DiscardUnknown(m)
}

var xxx_messageInfo_NodeResources proto.InternalMessageInfo

// KubernetesResources defines resource requirements for Kubernetes Applications
type KubernetesResources struct {
	// CPU Node Pool resources
	CpuPool *NodePoolResources `protobuf:"bytes,1,opt,name=cpu_pool,json=cpuPool,proto3" json:"cpu_pool,omitempty"`
	// GPU Node Pool resources
	GpuPool *NodePoolResources `protobuf:"bytes,2,opt,name=gpu_pool,json=gpuPool,proto3" json:"gpu_pool,omitempty"`
	// Minimum Kubernetes version
	MinKubernetesVersion string `protobuf:"bytes,4,opt,name=min_kubernetes_version,json=minKubernetesVersion,proto3" json:"min_kubernetes_version,omitempty"`
}

func (m *KubernetesResources) Reset()         { *m = KubernetesResources{} }
func (m *KubernetesResources) String() string { return proto.CompactTextString(m) }
func (*KubernetesResources) ProtoMessage()    {}
func (*KubernetesResources) Descriptor() ([]byte, []int) {
	return fileDescriptor_cf1b13971fe4c19d, []int{2}
}
func (m *KubernetesResources) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *KubernetesResources) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_KubernetesResources.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *KubernetesResources) XXX_Merge(src proto.Message) {
	xxx_messageInfo_KubernetesResources.Merge(m, src)
}
func (m *KubernetesResources) XXX_Size() int {
	return m.Size()
}
func (m *KubernetesResources) XXX_DiscardUnknown() {
	xxx_messageInfo_KubernetesResources.DiscardUnknown(m)
}

var xxx_messageInfo_KubernetesResources proto.InternalMessageInfo

// NodePoolResources defines the total resource and topology requirements for a Kubernetes node pool.
type NodePoolResources struct {
	// Total Vcpus to be allocated in the pool, in increments of 0.001
	TotalVcpus Udec64 `protobuf:"bytes,1,opt,name=total_vcpus,json=totalVcpus,proto3" json:"total_vcpus"`
	// Total RAM in megabytes to be allocated in the pool
	TotalMemory uint64 `protobuf:"varint,2,opt,name=total_memory,json=totalMemory,proto3" json:"total_memory,omitempty"`
	// Total Disk in gigabytes to be allocated in the pool
	TotalDisk uint64 `protobuf:"varint,3,opt,name=total_disk,json=totalDisk,proto3" json:"total_disk,omitempty"`
	// Total GPU resources
	TotalGpus []*GPUResource `protobuf:"bytes,6,rep,name=total_gpus,json=totalGpus,proto3" json:"total_gpus,omitempty"`
	// Total optional resources to be allocated in the pool,
	// follows the NodeResources.OptResMap format.
	TotalOptRes map[string]string `protobuf:"bytes,4,rep,name=total_opt_res,json=totalOptRes,proto3" json:"total_opt_res,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	// Minimum viable topology
	Topology NodePoolTopology `protobuf:"bytes,5,opt,name=topology,proto3" json:"topology"`
}

func (m *NodePoolResources) Reset()         { *m = NodePoolResources{} }
func (m *NodePoolResources) String() string { return proto.CompactTextString(m) }
func (*NodePoolResources) ProtoMessage()    {}
func (*NodePoolResources) Descriptor() ([]byte, []int) {
	return fileDescriptor_cf1b13971fe4c19d, []int{3}
}
func (m *NodePoolResources) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *NodePoolResources) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_NodePoolResources.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *NodePoolResources) XXX_Merge(src proto.Message) {
	xxx_messageInfo_NodePoolResources.Merge(m, src)
}
func (m *NodePoolResources) XXX_Size() int {
	return m.Size()
}
func (m *NodePoolResources) XXX_DiscardUnknown() {
	xxx_messageInfo_NodePoolResources.DiscardUnknown(m)
}

var xxx_messageInfo_NodePoolResources proto.InternalMessageInfo

// NodePoolTopology defines the minimum resource requirements for a Kubernetes node pool.
type NodePoolTopology struct {
	// Minimum number of vcpus per node
	MinNodeVcpus uint64 `protobuf:"varint,1,opt,name=min_node_vcpus,json=minNodeVcpus,proto3" json:"min_node_vcpus,omitempty"`
	// Minimum amount of RAM in megabytes per node
	MinNodeMemory uint64 `protobuf:"varint,2,opt,name=min_node_memory,json=minNodeMemory,proto3" json:"min_node_memory,omitempty"`
	// Minimum amount of root partition disk space in gigabytes per node
	MinNodeDisk uint64 `protobuf:"varint,3,opt,name=min_node_disk,json=minNodeDisk,proto3" json:"min_node_disk,omitempty"`
	// Minimum GPU resources per node
	MinNodeGpus []*GPUResource `protobuf:"bytes,6,rep,name=min_node_gpus,json=minNodeGpus,proto3" json:"min_node_gpus,omitempty"`
	// Minimum number of optional resources per node
	MinNodeOptRes map[string]string `protobuf:"bytes,4,rep,name=min_node_opt_res,json=minNodeOptRes,proto3" json:"min_node_opt_res,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	// Minimum number of nodes in pool, to satisfy HA/replication requirements
	MinNumberOfNodes int32 `protobuf:"varint,5,opt,name=min_number_of_nodes,json=minNumberOfNodes,proto3" json:"min_number_of_nodes,omitempty"`
}

func (m *NodePoolTopology) Reset()         { *m = NodePoolTopology{} }
func (m *NodePoolTopology) String() string { return proto.CompactTextString(m) }
func (*NodePoolTopology) ProtoMessage()    {}
func (*NodePoolTopology) Descriptor() ([]byte, []int) {
	return fileDescriptor_cf1b13971fe4c19d, []int{4}
}
func (m *NodePoolTopology) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *NodePoolTopology) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_NodePoolTopology.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *NodePoolTopology) XXX_Merge(src proto.Message) {
	xxx_messageInfo_NodePoolTopology.Merge(m, src)
}
func (m *NodePoolTopology) XXX_Size() int {
	return m.Size()
}
func (m *NodePoolTopology) XXX_DiscardUnknown() {
	xxx_messageInfo_NodePoolTopology.DiscardUnknown(m)
}

var xxx_messageInfo_NodePoolTopology proto.InternalMessageInfo

// NodePool defines the resources in a Kubernetes node pool.
type NodePool struct {
	// Node pool name
	Name string `protobuf:"bytes,1,opt,name=Name,proto3" json:"Name,omitempty"`
	// Number of nodes in the pool
	NumNodes uint32 `protobuf:"varint,2,opt,name=num_nodes,json=numNodes,proto3" json:"num_nodes,omitempty"`
	// Specification of per node resources
	NodeResources *NodeResources `protobuf:"bytes,3,opt,name=node_resources,json=nodeResources,proto3" json:"node_resources,omitempty"`
	// Scalable indicates the system may scale the number of nodes
	Scalable bool `protobuf:"varint,4,opt,name=scalable,proto3" json:"scalable,omitempty"`
	// Pool is the control-plane pool for a Kubernetes cluster
	ControlPlane bool `protobuf:"varint,5,opt,name=control_plane,json=controlPlane,proto3" json:"control_plane,omitempty"`
	// Node names in pool when using nodes
	Nodes []string `protobuf:"bytes,6,rep,name=nodes,proto3" json:"nodes,omitempty"`
}

func (m *NodePool) Reset()         { *m = NodePool{} }
func (m *NodePool) String() string { return proto.CompactTextString(m) }
func (*NodePool) ProtoMessage()    {}
func (*NodePool) Descriptor() ([]byte, []int) {
	return fileDescriptor_cf1b13971fe4c19d, []int{5}
}
func (m *NodePool) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *NodePool) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_NodePool.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *NodePool) XXX_Merge(src proto.Message) {
	xxx_messageInfo_NodePool.Merge(m, src)
}
func (m *NodePool) XXX_Size() int {
	return m.Size()
}
func (m *NodePool) XXX_DiscardUnknown() {
	xxx_messageInfo_NodePool.DiscardUnknown(m)
}

var xxx_messageInfo_NodePool proto.InternalMessageInfo

func init() {
	proto.RegisterType((*GPUResource)(nil), "edgeproto.GPUResource")
	proto.RegisterType((*NodeResources)(nil), "edgeproto.NodeResources")
	proto.RegisterMapType((map[string]string)(nil), "edgeproto.NodeResources.OptResMapEntry")
	proto.RegisterType((*KubernetesResources)(nil), "edgeproto.KubernetesResources")
	proto.RegisterType((*NodePoolResources)(nil), "edgeproto.NodePoolResources")
	proto.RegisterMapType((map[string]string)(nil), "edgeproto.NodePoolResources.TotalOptResEntry")
	proto.RegisterType((*NodePoolTopology)(nil), "edgeproto.NodePoolTopology")
	proto.RegisterMapType((map[string]string)(nil), "edgeproto.NodePoolTopology.MinNodeOptResEntry")
	proto.RegisterType((*NodePool)(nil), "edgeproto.NodePool")
}

func init() { proto.RegisterFile("resources.proto", fileDescriptor_cf1b13971fe4c19d) }

var fileDescriptor_cf1b13971fe4c19d = []byte{
	// 902 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x94, 0x55, 0xcf, 0x6f, 0xdc, 0x44,
	0x14, 0x5e, 0x67, 0x9d, 0x8d, 0xfd, 0x9c, 0xcd, 0x8f, 0x69, 0x08, 0x66, 0xdb, 0x2e, 0xe9, 0x82,
	0x20, 0x42, 0xea, 0x16, 0x2d, 0xa5, 0x54, 0x11, 0xbf, 0x14, 0x01, 0x11, 0x42, 0x49, 0xc3, 0xd0,
	0x84, 0xa3, 0xe5, 0xd8, 0x93, 0x95, 0x15, 0x7b, 0xc6, 0xf2, 0x8f, 0x15, 0xdb, 0x3f, 0x01, 0x2e,
	0x1c, 0x39, 0x71, 0xe6, 0xcc, 0x9d, 0x0b, 0xa7, 0x1c, 0x7b, 0x84, 0x0b, 0x82, 0xe4, 0xc2, 0x1d,
	0x04, 0x57, 0x34, 0x6f, 0xc6, 0xae, 0x37, 0xa5, 0x51, 0x73, 0x9b, 0xf7, 0xe6, 0x7d, 0xef, 0x7d,
	0xfb, 0xbe, 0x6f, 0xc7, 0xb0, 0x9c, 0xb1, 0x5c, 0x94, 0x59, 0xc0, 0xf2, 0x61, 0x9a, 0x89, 0x42,
	0x10, 0x9b, 0x85, 0x63, 0x86, 0xc7, 0xde, 0xda, 0x58, 0x8c, 0x05, 0x1e, 0xef, 0xc8, 0x93, 0x2a,
	0xe8, 0x75, 0x43, 0x16, 0x44, 0x89, 0x1f, 0xeb, 0xf0, 0x66, 0x21, 0x44, 0x9c, 0xdf, 0xc1, 0x60,
	0xcc, 0x78, 0x7d, 0x50, 0xd7, 0x83, 0xef, 0x0d, 0x70, 0x76, 0xf6, 0x0f, 0xa8, 0x9e, 0x42, 0x5e,
	0x02, 0x2b, 0x11, 0x21, 0x8b, 0xbd, 0x28, 0x74, 0x8d, 0x0d, 0x63, 0xd3, 0xa6, 0x0b, 0x18, 0x7f,
	0x1a, 0x92, 0x35, 0x98, 0x0f, 0x44, 0xc9, 0x0b, 0x77, 0x6e, 0xc3, 0xd8, 0xec, 0x52, 0x15, 0x90,
	0x75, 0xe8, 0x4c, 0x18, 0x0f, 0x45, 0xe6, 0xb6, 0xb1, 0x5c, 0x47, 0x32, 0x9f, 0xb0, 0x44, 0x64,
	0x53, 0xd7, 0xdc, 0x30, 0x36, 0x4d, 0xaa, 0x23, 0xf2, 0x02, 0x74, 0x22, 0xee, 0x95, 0x39, 0x73,
	0xe7, 0x55, 0x9b, 0x88, 0x1f, 0xe4, 0x6c, 0xeb, 0xc5, 0x3f, 0xff, 0x72, 0x8d, 0x1f, 0xff, 0x71,
	0x4d, 0x2e, 0x38, 0xfb, 0xf9, 0x5f, 0x77, 0x61, 0x57, 0x4d, 0x1d, 0x7c, 0xd3, 0x86, 0xee, 0x9e,
	0x08, 0x59, 0xc5, 0x30, 0x97, 0x3c, 0x26, 0x41, 0x5a, 0xe6, 0xc8, 0xcf, 0xa4, 0x2a, 0x20, 0x2b,
	0xd0, 0xce, 0xfc, 0x04, 0xb9, 0x99, 0x54, 0x1e, 0x09, 0x01, 0x33, 0x8c, 0xf2, 0x13, 0xe4, 0x65,
	0x52, 0x3c, 0x93, 0x37, 0xc0, 0x1c, 0x4b, 0xe8, 0xc2, 0x46, 0x7b, 0xd3, 0x19, 0xad, 0x0f, 0xeb,
	0x65, 0x0e, 0x1b, 0x4b, 0xa0, 0x58, 0x43, 0x76, 0xc0, 0x11, 0x69, 0xe1, 0x65, 0x2c, 0xf7, 0x12,
	0x3f, 0x75, 0x4d, 0x84, 0xbc, 0xde, 0x80, 0xcc, 0xd0, 0x1a, 0x3e, 0x48, 0x0b, 0xca, 0xf2, 0x5d,
	0x3f, 0xfd, 0x98, 0x17, 0xd9, 0x94, 0xda, 0xa2, 0x8a, 0xc9, 0x9b, 0xb0, 0x1a, 0xf1, 0xe3, 0xcc,
	0xf7, 0xb8, 0x08, 0x99, 0x77, 0x1c, 0xfb, 0x13, 0x91, 0xe1, 0xaf, 0xb7, 0xb7, 0xcd, 0x1f, 0xfe,
	0x76, 0x0d, 0xba, 0x8c, 0xd7, 0xb2, 0xdd, 0x27, 0x78, 0x49, 0xee, 0xc1, 0x1a, 0xfb, 0xaa, 0x60,
	0x19, 0xf7, 0x63, 0x6f, 0x22, 0xe2, 0x32, 0x61, 0x5e, 0x1e, 0x3d, 0x62, 0x6e, 0x47, 0xfe, 0x14,
	0x0d, 0x22, 0x55, 0xc5, 0x21, 0x16, 0x7c, 0x11, 0x3d, 0x62, 0xe4, 0x16, 0xd8, 0x38, 0x83, 0xfb,
	0x09, 0x73, 0xad, 0xc6, 0x04, 0x4b, 0xa6, 0xf7, 0xfc, 0x84, 0xf5, 0xde, 0x85, 0xa5, 0x59, 0xa6,
	0x72, 0x73, 0x27, 0x6c, 0xaa, 0xd5, 0x96, 0x47, 0xdc, 0xb0, 0x1f, 0x97, 0x0c, 0xb7, 0x69, 0x53,
	0x15, 0x6c, 0xcd, 0xdd, 0x37, 0x06, 0x3f, 0x19, 0x70, 0xed, 0xb3, 0xf2, 0x88, 0x65, 0x9c, 0x15,
	0x2c, 0x7f, 0xa2, 0xc9, 0x3b, 0x60, 0x05, 0x69, 0xe9, 0xa5, 0x42, 0xc4, 0xd8, 0xc8, 0x19, 0xdd,
	0xb8, 0xb0, 0xa8, 0x7d, 0x21, 0xe2, 0xba, 0x9e, 0x2e, 0x04, 0x69, 0x29, 0x33, 0x12, 0x38, 0xae,
	0x80, 0x73, 0xcf, 0x03, 0x1c, 0x6b, 0xe0, 0x5d, 0x58, 0x4f, 0x22, 0xee, 0x9d, 0xd4, 0x64, 0xbc,
	0x09, 0xcb, 0xf2, 0x48, 0x70, 0xf4, 0x9b, 0x4d, 0xd7, 0x92, 0x88, 0x3f, 0x61, 0x7a, 0xa8, 0xee,
	0x06, 0xdf, 0xb5, 0x61, 0xf5, 0xa9, 0xa6, 0xe4, 0x3e, 0x38, 0x85, 0x28, 0xe4, 0xae, 0x6b, 0x5f,
	0x39, 0xa3, 0xd5, 0x06, 0x8f, 0x83, 0x90, 0x05, 0xf7, 0xee, 0x6e, 0x9b, 0xa7, 0xbf, 0xbd, 0xdc,
	0xa2, 0x80, 0xb5, 0x87, 0xe8, 0xba, 0x5b, 0xb0, 0xa8, 0x90, 0xda, 0xeb, 0xca, 0x7e, 0xaa, 0xdb,
	0xae, 0x32, 0xfc, 0x4d, 0x50, 0x00, 0xaf, 0x61, 0x46, 0x1b, 0x33, 0x1f, 0x49, 0x47, 0xbe, 0x5d,
	0x5d, 0xa3, 0x2f, 0x3b, 0x97, 0xfa, 0x52, 0xc1, 0x76, 0xe4, 0xe0, 0xcf, 0xa1, 0xab, 0x60, 0xda,
	0xa2, 0xda, 0x9e, 0xb7, 0x2f, 0x5b, 0xde, 0xf0, 0xa1, 0x44, 0x28, 0xf5, 0x95, 0x49, 0x15, 0x51,
	0x95, 0x21, 0xef, 0x81, 0x55, 0x88, 0x54, 0xc4, 0x62, 0x3c, 0x45, 0x77, 0x3a, 0xa3, 0xeb, 0xff,
	0xd3, 0xed, 0xa1, 0x2e, 0xd1, 0xcb, 0xa8, 0x21, 0xbd, 0xf7, 0x61, 0xe5, 0x62, 0xff, 0x2b, 0x59,
	0xeb, 0xeb, 0x36, 0xac, 0x5c, 0x1c, 0x42, 0x5e, 0x85, 0x25, 0xa9, 0x32, 0x9a, 0xba, 0xf9, 0xa7,
	0x5f, 0x4c, 0x22, 0x2e, 0x8b, 0x95, 0x0a, 0xaf, 0xc1, 0x72, 0x5d, 0x35, 0x23, 0x44, 0x57, 0x97,
	0x69, 0x29, 0x06, 0xd0, 0xad, 0xeb, 0x1a, 0x6a, 0x38, 0xba, 0x0a, 0xf5, 0xd8, 0x6a, 0xd4, 0x3c,
	0x87, 0x24, 0x15, 0x16, 0x45, 0xf9, 0x12, 0x56, 0x6a, 0xec, 0xac, 0x2e, 0xc3, 0x4b, 0x36, 0x39,
	0xdc, 0x55, 0x2d, 0x9a, 0xc2, 0x54, 0xc4, 0xb5, 0x34, 0xb7, 0xe1, 0x1a, 0x36, 0x2e, 0x93, 0x23,
	0x96, 0x79, 0xe2, 0x18, 0x47, 0xe4, 0xa8, 0xd2, 0x3c, 0x95, 0x33, 0xf7, 0xf0, 0xe6, 0xc1, 0xb1,
	0xc4, 0xe4, 0xbd, 0x0f, 0x81, 0x3c, 0xdd, 0xf3, 0x4a, 0x62, 0xfc, 0x6a, 0x80, 0x55, 0xf1, 0x94,
	0x0f, 0xa9, 0x7c, 0x3a, 0x34, 0x12, 0xcf, 0xe4, 0x3a, 0xd8, 0xbc, 0x4c, 0x34, 0x0f, 0xf5, 0x41,
	0xb0, 0x78, 0x99, 0xe0, 0x7c, 0xf2, 0x01, 0x2c, 0xe1, 0x0e, 0xea, 0x6f, 0x17, 0x2e, 0xda, 0x19,
	0xb9, 0xcf, 0x7a, 0x3c, 0x69, 0x97, 0xcf, 0x3c, 0xf1, 0x3d, 0xb0, 0xf2, 0xc0, 0x8f, 0xfd, 0xa3,
	0x98, 0xe1, 0xdf, 0xd9, 0xa2, 0x75, 0x4c, 0x5e, 0x81, 0x6e, 0x20, 0x78, 0x91, 0x89, 0xd8, 0x4b,
	0x63, 0x9f, 0xab, 0xef, 0x88, 0x45, 0x17, 0x75, 0x72, 0x5f, 0xe6, 0x48, 0x0f, 0xe6, 0x15, 0x35,
	0xa9, 0x5e, 0xf5, 0x08, 0xaa, 0xd4, 0xf6, 0x8d, 0xd3, 0x3f, 0xfa, 0xad, 0xd3, 0xb3, 0xbe, 0xf1,
	0xf8, 0xac, 0x6f, 0xfc, 0x7e, 0xd6, 0x37, 0xbe, 0x3d, 0xef, 0xb7, 0x1e, 0x9f, 0xf7, 0x5b, 0xbf,
	0x9c, 0xf7, 0x5b, 0x47, 0x1d, 0xa4, 0xf7, 0xd6, 0x7f, 0x01, 0x00, 0x00, 0xff, 0xff, 0x14, 0xa4,
	0x00, 0xee, 0x79, 0x07, 0x00, 0x00,
}

func (m *GPUResource) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *GPUResource) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *GPUResource) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.InUse != 0 {
		i = encodeVarintResources(dAtA, i, uint64(m.InUse))
		i--
		dAtA[i] = 0x28
	}
	if m.Memory != 0 {
		i = encodeVarintResources(dAtA, i, uint64(m.Memory))
		i--
		dAtA[i] = 0x20
	}
	if len(m.Vendor) > 0 {
		i -= len(m.Vendor)
		copy(dAtA[i:], m.Vendor)
		i = encodeVarintResources(dAtA, i, uint64(len(m.Vendor)))
		i--
		dAtA[i] = 0x1a
	}
	if m.Count != 0 {
		i = encodeVarintResources(dAtA, i, uint64(m.Count))
		i--
		dAtA[i] = 0x10
	}
	if len(m.ModelId) > 0 {
		i -= len(m.ModelId)
		copy(dAtA[i:], m.ModelId)
		i = encodeVarintResources(dAtA, i, uint64(len(m.ModelId)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *NodeResources) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *NodeResources) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *NodeResources) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.NodeName) > 0 {
		i -= len(m.NodeName)
		copy(dAtA[i:], m.NodeName)
		i = encodeVarintResources(dAtA, i, uint64(len(m.NodeName)))
		i--
		dAtA[i] = 0x42
	}
	if len(m.Gpus) > 0 {
		for iNdEx := len(m.Gpus) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.Gpus[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintResources(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x3a
		}
	}
	if m.ExternalVolumeSize != 0 {
		i = encodeVarintResources(dAtA, i, uint64(m.ExternalVolumeSize))
		i--
		dAtA[i] = 0x30
	}
	if len(m.InfraNodeFlavor) > 0 {
		i -= len(m.InfraNodeFlavor)
		copy(dAtA[i:], m.InfraNodeFlavor)
		i = encodeVarintResources(dAtA, i, uint64(len(m.InfraNodeFlavor)))
		i--
		dAtA[i] = 0x2a
	}
	if len(m.OptResMap) > 0 {
		for k := range m.OptResMap {
			v := m.OptResMap[k]
			baseI := i
			i -= len(v)
			copy(dAtA[i:], v)
			i = encodeVarintResources(dAtA, i, uint64(len(v)))
			i--
			dAtA[i] = 0x12
			i -= len(k)
			copy(dAtA[i:], k)
			i = encodeVarintResources(dAtA, i, uint64(len(k)))
			i--
			dAtA[i] = 0xa
			i = encodeVarintResources(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x22
		}
	}
	if m.Disk != 0 {
		i = encodeVarintResources(dAtA, i, uint64(m.Disk))
		i--
		dAtA[i] = 0x18
	}
	if m.Ram != 0 {
		i = encodeVarintResources(dAtA, i, uint64(m.Ram))
		i--
		dAtA[i] = 0x10
	}
	if m.Vcpus != 0 {
		i = encodeVarintResources(dAtA, i, uint64(m.Vcpus))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *KubernetesResources) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *KubernetesResources) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *KubernetesResources) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.MinKubernetesVersion) > 0 {
		i -= len(m.MinKubernetesVersion)
		copy(dAtA[i:], m.MinKubernetesVersion)
		i = encodeVarintResources(dAtA, i, uint64(len(m.MinKubernetesVersion)))
		i--
		dAtA[i] = 0x22
	}
	if m.GpuPool != nil {
		{
			size, err := m.GpuPool.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintResources(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x12
	}
	if m.CpuPool != nil {
		{
			size, err := m.CpuPool.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintResources(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *NodePoolResources) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *NodePoolResources) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *NodePoolResources) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.TotalGpus) > 0 {
		for iNdEx := len(m.TotalGpus) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.TotalGpus[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintResources(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x32
		}
	}
	{
		size, err := m.Topology.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintResources(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x2a
	if len(m.TotalOptRes) > 0 {
		for k := range m.TotalOptRes {
			v := m.TotalOptRes[k]
			baseI := i
			i -= len(v)
			copy(dAtA[i:], v)
			i = encodeVarintResources(dAtA, i, uint64(len(v)))
			i--
			dAtA[i] = 0x12
			i -= len(k)
			copy(dAtA[i:], k)
			i = encodeVarintResources(dAtA, i, uint64(len(k)))
			i--
			dAtA[i] = 0xa
			i = encodeVarintResources(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x22
		}
	}
	if m.TotalDisk != 0 {
		i = encodeVarintResources(dAtA, i, uint64(m.TotalDisk))
		i--
		dAtA[i] = 0x18
	}
	if m.TotalMemory != 0 {
		i = encodeVarintResources(dAtA, i, uint64(m.TotalMemory))
		i--
		dAtA[i] = 0x10
	}
	{
		size, err := m.TotalVcpus.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintResources(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0xa
	return len(dAtA) - i, nil
}

func (m *NodePoolTopology) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *NodePoolTopology) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *NodePoolTopology) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.MinNodeGpus) > 0 {
		for iNdEx := len(m.MinNodeGpus) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.MinNodeGpus[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintResources(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x32
		}
	}
	if m.MinNumberOfNodes != 0 {
		i = encodeVarintResources(dAtA, i, uint64(m.MinNumberOfNodes))
		i--
		dAtA[i] = 0x28
	}
	if len(m.MinNodeOptRes) > 0 {
		for k := range m.MinNodeOptRes {
			v := m.MinNodeOptRes[k]
			baseI := i
			i -= len(v)
			copy(dAtA[i:], v)
			i = encodeVarintResources(dAtA, i, uint64(len(v)))
			i--
			dAtA[i] = 0x12
			i -= len(k)
			copy(dAtA[i:], k)
			i = encodeVarintResources(dAtA, i, uint64(len(k)))
			i--
			dAtA[i] = 0xa
			i = encodeVarintResources(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x22
		}
	}
	if m.MinNodeDisk != 0 {
		i = encodeVarintResources(dAtA, i, uint64(m.MinNodeDisk))
		i--
		dAtA[i] = 0x18
	}
	if m.MinNodeMemory != 0 {
		i = encodeVarintResources(dAtA, i, uint64(m.MinNodeMemory))
		i--
		dAtA[i] = 0x10
	}
	if m.MinNodeVcpus != 0 {
		i = encodeVarintResources(dAtA, i, uint64(m.MinNodeVcpus))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *NodePool) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *NodePool) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *NodePool) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.Nodes) > 0 {
		for iNdEx := len(m.Nodes) - 1; iNdEx >= 0; iNdEx-- {
			i -= len(m.Nodes[iNdEx])
			copy(dAtA[i:], m.Nodes[iNdEx])
			i = encodeVarintResources(dAtA, i, uint64(len(m.Nodes[iNdEx])))
			i--
			dAtA[i] = 0x32
		}
	}
	if m.ControlPlane {
		i--
		if m.ControlPlane {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x28
	}
	if m.Scalable {
		i--
		if m.Scalable {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x20
	}
	if m.NodeResources != nil {
		{
			size, err := m.NodeResources.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintResources(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x1a
	}
	if m.NumNodes != 0 {
		i = encodeVarintResources(dAtA, i, uint64(m.NumNodes))
		i--
		dAtA[i] = 0x10
	}
	if len(m.Name) > 0 {
		i -= len(m.Name)
		copy(dAtA[i:], m.Name)
		i = encodeVarintResources(dAtA, i, uint64(len(m.Name)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func encodeVarintResources(dAtA []byte, offset int, v uint64) int {
	offset -= sovResources(v)
	base := offset
	for v >= 1<<7 {
		dAtA[offset] = uint8(v&0x7f | 0x80)
		v >>= 7
		offset++
	}
	dAtA[offset] = uint8(v)
	return base
}
func (m *GPUResource) Matches(o *GPUResource, fopts ...MatchOpt) bool {
	opts := MatchOptions{}
	applyMatchOptions(&opts, fopts...)
	if o == nil {
		if opts.Filter {
			return true
		}
		return false
	}
	if !opts.Filter || o.ModelId != "" {
		if o.ModelId != m.ModelId {
			return false
		}
	}
	if !opts.Filter || o.Count != 0 {
		if o.Count != m.Count {
			return false
		}
	}
	if !opts.Filter || o.Vendor != "" {
		if o.Vendor != m.Vendor {
			return false
		}
	}
	if !opts.Filter || o.Memory != 0 {
		if o.Memory != m.Memory {
			return false
		}
	}
	if !opts.Filter || o.InUse != 0 {
		if o.InUse != m.InUse {
			return false
		}
	}
	return true
}

func (m *GPUResource) Clone() *GPUResource {
	cp := &GPUResource{}
	cp.DeepCopyIn(m)
	return cp
}

func (m *GPUResource) CopyInFields(src *GPUResource) int {
	changed := 0
	if m.ModelId != src.ModelId {
		m.ModelId = src.ModelId
		changed++
	}
	if m.Count != src.Count {
		m.Count = src.Count
		changed++
	}
	if m.Vendor != src.Vendor {
		m.Vendor = src.Vendor
		changed++
	}
	if m.Memory != src.Memory {
		m.Memory = src.Memory
		changed++
	}
	if m.InUse != src.InUse {
		m.InUse = src.InUse
		changed++
	}
	return changed
}

func (m *GPUResource) DeepCopyIn(src *GPUResource) {
	m.ModelId = src.ModelId
	m.Count = src.Count
	m.Vendor = src.Vendor
	m.Memory = src.Memory
	m.InUse = src.InUse
}

type GPUResourceKey string

func (k GPUResourceKey) GetKeyString() string {
	return string(k)
}

func GPUResourceKeyStringParse(str string, key *GPUResourceKey) {
	*key = GPUResourceKey(str)
}

func (k GPUResourceKey) NotFoundError() error {
	return fmt.Errorf("GPUResource key %s not found", k.GetKeyString())
}

func (k GPUResourceKey) ExistsError() error {
	return fmt.Errorf("GPUResource key %s already exists", k.GetKeyString())
}

func (k GPUResourceKey) BeingDeletedError() error {
	return fmt.Errorf("GPUResource key %s is being deleted", k.GetKeyString())
}

func (k GPUResourceKey) GetTags() map[string]string {
	return map[string]string{
		"modelid": string(k),
	}
}

func (k GPUResourceKey) AddTagsByFunc(addTag AddTagFunc) {
	addTag("modelid", string(k))
}

func (k GPUResourceKey) AddTags(tags map[string]string) {
	tagMap := TagMap(tags)
	k.AddTagsByFunc(tagMap.AddTag)
}

func (m *GPUResource) GetObjKey() objstore.ObjKey {
	return m.GetKey()
}

func (m *GPUResource) GetKey() *GPUResourceKey {
	key := GPUResourceKey(m.ModelId)
	return &key
}

func (m *GPUResource) GetKeyVal() GPUResourceKey {
	return GPUResourceKey(m.ModelId)
}

func (m *GPUResource) SetKey(key *GPUResourceKey) {
	m.ModelId = string(*key)
}

func CmpSortGPUResource(a GPUResource, b GPUResource) bool {
	return a.ModelId < b.ModelId
}

// Helper method to check that enums have valid values
func (m *GPUResource) ValidateEnums() error {
	return nil
}

func (s *GPUResource) ClearTagged(tags map[string]struct{}) {
}

func (m *NodeResources) Clone() *NodeResources {
	cp := &NodeResources{}
	cp.DeepCopyIn(m)
	return cp
}

func (m *NodeResources) AddGpus(vals ...*GPUResource) int {
	changes := 0
	cur := make(map[string]struct{})
	for _, v := range m.Gpus {
		cur[v.GetKey().GetKeyString()] = struct{}{}
	}
	for _, v := range vals {
		if _, found := cur[v.GetKey().GetKeyString()]; found {
			continue // duplicate
		}
		m.Gpus = append(m.Gpus, v)
		changes++
	}
	return changes
}

func (m *NodeResources) RemoveGpus(vals ...*GPUResource) int {
	changes := 0
	remove := make(map[string]struct{})
	for _, v := range vals {
		remove[v.GetKey().GetKeyString()] = struct{}{}
	}
	for i := len(m.Gpus); i >= 0; i-- {
		if _, found := remove[m.Gpus[i].GetKey().GetKeyString()]; found {
			m.Gpus = append(m.Gpus[:i], m.Gpus[i+1:]...)
			changes++
		}
	}
	return changes
}

func (m *NodeResources) CopyInFields(src *NodeResources) int {
	updateListAction := "replace"
	changed := 0
	if m.Vcpus != src.Vcpus {
		m.Vcpus = src.Vcpus
		changed++
	}
	if m.Ram != src.Ram {
		m.Ram = src.Ram
		changed++
	}
	if m.Disk != src.Disk {
		m.Disk = src.Disk
		changed++
	}
	if src.OptResMap != nil {
		if updateListAction == "add" {
			for k0, v := range src.OptResMap {
				m.OptResMap[k0] = v
				changed++
			}
		} else if updateListAction == "remove" {
			for k0, _ := range src.OptResMap {
				if _, ok := m.OptResMap[k0]; ok {
					delete(m.OptResMap, k0)
					changed++
				}
			}
		} else {
			m.OptResMap = make(map[string]string)
			for k0, v := range src.OptResMap {
				m.OptResMap[k0] = v
			}
			changed++
		}
	} else if m.OptResMap != nil {
		m.OptResMap = nil
		changed++
	}
	if m.InfraNodeFlavor != src.InfraNodeFlavor {
		m.InfraNodeFlavor = src.InfraNodeFlavor
		changed++
	}
	if m.ExternalVolumeSize != src.ExternalVolumeSize {
		m.ExternalVolumeSize = src.ExternalVolumeSize
		changed++
	}
	if src.Gpus != nil {
		if updateListAction == "add" {
			changed += m.AddGpus(src.Gpus...)
		} else if updateListAction == "remove" {
			changed += m.RemoveGpus(src.Gpus...)
		} else {
			m.Gpus = make([]*GPUResource, 0)
			for k0, _ := range src.Gpus {
				m.Gpus = append(m.Gpus, src.Gpus[k0].Clone())
			}
			changed++
		}
	} else if m.Gpus != nil {
		m.Gpus = nil
		changed++
	}
	if m.NodeName != src.NodeName {
		m.NodeName = src.NodeName
		changed++
	}
	return changed
}

func (m *NodeResources) DeepCopyIn(src *NodeResources) {
	m.Vcpus = src.Vcpus
	m.Ram = src.Ram
	m.Disk = src.Disk
	if src.OptResMap != nil {
		m.OptResMap = make(map[string]string)
		for k, v := range src.OptResMap {
			m.OptResMap[k] = v
		}
	} else {
		m.OptResMap = nil
	}
	m.InfraNodeFlavor = src.InfraNodeFlavor
	m.ExternalVolumeSize = src.ExternalVolumeSize
	if src.Gpus != nil {
		m.Gpus = make([]*GPUResource, len(src.Gpus), len(src.Gpus))
		for ii, s := range src.Gpus {
			var tmp_s GPUResource
			tmp_s.DeepCopyIn(s)
			m.Gpus[ii] = &tmp_s
		}
	} else {
		m.Gpus = nil
	}
	m.NodeName = src.NodeName
}

// Helper method to check that enums have valid values
func (m *NodeResources) ValidateEnums() error {
	for _, e := range m.Gpus {
		if err := e.ValidateEnums(); err != nil {
			return err
		}
	}
	return nil
}

func (s *NodeResources) ClearTagged(tags map[string]struct{}) {
	if s.Gpus != nil {
		for ii := 0; ii < len(s.Gpus); ii++ {
			s.Gpus[ii].ClearTagged(tags)
		}
	}
}

func (m *KubernetesResources) Clone() *KubernetesResources {
	cp := &KubernetesResources{}
	cp.DeepCopyIn(m)
	return cp
}

func (m *KubernetesResources) AddCpuPoolTopologyMinNodeGpus(vals ...*GPUResource) int {
	changes := 0
	cur := make(map[string]struct{})
	for _, v := range m.CpuPool.Topology.MinNodeGpus {
		cur[v.GetKey().GetKeyString()] = struct{}{}
	}
	for _, v := range vals {
		if _, found := cur[v.GetKey().GetKeyString()]; found {
			continue // duplicate
		}
		m.CpuPool.Topology.MinNodeGpus = append(m.CpuPool.Topology.MinNodeGpus, v)
		changes++
	}
	return changes
}

func (m *KubernetesResources) RemoveCpuPoolTopologyMinNodeGpus(vals ...*GPUResource) int {
	changes := 0
	remove := make(map[string]struct{})
	for _, v := range vals {
		remove[v.GetKey().GetKeyString()] = struct{}{}
	}
	for i := len(m.CpuPool.Topology.MinNodeGpus); i >= 0; i-- {
		if _, found := remove[m.CpuPool.Topology.MinNodeGpus[i].GetKey().GetKeyString()]; found {
			m.CpuPool.Topology.MinNodeGpus = append(m.CpuPool.Topology.MinNodeGpus[:i], m.CpuPool.Topology.MinNodeGpus[i+1:]...)
			changes++
		}
	}
	return changes
}

func (m *KubernetesResources) AddCpuPoolTotalGpus(vals ...*GPUResource) int {
	changes := 0
	cur := make(map[string]struct{})
	for _, v := range m.CpuPool.TotalGpus {
		cur[v.GetKey().GetKeyString()] = struct{}{}
	}
	for _, v := range vals {
		if _, found := cur[v.GetKey().GetKeyString()]; found {
			continue // duplicate
		}
		m.CpuPool.TotalGpus = append(m.CpuPool.TotalGpus, v)
		changes++
	}
	return changes
}

func (m *KubernetesResources) RemoveCpuPoolTotalGpus(vals ...*GPUResource) int {
	changes := 0
	remove := make(map[string]struct{})
	for _, v := range vals {
		remove[v.GetKey().GetKeyString()] = struct{}{}
	}
	for i := len(m.CpuPool.TotalGpus); i >= 0; i-- {
		if _, found := remove[m.CpuPool.TotalGpus[i].GetKey().GetKeyString()]; found {
			m.CpuPool.TotalGpus = append(m.CpuPool.TotalGpus[:i], m.CpuPool.TotalGpus[i+1:]...)
			changes++
		}
	}
	return changes
}

func (m *KubernetesResources) AddGpuPoolTopologyMinNodeGpus(vals ...*GPUResource) int {
	changes := 0
	cur := make(map[string]struct{})
	for _, v := range m.GpuPool.Topology.MinNodeGpus {
		cur[v.GetKey().GetKeyString()] = struct{}{}
	}
	for _, v := range vals {
		if _, found := cur[v.GetKey().GetKeyString()]; found {
			continue // duplicate
		}
		m.GpuPool.Topology.MinNodeGpus = append(m.GpuPool.Topology.MinNodeGpus, v)
		changes++
	}
	return changes
}

func (m *KubernetesResources) RemoveGpuPoolTopologyMinNodeGpus(vals ...*GPUResource) int {
	changes := 0
	remove := make(map[string]struct{})
	for _, v := range vals {
		remove[v.GetKey().GetKeyString()] = struct{}{}
	}
	for i := len(m.GpuPool.Topology.MinNodeGpus); i >= 0; i-- {
		if _, found := remove[m.GpuPool.Topology.MinNodeGpus[i].GetKey().GetKeyString()]; found {
			m.GpuPool.Topology.MinNodeGpus = append(m.GpuPool.Topology.MinNodeGpus[:i], m.GpuPool.Topology.MinNodeGpus[i+1:]...)
			changes++
		}
	}
	return changes
}

func (m *KubernetesResources) AddGpuPoolTotalGpus(vals ...*GPUResource) int {
	changes := 0
	cur := make(map[string]struct{})
	for _, v := range m.GpuPool.TotalGpus {
		cur[v.GetKey().GetKeyString()] = struct{}{}
	}
	for _, v := range vals {
		if _, found := cur[v.GetKey().GetKeyString()]; found {
			continue // duplicate
		}
		m.GpuPool.TotalGpus = append(m.GpuPool.TotalGpus, v)
		changes++
	}
	return changes
}

func (m *KubernetesResources) RemoveGpuPoolTotalGpus(vals ...*GPUResource) int {
	changes := 0
	remove := make(map[string]struct{})
	for _, v := range vals {
		remove[v.GetKey().GetKeyString()] = struct{}{}
	}
	for i := len(m.GpuPool.TotalGpus); i >= 0; i-- {
		if _, found := remove[m.GpuPool.TotalGpus[i].GetKey().GetKeyString()]; found {
			m.GpuPool.TotalGpus = append(m.GpuPool.TotalGpus[:i], m.GpuPool.TotalGpus[i+1:]...)
			changes++
		}
	}
	return changes
}

func (m *KubernetesResources) CopyInFields(src *KubernetesResources) int {
	updateListAction := "replace"
	changed := 0
	if src.CpuPool != nil {
		if m.CpuPool == nil {
			m.CpuPool = &NodePoolResources{}
		}
		if m.CpuPool.TotalVcpus.Whole != src.CpuPool.TotalVcpus.Whole {
			m.CpuPool.TotalVcpus.Whole = src.CpuPool.TotalVcpus.Whole
			changed++
		}
		if m.CpuPool.TotalVcpus.Nanos != src.CpuPool.TotalVcpus.Nanos {
			m.CpuPool.TotalVcpus.Nanos = src.CpuPool.TotalVcpus.Nanos
			changed++
		}
		if m.CpuPool.TotalMemory != src.CpuPool.TotalMemory {
			m.CpuPool.TotalMemory = src.CpuPool.TotalMemory
			changed++
		}
		if m.CpuPool.TotalDisk != src.CpuPool.TotalDisk {
			m.CpuPool.TotalDisk = src.CpuPool.TotalDisk
			changed++
		}
		if src.CpuPool.TotalOptRes != nil {
			if updateListAction == "add" {
				for k1, v := range src.CpuPool.TotalOptRes {
					m.CpuPool.TotalOptRes[k1] = v
					changed++
				}
			} else if updateListAction == "remove" {
				for k1, _ := range src.CpuPool.TotalOptRes {
					if _, ok := m.CpuPool.TotalOptRes[k1]; ok {
						delete(m.CpuPool.TotalOptRes, k1)
						changed++
					}
				}
			} else {
				m.CpuPool.TotalOptRes = make(map[string]string)
				for k1, v := range src.CpuPool.TotalOptRes {
					m.CpuPool.TotalOptRes[k1] = v
				}
				changed++
			}
		} else if m.CpuPool.TotalOptRes != nil {
			m.CpuPool.TotalOptRes = nil
			changed++
		}
		if m.CpuPool.Topology.MinNodeVcpus != src.CpuPool.Topology.MinNodeVcpus {
			m.CpuPool.Topology.MinNodeVcpus = src.CpuPool.Topology.MinNodeVcpus
			changed++
		}
		if m.CpuPool.Topology.MinNodeMemory != src.CpuPool.Topology.MinNodeMemory {
			m.CpuPool.Topology.MinNodeMemory = src.CpuPool.Topology.MinNodeMemory
			changed++
		}
		if m.CpuPool.Topology.MinNodeDisk != src.CpuPool.Topology.MinNodeDisk {
			m.CpuPool.Topology.MinNodeDisk = src.CpuPool.Topology.MinNodeDisk
			changed++
		}
		if src.CpuPool.Topology.MinNodeOptRes != nil {
			if updateListAction == "add" {
				for k2, v := range src.CpuPool.Topology.MinNodeOptRes {
					m.CpuPool.Topology.MinNodeOptRes[k2] = v
					changed++
				}
			} else if updateListAction == "remove" {
				for k2, _ := range src.CpuPool.Topology.MinNodeOptRes {
					if _, ok := m.CpuPool.Topology.MinNodeOptRes[k2]; ok {
						delete(m.CpuPool.Topology.MinNodeOptRes, k2)
						changed++
					}
				}
			} else {
				m.CpuPool.Topology.MinNodeOptRes = make(map[string]string)
				for k2, v := range src.CpuPool.Topology.MinNodeOptRes {
					m.CpuPool.Topology.MinNodeOptRes[k2] = v
				}
				changed++
			}
		} else if m.CpuPool.Topology.MinNodeOptRes != nil {
			m.CpuPool.Topology.MinNodeOptRes = nil
			changed++
		}
		if m.CpuPool.Topology.MinNumberOfNodes != src.CpuPool.Topology.MinNumberOfNodes {
			m.CpuPool.Topology.MinNumberOfNodes = src.CpuPool.Topology.MinNumberOfNodes
			changed++
		}
		if src.CpuPool.Topology.MinNodeGpus != nil {
			if updateListAction == "add" {
				changed += m.AddCpuPoolTopologyMinNodeGpus(src.CpuPool.Topology.MinNodeGpus...)
			} else if updateListAction == "remove" {
				changed += m.RemoveCpuPoolTopologyMinNodeGpus(src.CpuPool.Topology.MinNodeGpus...)
			} else {
				m.CpuPool.Topology.MinNodeGpus = make([]*GPUResource, 0)
				for k2, _ := range src.CpuPool.Topology.MinNodeGpus {
					m.CpuPool.Topology.MinNodeGpus = append(m.CpuPool.Topology.MinNodeGpus, src.CpuPool.Topology.MinNodeGpus[k2].Clone())
				}
				changed++
			}
		} else if m.CpuPool.Topology.MinNodeGpus != nil {
			m.CpuPool.Topology.MinNodeGpus = nil
			changed++
		}
		if src.CpuPool.TotalGpus != nil {
			if updateListAction == "add" {
				changed += m.AddCpuPoolTotalGpus(src.CpuPool.TotalGpus...)
			} else if updateListAction == "remove" {
				changed += m.RemoveCpuPoolTotalGpus(src.CpuPool.TotalGpus...)
			} else {
				m.CpuPool.TotalGpus = make([]*GPUResource, 0)
				for k1, _ := range src.CpuPool.TotalGpus {
					m.CpuPool.TotalGpus = append(m.CpuPool.TotalGpus, src.CpuPool.TotalGpus[k1].Clone())
				}
				changed++
			}
		} else if m.CpuPool.TotalGpus != nil {
			m.CpuPool.TotalGpus = nil
			changed++
		}
	} else if m.CpuPool != nil {
		m.CpuPool = nil
		changed++
	}
	if src.GpuPool != nil {
		if m.GpuPool == nil {
			m.GpuPool = &NodePoolResources{}
		}
		if m.GpuPool.TotalVcpus.Whole != src.GpuPool.TotalVcpus.Whole {
			m.GpuPool.TotalVcpus.Whole = src.GpuPool.TotalVcpus.Whole
			changed++
		}
		if m.GpuPool.TotalVcpus.Nanos != src.GpuPool.TotalVcpus.Nanos {
			m.GpuPool.TotalVcpus.Nanos = src.GpuPool.TotalVcpus.Nanos
			changed++
		}
		if m.GpuPool.TotalMemory != src.GpuPool.TotalMemory {
			m.GpuPool.TotalMemory = src.GpuPool.TotalMemory
			changed++
		}
		if m.GpuPool.TotalDisk != src.GpuPool.TotalDisk {
			m.GpuPool.TotalDisk = src.GpuPool.TotalDisk
			changed++
		}
		if src.GpuPool.TotalOptRes != nil {
			if updateListAction == "add" {
				for k1, v := range src.GpuPool.TotalOptRes {
					m.GpuPool.TotalOptRes[k1] = v
					changed++
				}
			} else if updateListAction == "remove" {
				for k1, _ := range src.GpuPool.TotalOptRes {
					if _, ok := m.GpuPool.TotalOptRes[k1]; ok {
						delete(m.GpuPool.TotalOptRes, k1)
						changed++
					}
				}
			} else {
				m.GpuPool.TotalOptRes = make(map[string]string)
				for k1, v := range src.GpuPool.TotalOptRes {
					m.GpuPool.TotalOptRes[k1] = v
				}
				changed++
			}
		} else if m.GpuPool.TotalOptRes != nil {
			m.GpuPool.TotalOptRes = nil
			changed++
		}
		if m.GpuPool.Topology.MinNodeVcpus != src.GpuPool.Topology.MinNodeVcpus {
			m.GpuPool.Topology.MinNodeVcpus = src.GpuPool.Topology.MinNodeVcpus
			changed++
		}
		if m.GpuPool.Topology.MinNodeMemory != src.GpuPool.Topology.MinNodeMemory {
			m.GpuPool.Topology.MinNodeMemory = src.GpuPool.Topology.MinNodeMemory
			changed++
		}
		if m.GpuPool.Topology.MinNodeDisk != src.GpuPool.Topology.MinNodeDisk {
			m.GpuPool.Topology.MinNodeDisk = src.GpuPool.Topology.MinNodeDisk
			changed++
		}
		if src.GpuPool.Topology.MinNodeOptRes != nil {
			if updateListAction == "add" {
				for k2, v := range src.GpuPool.Topology.MinNodeOptRes {
					m.GpuPool.Topology.MinNodeOptRes[k2] = v
					changed++
				}
			} else if updateListAction == "remove" {
				for k2, _ := range src.GpuPool.Topology.MinNodeOptRes {
					if _, ok := m.GpuPool.Topology.MinNodeOptRes[k2]; ok {
						delete(m.GpuPool.Topology.MinNodeOptRes, k2)
						changed++
					}
				}
			} else {
				m.GpuPool.Topology.MinNodeOptRes = make(map[string]string)
				for k2, v := range src.GpuPool.Topology.MinNodeOptRes {
					m.GpuPool.Topology.MinNodeOptRes[k2] = v
				}
				changed++
			}
		} else if m.GpuPool.Topology.MinNodeOptRes != nil {
			m.GpuPool.Topology.MinNodeOptRes = nil
			changed++
		}
		if m.GpuPool.Topology.MinNumberOfNodes != src.GpuPool.Topology.MinNumberOfNodes {
			m.GpuPool.Topology.MinNumberOfNodes = src.GpuPool.Topology.MinNumberOfNodes
			changed++
		}
		if src.GpuPool.Topology.MinNodeGpus != nil {
			if updateListAction == "add" {
				changed += m.AddGpuPoolTopologyMinNodeGpus(src.GpuPool.Topology.MinNodeGpus...)
			} else if updateListAction == "remove" {
				changed += m.RemoveGpuPoolTopologyMinNodeGpus(src.GpuPool.Topology.MinNodeGpus...)
			} else {
				m.GpuPool.Topology.MinNodeGpus = make([]*GPUResource, 0)
				for k2, _ := range src.GpuPool.Topology.MinNodeGpus {
					m.GpuPool.Topology.MinNodeGpus = append(m.GpuPool.Topology.MinNodeGpus, src.GpuPool.Topology.MinNodeGpus[k2].Clone())
				}
				changed++
			}
		} else if m.GpuPool.Topology.MinNodeGpus != nil {
			m.GpuPool.Topology.MinNodeGpus = nil
			changed++
		}
		if src.GpuPool.TotalGpus != nil {
			if updateListAction == "add" {
				changed += m.AddGpuPoolTotalGpus(src.GpuPool.TotalGpus...)
			} else if updateListAction == "remove" {
				changed += m.RemoveGpuPoolTotalGpus(src.GpuPool.TotalGpus...)
			} else {
				m.GpuPool.TotalGpus = make([]*GPUResource, 0)
				for k1, _ := range src.GpuPool.TotalGpus {
					m.GpuPool.TotalGpus = append(m.GpuPool.TotalGpus, src.GpuPool.TotalGpus[k1].Clone())
				}
				changed++
			}
		} else if m.GpuPool.TotalGpus != nil {
			m.GpuPool.TotalGpus = nil
			changed++
		}
	} else if m.GpuPool != nil {
		m.GpuPool = nil
		changed++
	}
	if m.MinKubernetesVersion != src.MinKubernetesVersion {
		m.MinKubernetesVersion = src.MinKubernetesVersion
		changed++
	}
	return changed
}

func (m *KubernetesResources) DeepCopyIn(src *KubernetesResources) {
	if src.CpuPool != nil {
		var tmp_CpuPool NodePoolResources
		tmp_CpuPool.DeepCopyIn(src.CpuPool)
		m.CpuPool = &tmp_CpuPool
	} else {
		m.CpuPool = nil
	}
	if src.GpuPool != nil {
		var tmp_GpuPool NodePoolResources
		tmp_GpuPool.DeepCopyIn(src.GpuPool)
		m.GpuPool = &tmp_GpuPool
	} else {
		m.GpuPool = nil
	}
	m.MinKubernetesVersion = src.MinKubernetesVersion
}

// Helper method to check that enums have valid values
func (m *KubernetesResources) ValidateEnums() error {
	if m.CpuPool != nil {
		if err := m.CpuPool.ValidateEnums(); err != nil {
			return err
		}
	}
	if m.GpuPool != nil {
		if err := m.GpuPool.ValidateEnums(); err != nil {
			return err
		}
	}
	return nil
}

func (s *KubernetesResources) ClearTagged(tags map[string]struct{}) {
	if s.CpuPool != nil {
		s.CpuPool.ClearTagged(tags)
	}
	if s.GpuPool != nil {
		s.GpuPool.ClearTagged(tags)
	}
}

func (m *NodePoolResources) Clone() *NodePoolResources {
	cp := &NodePoolResources{}
	cp.DeepCopyIn(m)
	return cp
}

func (m *NodePoolResources) AddTopologyMinNodeGpus(vals ...*GPUResource) int {
	changes := 0
	cur := make(map[string]struct{})
	for _, v := range m.Topology.MinNodeGpus {
		cur[v.GetKey().GetKeyString()] = struct{}{}
	}
	for _, v := range vals {
		if _, found := cur[v.GetKey().GetKeyString()]; found {
			continue // duplicate
		}
		m.Topology.MinNodeGpus = append(m.Topology.MinNodeGpus, v)
		changes++
	}
	return changes
}

func (m *NodePoolResources) RemoveTopologyMinNodeGpus(vals ...*GPUResource) int {
	changes := 0
	remove := make(map[string]struct{})
	for _, v := range vals {
		remove[v.GetKey().GetKeyString()] = struct{}{}
	}
	for i := len(m.Topology.MinNodeGpus); i >= 0; i-- {
		if _, found := remove[m.Topology.MinNodeGpus[i].GetKey().GetKeyString()]; found {
			m.Topology.MinNodeGpus = append(m.Topology.MinNodeGpus[:i], m.Topology.MinNodeGpus[i+1:]...)
			changes++
		}
	}
	return changes
}

func (m *NodePoolResources) AddTotalGpus(vals ...*GPUResource) int {
	changes := 0
	cur := make(map[string]struct{})
	for _, v := range m.TotalGpus {
		cur[v.GetKey().GetKeyString()] = struct{}{}
	}
	for _, v := range vals {
		if _, found := cur[v.GetKey().GetKeyString()]; found {
			continue // duplicate
		}
		m.TotalGpus = append(m.TotalGpus, v)
		changes++
	}
	return changes
}

func (m *NodePoolResources) RemoveTotalGpus(vals ...*GPUResource) int {
	changes := 0
	remove := make(map[string]struct{})
	for _, v := range vals {
		remove[v.GetKey().GetKeyString()] = struct{}{}
	}
	for i := len(m.TotalGpus); i >= 0; i-- {
		if _, found := remove[m.TotalGpus[i].GetKey().GetKeyString()]; found {
			m.TotalGpus = append(m.TotalGpus[:i], m.TotalGpus[i+1:]...)
			changes++
		}
	}
	return changes
}

func (m *NodePoolResources) CopyInFields(src *NodePoolResources) int {
	updateListAction := "replace"
	changed := 0
	if m.TotalVcpus.Whole != src.TotalVcpus.Whole {
		m.TotalVcpus.Whole = src.TotalVcpus.Whole
		changed++
	}
	if m.TotalVcpus.Nanos != src.TotalVcpus.Nanos {
		m.TotalVcpus.Nanos = src.TotalVcpus.Nanos
		changed++
	}
	if m.TotalMemory != src.TotalMemory {
		m.TotalMemory = src.TotalMemory
		changed++
	}
	if m.TotalDisk != src.TotalDisk {
		m.TotalDisk = src.TotalDisk
		changed++
	}
	if src.TotalOptRes != nil {
		if updateListAction == "add" {
			for k0, v := range src.TotalOptRes {
				m.TotalOptRes[k0] = v
				changed++
			}
		} else if updateListAction == "remove" {
			for k0, _ := range src.TotalOptRes {
				if _, ok := m.TotalOptRes[k0]; ok {
					delete(m.TotalOptRes, k0)
					changed++
				}
			}
		} else {
			m.TotalOptRes = make(map[string]string)
			for k0, v := range src.TotalOptRes {
				m.TotalOptRes[k0] = v
			}
			changed++
		}
	} else if m.TotalOptRes != nil {
		m.TotalOptRes = nil
		changed++
	}
	if m.Topology.MinNodeVcpus != src.Topology.MinNodeVcpus {
		m.Topology.MinNodeVcpus = src.Topology.MinNodeVcpus
		changed++
	}
	if m.Topology.MinNodeMemory != src.Topology.MinNodeMemory {
		m.Topology.MinNodeMemory = src.Topology.MinNodeMemory
		changed++
	}
	if m.Topology.MinNodeDisk != src.Topology.MinNodeDisk {
		m.Topology.MinNodeDisk = src.Topology.MinNodeDisk
		changed++
	}
	if src.Topology.MinNodeOptRes != nil {
		if updateListAction == "add" {
			for k1, v := range src.Topology.MinNodeOptRes {
				m.Topology.MinNodeOptRes[k1] = v
				changed++
			}
		} else if updateListAction == "remove" {
			for k1, _ := range src.Topology.MinNodeOptRes {
				if _, ok := m.Topology.MinNodeOptRes[k1]; ok {
					delete(m.Topology.MinNodeOptRes, k1)
					changed++
				}
			}
		} else {
			m.Topology.MinNodeOptRes = make(map[string]string)
			for k1, v := range src.Topology.MinNodeOptRes {
				m.Topology.MinNodeOptRes[k1] = v
			}
			changed++
		}
	} else if m.Topology.MinNodeOptRes != nil {
		m.Topology.MinNodeOptRes = nil
		changed++
	}
	if m.Topology.MinNumberOfNodes != src.Topology.MinNumberOfNodes {
		m.Topology.MinNumberOfNodes = src.Topology.MinNumberOfNodes
		changed++
	}
	if src.Topology.MinNodeGpus != nil {
		if updateListAction == "add" {
			changed += m.AddTopologyMinNodeGpus(src.Topology.MinNodeGpus...)
		} else if updateListAction == "remove" {
			changed += m.RemoveTopologyMinNodeGpus(src.Topology.MinNodeGpus...)
		} else {
			m.Topology.MinNodeGpus = make([]*GPUResource, 0)
			for k1, _ := range src.Topology.MinNodeGpus {
				m.Topology.MinNodeGpus = append(m.Topology.MinNodeGpus, src.Topology.MinNodeGpus[k1].Clone())
			}
			changed++
		}
	} else if m.Topology.MinNodeGpus != nil {
		m.Topology.MinNodeGpus = nil
		changed++
	}
	if src.TotalGpus != nil {
		if updateListAction == "add" {
			changed += m.AddTotalGpus(src.TotalGpus...)
		} else if updateListAction == "remove" {
			changed += m.RemoveTotalGpus(src.TotalGpus...)
		} else {
			m.TotalGpus = make([]*GPUResource, 0)
			for k0, _ := range src.TotalGpus {
				m.TotalGpus = append(m.TotalGpus, src.TotalGpus[k0].Clone())
			}
			changed++
		}
	} else if m.TotalGpus != nil {
		m.TotalGpus = nil
		changed++
	}
	return changed
}

func (m *NodePoolResources) DeepCopyIn(src *NodePoolResources) {
	m.TotalVcpus.DeepCopyIn(&src.TotalVcpus)
	m.TotalMemory = src.TotalMemory
	m.TotalDisk = src.TotalDisk
	if src.TotalOptRes != nil {
		m.TotalOptRes = make(map[string]string)
		for k, v := range src.TotalOptRes {
			m.TotalOptRes[k] = v
		}
	} else {
		m.TotalOptRes = nil
	}
	m.Topology.DeepCopyIn(&src.Topology)
	if src.TotalGpus != nil {
		m.TotalGpus = make([]*GPUResource, len(src.TotalGpus), len(src.TotalGpus))
		for ii, s := range src.TotalGpus {
			var tmp_s GPUResource
			tmp_s.DeepCopyIn(s)
			m.TotalGpus[ii] = &tmp_s
		}
	} else {
		m.TotalGpus = nil
	}
}

// Helper method to check that enums have valid values
func (m *NodePoolResources) ValidateEnums() error {
	if err := m.TotalVcpus.ValidateEnums(); err != nil {
		return err
	}
	if err := m.Topology.ValidateEnums(); err != nil {
		return err
	}
	for _, e := range m.TotalGpus {
		if err := e.ValidateEnums(); err != nil {
			return err
		}
	}
	return nil
}

func (s *NodePoolResources) ClearTagged(tags map[string]struct{}) {
	s.TotalVcpus.ClearTagged(tags)
	s.Topology.ClearTagged(tags)
	if s.TotalGpus != nil {
		for ii := 0; ii < len(s.TotalGpus); ii++ {
			s.TotalGpus[ii].ClearTagged(tags)
		}
	}
}

func (m *NodePoolTopology) Clone() *NodePoolTopology {
	cp := &NodePoolTopology{}
	cp.DeepCopyIn(m)
	return cp
}

func (m *NodePoolTopology) AddMinNodeGpus(vals ...*GPUResource) int {
	changes := 0
	cur := make(map[string]struct{})
	for _, v := range m.MinNodeGpus {
		cur[v.GetKey().GetKeyString()] = struct{}{}
	}
	for _, v := range vals {
		if _, found := cur[v.GetKey().GetKeyString()]; found {
			continue // duplicate
		}
		m.MinNodeGpus = append(m.MinNodeGpus, v)
		changes++
	}
	return changes
}

func (m *NodePoolTopology) RemoveMinNodeGpus(vals ...*GPUResource) int {
	changes := 0
	remove := make(map[string]struct{})
	for _, v := range vals {
		remove[v.GetKey().GetKeyString()] = struct{}{}
	}
	for i := len(m.MinNodeGpus); i >= 0; i-- {
		if _, found := remove[m.MinNodeGpus[i].GetKey().GetKeyString()]; found {
			m.MinNodeGpus = append(m.MinNodeGpus[:i], m.MinNodeGpus[i+1:]...)
			changes++
		}
	}
	return changes
}

func (m *NodePoolTopology) CopyInFields(src *NodePoolTopology) int {
	updateListAction := "replace"
	changed := 0
	if m.MinNodeVcpus != src.MinNodeVcpus {
		m.MinNodeVcpus = src.MinNodeVcpus
		changed++
	}
	if m.MinNodeMemory != src.MinNodeMemory {
		m.MinNodeMemory = src.MinNodeMemory
		changed++
	}
	if m.MinNodeDisk != src.MinNodeDisk {
		m.MinNodeDisk = src.MinNodeDisk
		changed++
	}
	if src.MinNodeOptRes != nil {
		if updateListAction == "add" {
			for k0, v := range src.MinNodeOptRes {
				m.MinNodeOptRes[k0] = v
				changed++
			}
		} else if updateListAction == "remove" {
			for k0, _ := range src.MinNodeOptRes {
				if _, ok := m.MinNodeOptRes[k0]; ok {
					delete(m.MinNodeOptRes, k0)
					changed++
				}
			}
		} else {
			m.MinNodeOptRes = make(map[string]string)
			for k0, v := range src.MinNodeOptRes {
				m.MinNodeOptRes[k0] = v
			}
			changed++
		}
	} else if m.MinNodeOptRes != nil {
		m.MinNodeOptRes = nil
		changed++
	}
	if m.MinNumberOfNodes != src.MinNumberOfNodes {
		m.MinNumberOfNodes = src.MinNumberOfNodes
		changed++
	}
	if src.MinNodeGpus != nil {
		if updateListAction == "add" {
			changed += m.AddMinNodeGpus(src.MinNodeGpus...)
		} else if updateListAction == "remove" {
			changed += m.RemoveMinNodeGpus(src.MinNodeGpus...)
		} else {
			m.MinNodeGpus = make([]*GPUResource, 0)
			for k0, _ := range src.MinNodeGpus {
				m.MinNodeGpus = append(m.MinNodeGpus, src.MinNodeGpus[k0].Clone())
			}
			changed++
		}
	} else if m.MinNodeGpus != nil {
		m.MinNodeGpus = nil
		changed++
	}
	return changed
}

func (m *NodePoolTopology) DeepCopyIn(src *NodePoolTopology) {
	m.MinNodeVcpus = src.MinNodeVcpus
	m.MinNodeMemory = src.MinNodeMemory
	m.MinNodeDisk = src.MinNodeDisk
	if src.MinNodeOptRes != nil {
		m.MinNodeOptRes = make(map[string]string)
		for k, v := range src.MinNodeOptRes {
			m.MinNodeOptRes[k] = v
		}
	} else {
		m.MinNodeOptRes = nil
	}
	m.MinNumberOfNodes = src.MinNumberOfNodes
	if src.MinNodeGpus != nil {
		m.MinNodeGpus = make([]*GPUResource, len(src.MinNodeGpus), len(src.MinNodeGpus))
		for ii, s := range src.MinNodeGpus {
			var tmp_s GPUResource
			tmp_s.DeepCopyIn(s)
			m.MinNodeGpus[ii] = &tmp_s
		}
	} else {
		m.MinNodeGpus = nil
	}
}

// Helper method to check that enums have valid values
func (m *NodePoolTopology) ValidateEnums() error {
	for _, e := range m.MinNodeGpus {
		if err := e.ValidateEnums(); err != nil {
			return err
		}
	}
	return nil
}

func (s *NodePoolTopology) ClearTagged(tags map[string]struct{}) {
	if s.MinNodeGpus != nil {
		for ii := 0; ii < len(s.MinNodeGpus); ii++ {
			s.MinNodeGpus[ii].ClearTagged(tags)
		}
	}
}

func (m *NodePool) Clone() *NodePool {
	cp := &NodePool{}
	cp.DeepCopyIn(m)
	return cp
}

func (m *NodePool) AddNodeResourcesGpus(vals ...*GPUResource) int {
	changes := 0
	cur := make(map[string]struct{})
	for _, v := range m.NodeResources.Gpus {
		cur[v.GetKey().GetKeyString()] = struct{}{}
	}
	for _, v := range vals {
		if _, found := cur[v.GetKey().GetKeyString()]; found {
			continue // duplicate
		}
		m.NodeResources.Gpus = append(m.NodeResources.Gpus, v)
		changes++
	}
	return changes
}

func (m *NodePool) RemoveNodeResourcesGpus(vals ...*GPUResource) int {
	changes := 0
	remove := make(map[string]struct{})
	for _, v := range vals {
		remove[v.GetKey().GetKeyString()] = struct{}{}
	}
	for i := len(m.NodeResources.Gpus); i >= 0; i-- {
		if _, found := remove[m.NodeResources.Gpus[i].GetKey().GetKeyString()]; found {
			m.NodeResources.Gpus = append(m.NodeResources.Gpus[:i], m.NodeResources.Gpus[i+1:]...)
			changes++
		}
	}
	return changes
}

func (m *NodePool) AddNodes(vals ...string) int {
	changes := 0
	cur := make(map[string]struct{})
	for _, v := range m.Nodes {
		cur[v] = struct{}{}
	}
	for _, v := range vals {
		if _, found := cur[v]; found {
			continue // duplicate
		}
		m.Nodes = append(m.Nodes, v)
		changes++
	}
	return changes
}

func (m *NodePool) RemoveNodes(vals ...string) int {
	changes := 0
	remove := make(map[string]struct{})
	for _, v := range vals {
		remove[v] = struct{}{}
	}
	for i := len(m.Nodes); i >= 0; i-- {
		if _, found := remove[m.Nodes[i]]; found {
			m.Nodes = append(m.Nodes[:i], m.Nodes[i+1:]...)
			changes++
		}
	}
	return changes
}

func (m *NodePool) CopyInFields(src *NodePool) int {
	updateListAction := "replace"
	changed := 0
	if m.Name != src.Name {
		m.Name = src.Name
		changed++
	}
	if m.NumNodes != src.NumNodes {
		m.NumNodes = src.NumNodes
		changed++
	}
	if src.NodeResources != nil {
		if m.NodeResources == nil {
			m.NodeResources = &NodeResources{}
		}
		if m.NodeResources.Vcpus != src.NodeResources.Vcpus {
			m.NodeResources.Vcpus = src.NodeResources.Vcpus
			changed++
		}
		if m.NodeResources.Ram != src.NodeResources.Ram {
			m.NodeResources.Ram = src.NodeResources.Ram
			changed++
		}
		if m.NodeResources.Disk != src.NodeResources.Disk {
			m.NodeResources.Disk = src.NodeResources.Disk
			changed++
		}
		if src.NodeResources.OptResMap != nil {
			if updateListAction == "add" {
				for k1, v := range src.NodeResources.OptResMap {
					m.NodeResources.OptResMap[k1] = v
					changed++
				}
			} else if updateListAction == "remove" {
				for k1, _ := range src.NodeResources.OptResMap {
					if _, ok := m.NodeResources.OptResMap[k1]; ok {
						delete(m.NodeResources.OptResMap, k1)
						changed++
					}
				}
			} else {
				m.NodeResources.OptResMap = make(map[string]string)
				for k1, v := range src.NodeResources.OptResMap {
					m.NodeResources.OptResMap[k1] = v
				}
				changed++
			}
		} else if m.NodeResources.OptResMap != nil {
			m.NodeResources.OptResMap = nil
			changed++
		}
		if m.NodeResources.InfraNodeFlavor != src.NodeResources.InfraNodeFlavor {
			m.NodeResources.InfraNodeFlavor = src.NodeResources.InfraNodeFlavor
			changed++
		}
		if m.NodeResources.ExternalVolumeSize != src.NodeResources.ExternalVolumeSize {
			m.NodeResources.ExternalVolumeSize = src.NodeResources.ExternalVolumeSize
			changed++
		}
		if src.NodeResources.Gpus != nil {
			if updateListAction == "add" {
				changed += m.AddNodeResourcesGpus(src.NodeResources.Gpus...)
			} else if updateListAction == "remove" {
				changed += m.RemoveNodeResourcesGpus(src.NodeResources.Gpus...)
			} else {
				m.NodeResources.Gpus = make([]*GPUResource, 0)
				for k1, _ := range src.NodeResources.Gpus {
					m.NodeResources.Gpus = append(m.NodeResources.Gpus, src.NodeResources.Gpus[k1].Clone())
				}
				changed++
			}
		} else if m.NodeResources.Gpus != nil {
			m.NodeResources.Gpus = nil
			changed++
		}
		if m.NodeResources.NodeName != src.NodeResources.NodeName {
			m.NodeResources.NodeName = src.NodeResources.NodeName
			changed++
		}
	} else if m.NodeResources != nil {
		m.NodeResources = nil
		changed++
	}
	if m.Scalable != src.Scalable {
		m.Scalable = src.Scalable
		changed++
	}
	if m.ControlPlane != src.ControlPlane {
		m.ControlPlane = src.ControlPlane
		changed++
	}
	if src.Nodes != nil {
		if updateListAction == "add" {
			changed += m.AddNodes(src.Nodes...)
		} else if updateListAction == "remove" {
			changed += m.RemoveNodes(src.Nodes...)
		} else {
			m.Nodes = make([]string, 0)
			m.Nodes = append(m.Nodes, src.Nodes...)
			changed++
		}
	} else if m.Nodes != nil {
		m.Nodes = nil
		changed++
	}
	return changed
}

func (m *NodePool) DeepCopyIn(src *NodePool) {
	m.Name = src.Name
	m.NumNodes = src.NumNodes
	if src.NodeResources != nil {
		var tmp_NodeResources NodeResources
		tmp_NodeResources.DeepCopyIn(src.NodeResources)
		m.NodeResources = &tmp_NodeResources
	} else {
		m.NodeResources = nil
	}
	m.Scalable = src.Scalable
	m.ControlPlane = src.ControlPlane
	if src.Nodes != nil {
		m.Nodes = make([]string, len(src.Nodes), len(src.Nodes))
		for ii, s := range src.Nodes {
			m.Nodes[ii] = s
		}
	} else {
		m.Nodes = nil
	}
}

// Helper method to check that enums have valid values
func (m *NodePool) ValidateEnums() error {
	if m.NodeResources != nil {
		if err := m.NodeResources.ValidateEnums(); err != nil {
			return err
		}
	}
	return nil
}

func (s *NodePool) ClearTagged(tags map[string]struct{}) {
	if s.NodeResources != nil {
		s.NodeResources.ClearTagged(tags)
	}
}

func (m *GPUResource) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.ModelId)
	if l > 0 {
		n += 1 + l + sovResources(uint64(l))
	}
	if m.Count != 0 {
		n += 1 + sovResources(uint64(m.Count))
	}
	l = len(m.Vendor)
	if l > 0 {
		n += 1 + l + sovResources(uint64(l))
	}
	if m.Memory != 0 {
		n += 1 + sovResources(uint64(m.Memory))
	}
	if m.InUse != 0 {
		n += 1 + sovResources(uint64(m.InUse))
	}
	return n
}

func (m *NodeResources) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Vcpus != 0 {
		n += 1 + sovResources(uint64(m.Vcpus))
	}
	if m.Ram != 0 {
		n += 1 + sovResources(uint64(m.Ram))
	}
	if m.Disk != 0 {
		n += 1 + sovResources(uint64(m.Disk))
	}
	if len(m.OptResMap) > 0 {
		for k, v := range m.OptResMap {
			_ = k
			_ = v
			mapEntrySize := 1 + len(k) + sovResources(uint64(len(k))) + 1 + len(v) + sovResources(uint64(len(v)))
			n += mapEntrySize + 1 + sovResources(uint64(mapEntrySize))
		}
	}
	l = len(m.InfraNodeFlavor)
	if l > 0 {
		n += 1 + l + sovResources(uint64(l))
	}
	if m.ExternalVolumeSize != 0 {
		n += 1 + sovResources(uint64(m.ExternalVolumeSize))
	}
	if len(m.Gpus) > 0 {
		for _, e := range m.Gpus {
			l = e.Size()
			n += 1 + l + sovResources(uint64(l))
		}
	}
	l = len(m.NodeName)
	if l > 0 {
		n += 1 + l + sovResources(uint64(l))
	}
	return n
}

func (m *KubernetesResources) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.CpuPool != nil {
		l = m.CpuPool.Size()
		n += 1 + l + sovResources(uint64(l))
	}
	if m.GpuPool != nil {
		l = m.GpuPool.Size()
		n += 1 + l + sovResources(uint64(l))
	}
	l = len(m.MinKubernetesVersion)
	if l > 0 {
		n += 1 + l + sovResources(uint64(l))
	}
	return n
}

func (m *NodePoolResources) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = m.TotalVcpus.Size()
	n += 1 + l + sovResources(uint64(l))
	if m.TotalMemory != 0 {
		n += 1 + sovResources(uint64(m.TotalMemory))
	}
	if m.TotalDisk != 0 {
		n += 1 + sovResources(uint64(m.TotalDisk))
	}
	if len(m.TotalOptRes) > 0 {
		for k, v := range m.TotalOptRes {
			_ = k
			_ = v
			mapEntrySize := 1 + len(k) + sovResources(uint64(len(k))) + 1 + len(v) + sovResources(uint64(len(v)))
			n += mapEntrySize + 1 + sovResources(uint64(mapEntrySize))
		}
	}
	l = m.Topology.Size()
	n += 1 + l + sovResources(uint64(l))
	if len(m.TotalGpus) > 0 {
		for _, e := range m.TotalGpus {
			l = e.Size()
			n += 1 + l + sovResources(uint64(l))
		}
	}
	return n
}

func (m *NodePoolTopology) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.MinNodeVcpus != 0 {
		n += 1 + sovResources(uint64(m.MinNodeVcpus))
	}
	if m.MinNodeMemory != 0 {
		n += 1 + sovResources(uint64(m.MinNodeMemory))
	}
	if m.MinNodeDisk != 0 {
		n += 1 + sovResources(uint64(m.MinNodeDisk))
	}
	if len(m.MinNodeOptRes) > 0 {
		for k, v := range m.MinNodeOptRes {
			_ = k
			_ = v
			mapEntrySize := 1 + len(k) + sovResources(uint64(len(k))) + 1 + len(v) + sovResources(uint64(len(v)))
			n += mapEntrySize + 1 + sovResources(uint64(mapEntrySize))
		}
	}
	if m.MinNumberOfNodes != 0 {
		n += 1 + sovResources(uint64(m.MinNumberOfNodes))
	}
	if len(m.MinNodeGpus) > 0 {
		for _, e := range m.MinNodeGpus {
			l = e.Size()
			n += 1 + l + sovResources(uint64(l))
		}
	}
	return n
}

func (m *NodePool) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.Name)
	if l > 0 {
		n += 1 + l + sovResources(uint64(l))
	}
	if m.NumNodes != 0 {
		n += 1 + sovResources(uint64(m.NumNodes))
	}
	if m.NodeResources != nil {
		l = m.NodeResources.Size()
		n += 1 + l + sovResources(uint64(l))
	}
	if m.Scalable {
		n += 2
	}
	if m.ControlPlane {
		n += 2
	}
	if len(m.Nodes) > 0 {
		for _, s := range m.Nodes {
			l = len(s)
			n += 1 + l + sovResources(uint64(l))
		}
	}
	return n
}

func sovResources(x uint64) (n int) {
	return (math_bits.Len64(x|1) + 6) / 7
}
func sozResources(x uint64) (n int) {
	return sovResources(uint64((x << 1) ^ uint64((int64(x) >> 63))))
}
func (m *GPUResource) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowResources
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: GPUResource: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: GPUResource: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ModelId", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthResources
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthResources
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ModelId = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Count", wireType)
			}
			m.Count = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Count |= uint32(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Vendor", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthResources
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthResources
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Vendor = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Memory", wireType)
			}
			m.Memory = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Memory |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field InUse", wireType)
			}
			m.InUse = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.InUse |= uint32(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipResources(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthResources
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *NodeResources) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowResources
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: NodeResources: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: NodeResources: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Vcpus", wireType)
			}
			m.Vcpus = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Vcpus |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Ram", wireType)
			}
			m.Ram = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Ram |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Disk", wireType)
			}
			m.Disk = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Disk |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OptResMap", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthResources
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthResources
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.OptResMap == nil {
				m.OptResMap = make(map[string]string)
			}
			var mapkey string
			var mapvalue string
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowResources
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					var stringLenmapkey uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowResources
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapkey |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapkey := int(stringLenmapkey)
					if intStringLenmapkey < 0 {
						return ErrInvalidLengthResources
					}
					postStringIndexmapkey := iNdEx + intStringLenmapkey
					if postStringIndexmapkey < 0 {
						return ErrInvalidLengthResources
					}
					if postStringIndexmapkey > l {
						return io.ErrUnexpectedEOF
					}
					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
					iNdEx = postStringIndexmapkey
				} else if fieldNum == 2 {
					var stringLenmapvalue uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowResources
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapvalue |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapvalue := int(stringLenmapvalue)
					if intStringLenmapvalue < 0 {
						return ErrInvalidLengthResources
					}
					postStringIndexmapvalue := iNdEx + intStringLenmapvalue
					if postStringIndexmapvalue < 0 {
						return ErrInvalidLengthResources
					}
					if postStringIndexmapvalue > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = string(dAtA[iNdEx:postStringIndexmapvalue])
					iNdEx = postStringIndexmapvalue
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipResources(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthResources
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.OptResMap[mapkey] = mapvalue
			iNdEx = postIndex
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field InfraNodeFlavor", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthResources
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthResources
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.InfraNodeFlavor = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 6:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ExternalVolumeSize", wireType)
			}
			m.ExternalVolumeSize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ExternalVolumeSize |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 7:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Gpus", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthResources
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthResources
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Gpus = append(m.Gpus, &GPUResource{})
			if err := m.Gpus[len(m.Gpus)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 8:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field NodeName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthResources
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthResources
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.NodeName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipResources(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthResources
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *KubernetesResources) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowResources
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: KubernetesResources: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: KubernetesResources: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field CpuPool", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthResources
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthResources
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.CpuPool == nil {
				m.CpuPool = &NodePoolResources{}
			}
			if err := m.CpuPool.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field GpuPool", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthResources
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthResources
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.GpuPool == nil {
				m.GpuPool = &NodePoolResources{}
			}
			if err := m.GpuPool.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field MinKubernetesVersion", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthResources
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthResources
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.MinKubernetesVersion = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipResources(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthResources
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *NodePoolResources) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowResources
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: NodePoolResources: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: NodePoolResources: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TotalVcpus", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthResources
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthResources
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.TotalVcpus.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field TotalMemory", wireType)
			}
			m.TotalMemory = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.TotalMemory |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field TotalDisk", wireType)
			}
			m.TotalDisk = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.TotalDisk |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TotalOptRes", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthResources
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthResources
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.TotalOptRes == nil {
				m.TotalOptRes = make(map[string]string)
			}
			var mapkey string
			var mapvalue string
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowResources
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					var stringLenmapkey uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowResources
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapkey |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapkey := int(stringLenmapkey)
					if intStringLenmapkey < 0 {
						return ErrInvalidLengthResources
					}
					postStringIndexmapkey := iNdEx + intStringLenmapkey
					if postStringIndexmapkey < 0 {
						return ErrInvalidLengthResources
					}
					if postStringIndexmapkey > l {
						return io.ErrUnexpectedEOF
					}
					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
					iNdEx = postStringIndexmapkey
				} else if fieldNum == 2 {
					var stringLenmapvalue uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowResources
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapvalue |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapvalue := int(stringLenmapvalue)
					if intStringLenmapvalue < 0 {
						return ErrInvalidLengthResources
					}
					postStringIndexmapvalue := iNdEx + intStringLenmapvalue
					if postStringIndexmapvalue < 0 {
						return ErrInvalidLengthResources
					}
					if postStringIndexmapvalue > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = string(dAtA[iNdEx:postStringIndexmapvalue])
					iNdEx = postStringIndexmapvalue
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipResources(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthResources
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.TotalOptRes[mapkey] = mapvalue
			iNdEx = postIndex
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Topology", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthResources
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthResources
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Topology.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 6:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TotalGpus", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthResources
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthResources
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.TotalGpus = append(m.TotalGpus, &GPUResource{})
			if err := m.TotalGpus[len(m.TotalGpus)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipResources(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthResources
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *NodePoolTopology) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowResources
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: NodePoolTopology: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: NodePoolTopology: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field MinNodeVcpus", wireType)
			}
			m.MinNodeVcpus = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.MinNodeVcpus |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field MinNodeMemory", wireType)
			}
			m.MinNodeMemory = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.MinNodeMemory |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field MinNodeDisk", wireType)
			}
			m.MinNodeDisk = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.MinNodeDisk |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field MinNodeOptRes", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthResources
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthResources
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.MinNodeOptRes == nil {
				m.MinNodeOptRes = make(map[string]string)
			}
			var mapkey string
			var mapvalue string
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowResources
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					var stringLenmapkey uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowResources
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapkey |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapkey := int(stringLenmapkey)
					if intStringLenmapkey < 0 {
						return ErrInvalidLengthResources
					}
					postStringIndexmapkey := iNdEx + intStringLenmapkey
					if postStringIndexmapkey < 0 {
						return ErrInvalidLengthResources
					}
					if postStringIndexmapkey > l {
						return io.ErrUnexpectedEOF
					}
					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
					iNdEx = postStringIndexmapkey
				} else if fieldNum == 2 {
					var stringLenmapvalue uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowResources
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapvalue |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapvalue := int(stringLenmapvalue)
					if intStringLenmapvalue < 0 {
						return ErrInvalidLengthResources
					}
					postStringIndexmapvalue := iNdEx + intStringLenmapvalue
					if postStringIndexmapvalue < 0 {
						return ErrInvalidLengthResources
					}
					if postStringIndexmapvalue > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = string(dAtA[iNdEx:postStringIndexmapvalue])
					iNdEx = postStringIndexmapvalue
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipResources(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthResources
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.MinNodeOptRes[mapkey] = mapvalue
			iNdEx = postIndex
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field MinNumberOfNodes", wireType)
			}
			m.MinNumberOfNodes = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.MinNumberOfNodes |= int32(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 6:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field MinNodeGpus", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthResources
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthResources
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.MinNodeGpus = append(m.MinNodeGpus, &GPUResource{})
			if err := m.MinNodeGpus[len(m.MinNodeGpus)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipResources(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthResources
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *NodePool) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowResources
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: NodePool: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: NodePool: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Name", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthResources
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthResources
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Name = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field NumNodes", wireType)
			}
			m.NumNodes = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.NumNodes |= uint32(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field NodeResources", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthResources
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthResources
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.NodeResources == nil {
				m.NodeResources = &NodeResources{}
			}
			if err := m.NodeResources.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Scalable", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.Scalable = bool(v != 0)
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ControlPlane", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.ControlPlane = bool(v != 0)
		case 6:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Nodes", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowResources
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthResources
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthResources
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Nodes = append(m.Nodes, string(dAtA[iNdEx:postIndex]))
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipResources(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthResources
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func skipResources(dAtA []byte) (n int, err error) {
	l := len(dAtA)
	iNdEx := 0
	depth := 0
	for iNdEx < l {
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return 0, ErrIntOverflowResources
			}
			if iNdEx >= l {
				return 0, io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		wireType := int(wire & 0x7)
		switch wireType {
		case 0:
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowResources
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				iNdEx++
				if dAtA[iNdEx-1] < 0x80 {
					break
				}
			}
		case 1:
			iNdEx += 8
		case 2:
			var length int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowResources
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				length |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if length < 0 {
				return 0, ErrInvalidLengthResources
			}
			iNdEx += length
		case 3:
			depth++
		case 4:
			if depth == 0 {
				return 0, ErrUnexpectedEndOfGroupResources
			}
			depth--
		case 5:
			iNdEx += 4
		default:
			return 0, fmt.Errorf("proto: illegal wireType %d", wireType)
		}
		if iNdEx < 0 {
			return 0, ErrInvalidLengthResources
		}
		if depth == 0 {
			return iNdEx, nil
		}
	}
	return 0, io.ErrUnexpectedEOF
}

var (
	ErrInvalidLengthResources        = fmt.Errorf("proto: negative length found during unmarshaling")
	ErrIntOverflowResources          = fmt.Errorf("proto: integer overflow")
	ErrUnexpectedEndOfGroupResources = fmt.Errorf("proto: unexpected end of group")
)
