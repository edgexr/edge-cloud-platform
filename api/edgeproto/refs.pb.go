// Code generated by protoc-gen-gogo. DO NOT EDIT.
// source: refs.proto

package edgeproto

import (
	context "context"
	encoding_binary "encoding/binary"
	"encoding/json"
	fmt "fmt"
	"github.com/edgexr/edge-cloud-platform/pkg/log"
	"github.com/edgexr/edge-cloud-platform/pkg/objstore"
	"github.com/edgexr/edge-cloud-platform/pkg/util"
	_ "github.com/edgexr/edge-cloud-platform/tools/protogen"
	_ "github.com/gogo/protobuf/gogoproto"
	proto "github.com/gogo/protobuf/proto"
	"go.etcd.io/etcd/client/v3/concurrency"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
	io "io"
	math "math"
	math_bits "math/bits"
	"sort"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.GoGoProtoPackageIsVersion3 // please upgrade the proto package

// VMResource
//
// VMResource specifies the resource requirement of a VM
type VMResource struct {
	// ClusterInstKey to track which cluster this VM resource belongs to
	Key ClusterKey `protobuf:"bytes,1,opt,name=key,proto3" json:"key"`
	// Infrastructure specific flavor of the VM
	VmFlavor string `protobuf:"bytes,2,opt,name=vm_flavor,json=vmFlavor,proto3" json:"vm_flavor,omitempty"`
	// Resource Type can be platform, rootlb, cluster-master, cluster-k8s-node, cluster-docker-node, appvm, k8s-lb-svc
	Type string `protobuf:"bytes,3,opt,name=type,proto3" json:"type,omitempty"`
	// Number of these VMs in cluster
	Count uint32 `protobuf:"varint,5,opt,name=count,proto3" json:"count,omitempty"`
}

func (m *VMResource) Reset()         { *m = VMResource{} }
func (m *VMResource) String() string { return proto.CompactTextString(m) }
func (*VMResource) ProtoMessage()    {}
func (*VMResource) Descriptor() ([]byte, []int) {
	return fileDescriptor_6435a763ece979c6, []int{0}
}
func (m *VMResource) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *VMResource) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_VMResource.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *VMResource) XXX_Merge(src proto.Message) {
	xxx_messageInfo_VMResource.Merge(m, src)
}
func (m *VMResource) XXX_Size() int {
	return m.Size()
}
func (m *VMResource) XXX_DiscardUnknown() {
	xxx_messageInfo_VMResource.DiscardUnknown(m)
}

var xxx_messageInfo_VMResource proto.InternalMessageInfo

// CloudletRefs track used resources and Clusters instantiated on a Cloudlet. Used resources are compared against max resources for a Cloudlet to determine if resources are available for a new Cluster to be instantiated on the Cloudlet.
type CloudletRefs struct {
	// Cloudlet key
	Key CloudletKey `protobuf:"bytes,1,opt,name=key,proto3" json:"key"`
	// Used ports on root load balancer. Map key is public port, value is a bitmap for the protocol
	// bitmap: bit 0: tcp, bit 1: udp
	RootLbPorts map[int32]int32 `protobuf:"bytes,8,rep,name=root_lb_ports,json=rootLbPorts,proto3" json:"root_lb_ports,omitempty" protobuf_key:"varint,1,opt,name=key,proto3" protobuf_val:"varint,2,opt,name=value,proto3"`
	// Used dynamic IPs
	UsedDynamicIps int32 `protobuf:"varint,9,opt,name=used_dynamic_ips,json=usedDynamicIps,proto3" json:"used_dynamic_ips,omitempty"`
	// Used static IPs
	UsedStaticIps string `protobuf:"bytes,10,opt,name=used_static_ips,json=usedStaticIps,proto3" json:"used_static_ips,omitempty"`
	// Used Optional Resources
	OptResUsedMap map[string]uint32 `protobuf:"bytes,11,rep,name=opt_res_used_map,json=optResUsedMap,proto3" json:"opt_res_used_map,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"varint,2,opt,name=value,proto3"`
	// Track reservable autoclusterinsts ids in use. This is a bitmap.
	ReservedAutoClusterIds uint64 `protobuf:"fixed64,12,opt,name=reserved_auto_cluster_ids,json=reservedAutoClusterIds,proto3" json:"reserved_auto_cluster_ids,omitempty"`
	// Clusters instantiated on the Cloudlet
	ClusterInsts []ClusterKey `protobuf:"bytes,13,rep,name=cluster_insts,json=clusterInsts,proto3" json:"cluster_insts"`
	// VM apps instantiated on the Cloudlet
	VmAppInsts []AppInstKey `protobuf:"bytes,14,rep,name=vm_app_insts,json=vmAppInsts,proto3" json:"vm_app_insts"`
	// (_deprecated_) Track k8s appinsts on clusterRefs instead. Previously K8s apps instantiated on the Cloudlet
	K8SAppInsts []AppInstKey `protobuf:"bytes,15,rep,name=k8s_app_insts,json=k8sAppInsts,proto3" json:"k8s_app_insts"`
}

func (m *CloudletRefs) Reset()         { *m = CloudletRefs{} }
func (m *CloudletRefs) String() string { return proto.CompactTextString(m) }
func (*CloudletRefs) ProtoMessage()    {}
func (*CloudletRefs) Descriptor() ([]byte, []int) {
	return fileDescriptor_6435a763ece979c6, []int{1}
}
func (m *CloudletRefs) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *CloudletRefs) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_CloudletRefs.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *CloudletRefs) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CloudletRefs.Merge(m, src)
}
func (m *CloudletRefs) XXX_Size() int {
	return m.Size()
}
func (m *CloudletRefs) XXX_DiscardUnknown() {
	xxx_messageInfo_CloudletRefs.DiscardUnknown(m)
}

var xxx_messageInfo_CloudletRefs proto.InternalMessageInfo

// ClusterRefs track used resources within a ClusterInst. Each AppInst specifies a set of required resources (Flavor), so tracking resources used by Apps within a Cluster is necessary to determine if enough resources are available for another AppInst to be instantiated on a ClusterInst.
type ClusterRefs struct {
	// Cluster Instance key
	Key ClusterKey `protobuf:"bytes,1,opt,name=key,proto3" json:"key"`
	// App instances in the Cluster Instance
	Apps []AppInstKey `protobuf:"bytes,2,rep,name=apps,proto3" json:"apps"`
}

func (m *ClusterRefs) Reset()         { *m = ClusterRefs{} }
func (m *ClusterRefs) String() string { return proto.CompactTextString(m) }
func (*ClusterRefs) ProtoMessage()    {}
func (*ClusterRefs) Descriptor() ([]byte, []int) {
	return fileDescriptor_6435a763ece979c6, []int{2}
}
func (m *ClusterRefs) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *ClusterRefs) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_ClusterRefs.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *ClusterRefs) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ClusterRefs.Merge(m, src)
}
func (m *ClusterRefs) XXX_Size() int {
	return m.Size()
}
func (m *ClusterRefs) XXX_DiscardUnknown() {
	xxx_messageInfo_ClusterRefs.DiscardUnknown(m)
}

var xxx_messageInfo_ClusterRefs proto.InternalMessageInfo

type AppInstRefs struct {
	// App key
	Key AppKey `protobuf:"bytes,1,opt,name=key,proto3" json:"key"`
	// AppInsts for App (key is JSON of AppInst Key)
	Insts map[string]uint32 `protobuf:"bytes,2,rep,name=insts,proto3" json:"insts" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"varint,2,opt,name=value,proto3"`
	// AppInsts being deleted (key is JSON of AppInst Key)
	DeleteRequestedInsts map[string]uint32 `protobuf:"bytes,3,rep,name=delete_requested_insts,json=deleteRequestedInsts,proto3" json:"delete_requested_insts" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"varint,2,opt,name=value,proto3"`
}

func (m *AppInstRefs) Reset()         { *m = AppInstRefs{} }
func (m *AppInstRefs) String() string { return proto.CompactTextString(m) }
func (*AppInstRefs) ProtoMessage()    {}
func (*AppInstRefs) Descriptor() ([]byte, []int) {
	return fileDescriptor_6435a763ece979c6, []int{3}
}
func (m *AppInstRefs) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *AppInstRefs) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_AppInstRefs.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *AppInstRefs) XXX_Merge(src proto.Message) {
	xxx_messageInfo_AppInstRefs.Merge(m, src)
}
func (m *AppInstRefs) XXX_Size() int {
	return m.Size()
}
func (m *AppInstRefs) XXX_DiscardUnknown() {
	xxx_messageInfo_AppInstRefs.DiscardUnknown(m)
}

var xxx_messageInfo_AppInstRefs proto.InternalMessageInfo

func init() {
	proto.RegisterType((*VMResource)(nil), "edgeproto.VMResource")
	proto.RegisterType((*CloudletRefs)(nil), "edgeproto.CloudletRefs")
	proto.RegisterMapType((map[string]uint32)(nil), "edgeproto.CloudletRefs.OptResUsedMapEntry")
	proto.RegisterMapType((map[int32]int32)(nil), "edgeproto.CloudletRefs.RootLbPortsEntry")
	proto.RegisterType((*ClusterRefs)(nil), "edgeproto.ClusterRefs")
	proto.RegisterType((*AppInstRefs)(nil), "edgeproto.AppInstRefs")
	proto.RegisterMapType((map[string]uint32)(nil), "edgeproto.AppInstRefs.DeleteRequestedInstsEntry")
	proto.RegisterMapType((map[string]uint32)(nil), "edgeproto.AppInstRefs.InstsEntry")
}

func init() { proto.RegisterFile("refs.proto", fileDescriptor_6435a763ece979c6) }

var fileDescriptor_6435a763ece979c6 = []byte{
	// 904 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x94, 0x55, 0x41, 0x6f, 0x1b, 0x45,
	0x18, 0xf5, 0xc4, 0xde, 0x12, 0x7f, 0xce, 0xda, 0xee, 0xd6, 0x98, 0xa9, 0x29, 0xc6, 0xf8, 0x80,
	0x2c, 0x94, 0xba, 0x26, 0x70, 0x08, 0x16, 0x02, 0xdc, 0x16, 0x68, 0x69, 0xab, 0xa0, 0x8d, 0xe8,
	0x75, 0xb5, 0xf1, 0x4e, 0xcc, 0xca, 0xf6, 0xce, 0xb0, 0x33, 0xeb, 0xca, 0x9c, 0xb8, 0x81, 0x0a,
	0x87, 0xfe, 0x00, 0x0e, 0x5c, 0xb9, 0xf2, 0x2b, 0x72, 0xec, 0x91, 0x13, 0x82, 0xe4, 0x82, 0x7c,
	0x42, 0xaa, 0xe5, 0x72, 0x44, 0x3b, 0xb3, 0x9b, 0xdd, 0x60, 0xbb, 0x69, 0x6e, 0xf3, 0xbd, 0x7d,
	0xf3, 0xbe, 0x37, 0xf3, 0x3d, 0x8f, 0x01, 0x7c, 0x72, 0xc8, 0xdb, 0xcc, 0xa7, 0x82, 0x1a, 0x79,
	0xe2, 0x0c, 0x88, 0x5c, 0xd6, 0xde, 0x10, 0x94, 0x8e, 0xf8, 0x0d, 0x59, 0x0c, 0x88, 0x77, 0xba,
	0x50, 0xcc, 0x5a, 0x65, 0x40, 0x07, 0x54, 0x2e, 0x6f, 0x84, 0xab, 0x08, 0xbd, 0xdc, 0x1f, 0xd1,
	0xc0, 0x19, 0x11, 0x31, 0x24, 0xd3, 0x08, 0x2a, 0xc6, 0x50, 0x42, 0x09, 0xb8, 0x20, 0xbe, 0xeb,
	0xf1, 0x18, 0xd2, 0x23, 0x28, 0x2a, 0xf3, 0x36, 0x63, 0xf1, 0x17, 0x9b, 0xb1, 0x14, 0xb1, 0xe2,
	0x7a, 0x87, 0xbe, 0xed, 0x13, 0x4e, 0x03, 0xbf, 0x4f, 0x22, 0xd3, 0xcd, 0x1f, 0x10, 0xc0, 0xc3,
	0x07, 0x66, 0x84, 0x1a, 0xd7, 0x21, 0x3b, 0x24, 0x53, 0x8c, 0x1a, 0xa8, 0x55, 0xd8, 0x79, 0xb5,
	0x7d, 0x7a, 0xa2, 0xf6, 0x2d, 0xd5, 0xe5, 0x1e, 0x99, 0xde, 0xcc, 0x1d, 0xfd, 0xf1, 0x66, 0xc6,
	0x0c, 0x79, 0xc6, 0xeb, 0x90, 0x9f, 0x8c, 0xad, 0xc3, 0x91, 0x3d, 0xa1, 0x3e, 0xde, 0x68, 0xa0,
	0x56, 0xde, 0xdc, 0x9c, 0x8c, 0x3f, 0x93, 0xb5, 0x61, 0x40, 0x4e, 0x4c, 0x19, 0xc1, 0x59, 0x89,
	0xcb, 0xb5, 0x51, 0x01, 0xad, 0x4f, 0x03, 0x4f, 0x60, 0xad, 0x81, 0x5a, 0xba, 0xa9, 0x8a, 0x2f,
	0x72, 0x9b, 0xb9, 0xb2, 0xd6, 0x5c, 0x68, 0xb0, 0x75, 0x2b, 0x3a, 0xaf, 0x49, 0x0e, 0xb9, 0xd1,
	0x4d, 0x9b, 0xa9, 0x9e, 0x31, 0xa3, 0x58, 0xa1, 0x9b, 0xf2, 0x6c, 0x81, 0x37, 0x63, 0x20, 0x71,
	0x76, 0x1f, 0x74, 0x9f, 0x52, 0x61, 0x8d, 0x0e, 0x2c, 0x46, 0x7d, 0xc1, 0xf1, 0x66, 0x23, 0xdb,
	0x2a, 0xec, 0xb4, 0x56, 0xa8, 0x84, 0xbd, 0xda, 0x26, 0xa5, 0xe2, 0xfe, 0xc1, 0x97, 0x21, 0xf5,
	0x53, 0x4f, 0xf8, 0x53, 0xb3, 0xe0, 0x27, 0x88, 0xd1, 0x82, 0x72, 0xc0, 0x89, 0x63, 0x39, 0x53,
	0xcf, 0x1e, 0xbb, 0x7d, 0xcb, 0x65, 0x1c, 0xe7, 0x1b, 0xa8, 0xa5, 0x99, 0xc5, 0x10, 0xbf, 0xad,
	0xe0, 0xbb, 0x8c, 0x1b, 0x6f, 0x43, 0x49, 0x32, 0xb9, 0xb0, 0x45, 0x44, 0x04, 0x79, 0x7e, 0x3d,
	0x84, 0xf7, 0x25, 0x1a, 0xf2, 0xf6, 0xa1, 0x4c, 0x99, 0xb0, 0x7c, 0xc2, 0x2d, 0xc9, 0x1f, 0xdb,
	0x0c, 0x17, 0xa4, 0xc5, 0x77, 0xd6, 0x59, 0xdc, 0x63, 0xc2, 0x24, 0xfc, 0x2b, 0x4e, 0x9c, 0x07,
	0x36, 0x53, 0x26, 0x75, 0x9a, 0xc6, 0x8c, 0x0f, 0xe0, 0xaa, 0x4f, 0x38, 0xf1, 0x27, 0xc4, 0xb1,
	0xec, 0x40, 0x50, 0x2b, 0xca, 0x86, 0xe5, 0x3a, 0x1c, 0x6f, 0x35, 0x50, 0xeb, 0x92, 0x59, 0x8d,
	0x09, 0xbd, 0x40, 0xd0, 0x68, 0xa8, 0x77, 0x1d, 0x6e, 0xec, 0x81, 0x7e, 0x4a, 0xf6, 0xb8, 0xe0,
	0x58, 0x97, 0x66, 0xd6, 0x44, 0xe0, 0xca, 0xe3, 0xe7, 0xb8, 0x10, 0xef, 0xf6, 0xb8, 0xba, 0xf7,
	0xad, 0x7e, 0x02, 0x70, 0xe3, 0x0e, 0x6c, 0x4d, 0xc6, 0x96, 0xcd, 0x58, 0xa4, 0x57, 0x5c, 0xd2,
	0xeb, 0x31, 0x16, 0x52, 0x43, 0xbd, 0xd2, 0xe3, 0xe7, 0xf8, 0x95, 0xa8, 0x96, 0x5a, 0x30, 0x19,
	0x47, 0x25, 0x37, 0x3e, 0x06, 0x7d, 0xb8, 0xcb, 0x53, 0x52, 0xa5, 0x17, 0x49, 0xa9, 0x74, 0x16,
	0x86, 0xbb, 0x3c, 0x16, 0xa8, 0x7d, 0x04, 0xe5, 0xff, 0x8f, 0xd7, 0x28, 0x27, 0xd9, 0xd2, 0x54,
	0x62, 0x2a, 0xa0, 0x4d, 0xec, 0x51, 0x40, 0x64, 0x8e, 0x35, 0x53, 0x15, 0xdd, 0x8d, 0x5d, 0x54,
	0xfb, 0x04, 0x8c, 0xe5, 0xbb, 0x4f, 0x2b, 0xe4, 0x57, 0x28, 0xe8, 0x29, 0x85, 0xee, 0xb5, 0xbf,
	0x9f, 0x61, 0xf4, 0xcf, 0x33, 0x8c, 0xbe, 0x9b, 0x63, 0xf4, 0xcb, 0x1c, 0xa3, 0xdf, 0x16, 0x38,
	0xe7, 0x51, 0x8f, 0xfc, 0xbb, 0xc0, 0xa8, 0xf9, 0x2b, 0x82, 0xf8, 0x32, 0x65, 0xee, 0x3f, 0x7c,
	0x89, 0x1f, 0xe1, 0x95, 0xd9, 0x62, 0x79, 0x02, 0xd2, 0x45, 0x17, 0x72, 0x36, 0x63, 0x1c, 0x6f,
	0x5c, 0xe8, 0xc2, 0xe5, 0x9e, 0x6e, 0x23, 0xed, 0xf3, 0xc9, 0x2a, 0xaf, 0x3f, 0x67, 0xa1, 0x10,
	0xed, 0x93, 0x5e, 0x3b, 0x69, 0xaf, 0x97, 0xcf, 0x36, 0x0b, 0x1b, 0x15, 0x66, 0x0b, 0x9c, 0xed,
	0x31, 0x96, 0xf8, 0xbb, 0x03, 0x9a, 0x1a, 0xa3, 0x32, 0xf8, 0xd6, 0xb2, 0x41, 0x99, 0x76, 0x39,
	0x3a, 0x79, 0xd3, 0xcb, 0x66, 0x95, 0x80, 0x31, 0x82, 0xaa, 0x43, 0x46, 0x44, 0x10, 0xcb, 0x27,
	0xdf, 0x04, 0x84, 0x0b, 0xe2, 0x44, 0x09, 0xc9, 0x4a, 0xe9, 0xce, 0x1a, 0xe9, 0xdb, 0x72, 0x93,
	0x19, 0xef, 0x49, 0x75, 0x52, 0xe1, 0xa9, 0x38, 0x2b, 0x08, 0xb5, 0x5d, 0x80, 0x84, 0x79, 0x91,
	0xe9, 0xd7, 0x3e, 0x87, 0xab, 0x6b, 0x5b, 0x5e, 0x28, 0x46, 0xe7, 0x8e, 0x67, 0xe7, 0x27, 0x04,
	0xa5, 0xf4, 0xa3, 0xd1, 0x63, 0xae, 0x31, 0x85, 0xf2, 0xfe, 0xd7, 0xf4, 0xd1, 0x99, 0xa7, 0xf5,
	0xb5, 0x35, 0x8f, 0x4c, 0x6d, 0xdd, 0x87, 0xe6, 0xbb, 0xb3, 0x39, 0xbe, 0x1e, 0xff, 0x4f, 0xc4,
	0x5f, 0xf8, 0x76, 0xaf, 0x2f, 0x5c, 0xea, 0x3d, 0x74, 0xc9, 0xa3, 0xed, 0x7b, 0x64, 0xda, 0xde,
	0xf3, 0x07, 0xb6, 0xe7, 0x7e, 0x6b, 0x87, 0x60, 0x07, 0xed, 0xfc, 0x88, 0xa0, 0x98, 0x4a, 0xb6,
	0x72, 0x53, 0x52, 0x6e, 0x92, 0xbc, 0x57, 0x97, 0x23, 0x2e, 0xbd, 0xac, 0xc1, 0x9b, 0xef, 0xcf,
	0xe6, 0xb8, 0x93, 0x58, 0x49, 0x1e, 0x9d, 0x73, 0xdc, 0x7c, 0x8f, 0xa0, 0x98, 0xca, 0x41, 0xe8,
	0x26, 0x50, 0x6e, 0xd2, 0x89, 0xae, 0xae, 0x4e, 0x4d, 0x6d, 0x0d, 0xde, 0xec, 0xcc, 0xe6, 0x78,
	0x3b, 0x76, 0x13, 0xbf, 0x39, 0x2f, 0x76, 0x72, 0xf3, 0xda, 0xd1, 0x5f, 0xf5, 0xcc, 0xd1, 0x71,
	0x1d, 0x3d, 0x3d, 0xae, 0xa3, 0x3f, 0x8f, 0xeb, 0xe8, 0xc9, 0x49, 0x3d, 0xf3, 0xf4, 0xa4, 0x9e,
	0xf9, 0xfd, 0xa4, 0x9e, 0x39, 0xb8, 0x24, 0x9b, 0xbc, 0xf7, 0x5f, 0x00, 0x00, 0x00, 0xff, 0xff,
	0x01, 0x45, 0x7b, 0xb9, 0x5d, 0x08, 0x00, 0x00,
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// CloudletRefsApiClient is the client API for CloudletRefsApi service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.
type CloudletRefsApiClient interface {
	// Show CloudletRefs (debug only)
	ShowCloudletRefs(ctx context.Context, in *CloudletRefs, opts ...grpc.CallOption) (CloudletRefsApi_ShowCloudletRefsClient, error)
}

type cloudletRefsApiClient struct {
	cc *grpc.ClientConn
}

func NewCloudletRefsApiClient(cc *grpc.ClientConn) CloudletRefsApiClient {
	return &cloudletRefsApiClient{cc}
}

func (c *cloudletRefsApiClient) ShowCloudletRefs(ctx context.Context, in *CloudletRefs, opts ...grpc.CallOption) (CloudletRefsApi_ShowCloudletRefsClient, error) {
	stream, err := c.cc.NewStream(ctx, &_CloudletRefsApi_serviceDesc.Streams[0], "/edgeproto.CloudletRefsApi/ShowCloudletRefs", opts...)
	if err != nil {
		return nil, err
	}
	x := &cloudletRefsApiShowCloudletRefsClient{stream}
	if err := x.ClientStream.SendMsg(in); err != nil {
		return nil, err
	}
	if err := x.ClientStream.CloseSend(); err != nil {
		return nil, err
	}
	return x, nil
}

type CloudletRefsApi_ShowCloudletRefsClient interface {
	Recv() (*CloudletRefs, error)
	grpc.ClientStream
}

type cloudletRefsApiShowCloudletRefsClient struct {
	grpc.ClientStream
}

func (x *cloudletRefsApiShowCloudletRefsClient) Recv() (*CloudletRefs, error) {
	m := new(CloudletRefs)
	if err := x.ClientStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

// CloudletRefsApiServer is the server API for CloudletRefsApi service.
type CloudletRefsApiServer interface {
	// Show CloudletRefs (debug only)
	ShowCloudletRefs(*CloudletRefs, CloudletRefsApi_ShowCloudletRefsServer) error
}

// UnimplementedCloudletRefsApiServer can be embedded to have forward compatible implementations.
type UnimplementedCloudletRefsApiServer struct {
}

func (*UnimplementedCloudletRefsApiServer) ShowCloudletRefs(req *CloudletRefs, srv CloudletRefsApi_ShowCloudletRefsServer) error {
	return status.Errorf(codes.Unimplemented, "method ShowCloudletRefs not implemented")
}

func RegisterCloudletRefsApiServer(s *grpc.Server, srv CloudletRefsApiServer) {
	s.RegisterService(&_CloudletRefsApi_serviceDesc, srv)
}

func _CloudletRefsApi_ShowCloudletRefs_Handler(srv interface{}, stream grpc.ServerStream) error {
	m := new(CloudletRefs)
	if err := stream.RecvMsg(m); err != nil {
		return err
	}
	return srv.(CloudletRefsApiServer).ShowCloudletRefs(m, &cloudletRefsApiShowCloudletRefsServer{stream})
}

type CloudletRefsApi_ShowCloudletRefsServer interface {
	Send(*CloudletRefs) error
	grpc.ServerStream
}

type cloudletRefsApiShowCloudletRefsServer struct {
	grpc.ServerStream
}

func (x *cloudletRefsApiShowCloudletRefsServer) Send(m *CloudletRefs) error {
	return x.ServerStream.SendMsg(m)
}

var _CloudletRefsApi_serviceDesc = grpc.ServiceDesc{
	ServiceName: "edgeproto.CloudletRefsApi",
	HandlerType: (*CloudletRefsApiServer)(nil),
	Methods:     []grpc.MethodDesc{},
	Streams: []grpc.StreamDesc{
		{
			StreamName:    "ShowCloudletRefs",
			Handler:       _CloudletRefsApi_ShowCloudletRefs_Handler,
			ServerStreams: true,
		},
	},
	Metadata: "refs.proto",
}

// ClusterRefsApiClient is the client API for ClusterRefsApi service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.
type ClusterRefsApiClient interface {
	// Show ClusterRefs (debug only)
	ShowClusterRefs(ctx context.Context, in *ClusterRefs, opts ...grpc.CallOption) (ClusterRefsApi_ShowClusterRefsClient, error)
}

type clusterRefsApiClient struct {
	cc *grpc.ClientConn
}

func NewClusterRefsApiClient(cc *grpc.ClientConn) ClusterRefsApiClient {
	return &clusterRefsApiClient{cc}
}

func (c *clusterRefsApiClient) ShowClusterRefs(ctx context.Context, in *ClusterRefs, opts ...grpc.CallOption) (ClusterRefsApi_ShowClusterRefsClient, error) {
	stream, err := c.cc.NewStream(ctx, &_ClusterRefsApi_serviceDesc.Streams[0], "/edgeproto.ClusterRefsApi/ShowClusterRefs", opts...)
	if err != nil {
		return nil, err
	}
	x := &clusterRefsApiShowClusterRefsClient{stream}
	if err := x.ClientStream.SendMsg(in); err != nil {
		return nil, err
	}
	if err := x.ClientStream.CloseSend(); err != nil {
		return nil, err
	}
	return x, nil
}

type ClusterRefsApi_ShowClusterRefsClient interface {
	Recv() (*ClusterRefs, error)
	grpc.ClientStream
}

type clusterRefsApiShowClusterRefsClient struct {
	grpc.ClientStream
}

func (x *clusterRefsApiShowClusterRefsClient) Recv() (*ClusterRefs, error) {
	m := new(ClusterRefs)
	if err := x.ClientStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

// ClusterRefsApiServer is the server API for ClusterRefsApi service.
type ClusterRefsApiServer interface {
	// Show ClusterRefs (debug only)
	ShowClusterRefs(*ClusterRefs, ClusterRefsApi_ShowClusterRefsServer) error
}

// UnimplementedClusterRefsApiServer can be embedded to have forward compatible implementations.
type UnimplementedClusterRefsApiServer struct {
}

func (*UnimplementedClusterRefsApiServer) ShowClusterRefs(req *ClusterRefs, srv ClusterRefsApi_ShowClusterRefsServer) error {
	return status.Errorf(codes.Unimplemented, "method ShowClusterRefs not implemented")
}

func RegisterClusterRefsApiServer(s *grpc.Server, srv ClusterRefsApiServer) {
	s.RegisterService(&_ClusterRefsApi_serviceDesc, srv)
}

func _ClusterRefsApi_ShowClusterRefs_Handler(srv interface{}, stream grpc.ServerStream) error {
	m := new(ClusterRefs)
	if err := stream.RecvMsg(m); err != nil {
		return err
	}
	return srv.(ClusterRefsApiServer).ShowClusterRefs(m, &clusterRefsApiShowClusterRefsServer{stream})
}

type ClusterRefsApi_ShowClusterRefsServer interface {
	Send(*ClusterRefs) error
	grpc.ServerStream
}

type clusterRefsApiShowClusterRefsServer struct {
	grpc.ServerStream
}

func (x *clusterRefsApiShowClusterRefsServer) Send(m *ClusterRefs) error {
	return x.ServerStream.SendMsg(m)
}

var _ClusterRefsApi_serviceDesc = grpc.ServiceDesc{
	ServiceName: "edgeproto.ClusterRefsApi",
	HandlerType: (*ClusterRefsApiServer)(nil),
	Methods:     []grpc.MethodDesc{},
	Streams: []grpc.StreamDesc{
		{
			StreamName:    "ShowClusterRefs",
			Handler:       _ClusterRefsApi_ShowClusterRefs_Handler,
			ServerStreams: true,
		},
	},
	Metadata: "refs.proto",
}

// AppInstRefsApiClient is the client API for AppInstRefsApi service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.
type AppInstRefsApiClient interface {
	// Show AppInstRefs (debug only)
	ShowAppInstRefs(ctx context.Context, in *AppInstRefs, opts ...grpc.CallOption) (AppInstRefsApi_ShowAppInstRefsClient, error)
}

type appInstRefsApiClient struct {
	cc *grpc.ClientConn
}

func NewAppInstRefsApiClient(cc *grpc.ClientConn) AppInstRefsApiClient {
	return &appInstRefsApiClient{cc}
}

func (c *appInstRefsApiClient) ShowAppInstRefs(ctx context.Context, in *AppInstRefs, opts ...grpc.CallOption) (AppInstRefsApi_ShowAppInstRefsClient, error) {
	stream, err := c.cc.NewStream(ctx, &_AppInstRefsApi_serviceDesc.Streams[0], "/edgeproto.AppInstRefsApi/ShowAppInstRefs", opts...)
	if err != nil {
		return nil, err
	}
	x := &appInstRefsApiShowAppInstRefsClient{stream}
	if err := x.ClientStream.SendMsg(in); err != nil {
		return nil, err
	}
	if err := x.ClientStream.CloseSend(); err != nil {
		return nil, err
	}
	return x, nil
}

type AppInstRefsApi_ShowAppInstRefsClient interface {
	Recv() (*AppInstRefs, error)
	grpc.ClientStream
}

type appInstRefsApiShowAppInstRefsClient struct {
	grpc.ClientStream
}

func (x *appInstRefsApiShowAppInstRefsClient) Recv() (*AppInstRefs, error) {
	m := new(AppInstRefs)
	if err := x.ClientStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

// AppInstRefsApiServer is the server API for AppInstRefsApi service.
type AppInstRefsApiServer interface {
	// Show AppInstRefs (debug only)
	ShowAppInstRefs(*AppInstRefs, AppInstRefsApi_ShowAppInstRefsServer) error
}

// UnimplementedAppInstRefsApiServer can be embedded to have forward compatible implementations.
type UnimplementedAppInstRefsApiServer struct {
}

func (*UnimplementedAppInstRefsApiServer) ShowAppInstRefs(req *AppInstRefs, srv AppInstRefsApi_ShowAppInstRefsServer) error {
	return status.Errorf(codes.Unimplemented, "method ShowAppInstRefs not implemented")
}

func RegisterAppInstRefsApiServer(s *grpc.Server, srv AppInstRefsApiServer) {
	s.RegisterService(&_AppInstRefsApi_serviceDesc, srv)
}

func _AppInstRefsApi_ShowAppInstRefs_Handler(srv interface{}, stream grpc.ServerStream) error {
	m := new(AppInstRefs)
	if err := stream.RecvMsg(m); err != nil {
		return err
	}
	return srv.(AppInstRefsApiServer).ShowAppInstRefs(m, &appInstRefsApiShowAppInstRefsServer{stream})
}

type AppInstRefsApi_ShowAppInstRefsServer interface {
	Send(*AppInstRefs) error
	grpc.ServerStream
}

type appInstRefsApiShowAppInstRefsServer struct {
	grpc.ServerStream
}

func (x *appInstRefsApiShowAppInstRefsServer) Send(m *AppInstRefs) error {
	return x.ServerStream.SendMsg(m)
}

var _AppInstRefsApi_serviceDesc = grpc.ServiceDesc{
	ServiceName: "edgeproto.AppInstRefsApi",
	HandlerType: (*AppInstRefsApiServer)(nil),
	Methods:     []grpc.MethodDesc{},
	Streams: []grpc.StreamDesc{
		{
			StreamName:    "ShowAppInstRefs",
			Handler:       _AppInstRefsApi_ShowAppInstRefs_Handler,
			ServerStreams: true,
		},
	},
	Metadata: "refs.proto",
}

func (m *VMResource) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *VMResource) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *VMResource) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.Count != 0 {
		i = encodeVarintRefs(dAtA, i, uint64(m.Count))
		i--
		dAtA[i] = 0x28
	}
	if len(m.Type) > 0 {
		i -= len(m.Type)
		copy(dAtA[i:], m.Type)
		i = encodeVarintRefs(dAtA, i, uint64(len(m.Type)))
		i--
		dAtA[i] = 0x1a
	}
	if len(m.VmFlavor) > 0 {
		i -= len(m.VmFlavor)
		copy(dAtA[i:], m.VmFlavor)
		i = encodeVarintRefs(dAtA, i, uint64(len(m.VmFlavor)))
		i--
		dAtA[i] = 0x12
	}
	{
		size, err := m.Key.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintRefs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0xa
	return len(dAtA) - i, nil
}

func (m *CloudletRefs) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *CloudletRefs) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *CloudletRefs) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.K8SAppInsts) > 0 {
		for iNdEx := len(m.K8SAppInsts) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.K8SAppInsts[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintRefs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x7a
		}
	}
	if len(m.VmAppInsts) > 0 {
		for iNdEx := len(m.VmAppInsts) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.VmAppInsts[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintRefs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x72
		}
	}
	if len(m.ClusterInsts) > 0 {
		for iNdEx := len(m.ClusterInsts) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.ClusterInsts[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintRefs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x6a
		}
	}
	if m.ReservedAutoClusterIds != 0 {
		i -= 8
		encoding_binary.LittleEndian.PutUint64(dAtA[i:], uint64(m.ReservedAutoClusterIds))
		i--
		dAtA[i] = 0x61
	}
	if len(m.OptResUsedMap) > 0 {
		for k := range m.OptResUsedMap {
			v := m.OptResUsedMap[k]
			baseI := i
			i = encodeVarintRefs(dAtA, i, uint64(v))
			i--
			dAtA[i] = 0x10
			i -= len(k)
			copy(dAtA[i:], k)
			i = encodeVarintRefs(dAtA, i, uint64(len(k)))
			i--
			dAtA[i] = 0xa
			i = encodeVarintRefs(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x5a
		}
	}
	if len(m.UsedStaticIps) > 0 {
		i -= len(m.UsedStaticIps)
		copy(dAtA[i:], m.UsedStaticIps)
		i = encodeVarintRefs(dAtA, i, uint64(len(m.UsedStaticIps)))
		i--
		dAtA[i] = 0x52
	}
	if m.UsedDynamicIps != 0 {
		i = encodeVarintRefs(dAtA, i, uint64(m.UsedDynamicIps))
		i--
		dAtA[i] = 0x48
	}
	if len(m.RootLbPorts) > 0 {
		for k := range m.RootLbPorts {
			v := m.RootLbPorts[k]
			baseI := i
			i = encodeVarintRefs(dAtA, i, uint64(v))
			i--
			dAtA[i] = 0x10
			i = encodeVarintRefs(dAtA, i, uint64(k))
			i--
			dAtA[i] = 0x8
			i = encodeVarintRefs(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x42
		}
	}
	{
		size, err := m.Key.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintRefs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0xa
	return len(dAtA) - i, nil
}

func (m *ClusterRefs) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ClusterRefs) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *ClusterRefs) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.Apps) > 0 {
		for iNdEx := len(m.Apps) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.Apps[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintRefs(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x12
		}
	}
	{
		size, err := m.Key.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintRefs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0xa
	return len(dAtA) - i, nil
}

func (m *AppInstRefs) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AppInstRefs) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *AppInstRefs) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.DeleteRequestedInsts) > 0 {
		for k := range m.DeleteRequestedInsts {
			v := m.DeleteRequestedInsts[k]
			baseI := i
			i = encodeVarintRefs(dAtA, i, uint64(v))
			i--
			dAtA[i] = 0x10
			i -= len(k)
			copy(dAtA[i:], k)
			i = encodeVarintRefs(dAtA, i, uint64(len(k)))
			i--
			dAtA[i] = 0xa
			i = encodeVarintRefs(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x1a
		}
	}
	if len(m.Insts) > 0 {
		for k := range m.Insts {
			v := m.Insts[k]
			baseI := i
			i = encodeVarintRefs(dAtA, i, uint64(v))
			i--
			dAtA[i] = 0x10
			i -= len(k)
			copy(dAtA[i:], k)
			i = encodeVarintRefs(dAtA, i, uint64(len(k)))
			i--
			dAtA[i] = 0xa
			i = encodeVarintRefs(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x12
		}
	}
	{
		size, err := m.Key.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintRefs(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0xa
	return len(dAtA) - i, nil
}

func encodeVarintRefs(dAtA []byte, offset int, v uint64) int {
	offset -= sovRefs(v)
	base := offset
	for v >= 1<<7 {
		dAtA[offset] = uint8(v&0x7f | 0x80)
		v >>= 7
		offset++
	}
	dAtA[offset] = uint8(v)
	return base
}
func (m *VMResource) Clone() *VMResource {
	cp := &VMResource{}
	cp.DeepCopyIn(m)
	return cp
}

func (m *VMResource) CopyInFields(src *VMResource) int {
	changed := 0
	if m.Key.Name != src.Key.Name {
		m.Key.Name = src.Key.Name
		changed++
	}
	if m.Key.Organization != src.Key.Organization {
		m.Key.Organization = src.Key.Organization
		changed++
	}
	if m.VmFlavor != src.VmFlavor {
		m.VmFlavor = src.VmFlavor
		changed++
	}
	if m.Type != src.Type {
		m.Type = src.Type
		changed++
	}
	if m.Count != src.Count {
		m.Count = src.Count
		changed++
	}
	return changed
}

func (m *VMResource) DeepCopyIn(src *VMResource) {
	m.Key.DeepCopyIn(&src.Key)
	m.VmFlavor = src.VmFlavor
	m.Type = src.Type
	m.Count = src.Count
}

func (m *VMResource) GetObjKey() objstore.ObjKey {
	return m.GetKey()
}

func (m *VMResource) GetKey() *ClusterKey {
	return &m.Key
}

func (m *VMResource) GetKeyVal() ClusterKey {
	return m.Key
}

func (m *VMResource) SetKey(key *ClusterKey) {
	m.Key = *key
}

func CmpSortVMResource(a VMResource, b VMResource) bool {
	return a.Key.GetKeyString() < b.Key.GetKeyString()
}

// Helper method to check that enums have valid values
func (m *VMResource) ValidateEnums() error {
	if err := m.Key.ValidateEnums(); err != nil {
		return err
	}
	return nil
}

func (s *VMResource) ClearTagged(tags map[string]struct{}) {
	s.Key.ClearTagged(tags)
}

func (m *CloudletRefs) Matches(o *CloudletRefs, fopts ...MatchOpt) bool {
	opts := MatchOptions{}
	applyMatchOptions(&opts, fopts...)
	if o == nil {
		if opts.Filter {
			return true
		}
		return false
	}
	if !m.Key.Matches(&o.Key, fopts...) {
		return false
	}
	if !opts.Filter || o.RootLbPorts != nil {
		if len(m.RootLbPorts) == 0 && len(o.RootLbPorts) > 0 || len(m.RootLbPorts) > 0 && len(o.RootLbPorts) == 0 {
			return false
		} else if m.RootLbPorts != nil && o.RootLbPorts != nil {
			if !opts.Filter && len(m.RootLbPorts) != len(o.RootLbPorts) {
				return false
			}
			for k, _ := range o.RootLbPorts {
				_, ok := m.RootLbPorts[k]
				if !ok {
					return false
				}
				if o.RootLbPorts[k] != m.RootLbPorts[k] {
					return false
				}
			}
		}
	}
	if !opts.Filter || o.UsedDynamicIps != 0 {
		if o.UsedDynamicIps != m.UsedDynamicIps {
			return false
		}
	}
	if !opts.Filter || o.UsedStaticIps != "" {
		if o.UsedStaticIps != m.UsedStaticIps {
			return false
		}
	}
	if !opts.Filter || o.OptResUsedMap != nil {
		if len(m.OptResUsedMap) == 0 && len(o.OptResUsedMap) > 0 || len(m.OptResUsedMap) > 0 && len(o.OptResUsedMap) == 0 {
			return false
		} else if m.OptResUsedMap != nil && o.OptResUsedMap != nil {
			if !opts.Filter && len(m.OptResUsedMap) != len(o.OptResUsedMap) {
				return false
			}
			for k, _ := range o.OptResUsedMap {
				_, ok := m.OptResUsedMap[k]
				if !ok {
					return false
				}
				if o.OptResUsedMap[k] != m.OptResUsedMap[k] {
					return false
				}
			}
		}
	}
	if !opts.Filter || o.ReservedAutoClusterIds != 0 {
		if o.ReservedAutoClusterIds != m.ReservedAutoClusterIds {
			return false
		}
	}
	if !opts.Filter || o.ClusterInsts != nil {
		if len(m.ClusterInsts) == 0 && len(o.ClusterInsts) > 0 || len(m.ClusterInsts) > 0 && len(o.ClusterInsts) == 0 {
			return false
		} else if m.ClusterInsts != nil && o.ClusterInsts != nil {
			if !opts.Filter && len(m.ClusterInsts) != len(o.ClusterInsts) {
				return false
			}
			if opts.SortArrayedKeys {
				sort.Slice(m.ClusterInsts, func(i, j int) bool {
					return m.ClusterInsts[i].GetKeyString() < m.ClusterInsts[j].GetKeyString()
				})
				sort.Slice(o.ClusterInsts, func(i, j int) bool {
					return o.ClusterInsts[i].GetKeyString() < o.ClusterInsts[j].GetKeyString()
				})
			}
			found := 0
			for oIndex, _ := range o.ClusterInsts {
				for mIndex, _ := range m.ClusterInsts {
					if m.ClusterInsts[mIndex].Matches(&o.ClusterInsts[oIndex], fopts...) {
						found++
						break
					}
				}
			}
			if found != len(o.ClusterInsts) {
				return false
			}
		}
	}
	if !opts.Filter || o.VmAppInsts != nil {
		if len(m.VmAppInsts) == 0 && len(o.VmAppInsts) > 0 || len(m.VmAppInsts) > 0 && len(o.VmAppInsts) == 0 {
			return false
		} else if m.VmAppInsts != nil && o.VmAppInsts != nil {
			if !opts.Filter && len(m.VmAppInsts) != len(o.VmAppInsts) {
				return false
			}
			if opts.SortArrayedKeys {
				sort.Slice(m.VmAppInsts, func(i, j int) bool {
					return m.VmAppInsts[i].GetKeyString() < m.VmAppInsts[j].GetKeyString()
				})
				sort.Slice(o.VmAppInsts, func(i, j int) bool {
					return o.VmAppInsts[i].GetKeyString() < o.VmAppInsts[j].GetKeyString()
				})
			}
			found := 0
			for oIndex, _ := range o.VmAppInsts {
				for mIndex, _ := range m.VmAppInsts {
					if m.VmAppInsts[mIndex].Matches(&o.VmAppInsts[oIndex], fopts...) {
						found++
						break
					}
				}
			}
			if found != len(o.VmAppInsts) {
				return false
			}
		}
	}
	if !opts.Filter || o.K8SAppInsts != nil {
		if len(m.K8SAppInsts) == 0 && len(o.K8SAppInsts) > 0 || len(m.K8SAppInsts) > 0 && len(o.K8SAppInsts) == 0 {
			return false
		} else if m.K8SAppInsts != nil && o.K8SAppInsts != nil {
			if !opts.Filter && len(m.K8SAppInsts) != len(o.K8SAppInsts) {
				return false
			}
			if opts.SortArrayedKeys {
				sort.Slice(m.K8SAppInsts, func(i, j int) bool {
					return m.K8SAppInsts[i].GetKeyString() < m.K8SAppInsts[j].GetKeyString()
				})
				sort.Slice(o.K8SAppInsts, func(i, j int) bool {
					return o.K8SAppInsts[i].GetKeyString() < o.K8SAppInsts[j].GetKeyString()
				})
			}
			found := 0
			for oIndex, _ := range o.K8SAppInsts {
				for mIndex, _ := range m.K8SAppInsts {
					if m.K8SAppInsts[mIndex].Matches(&o.K8SAppInsts[oIndex], fopts...) {
						found++
						break
					}
				}
			}
			if found != len(o.K8SAppInsts) {
				return false
			}
		}
	}
	return true
}

func (m *CloudletRefs) Clone() *CloudletRefs {
	cp := &CloudletRefs{}
	cp.DeepCopyIn(m)
	return cp
}

func (m *CloudletRefs) AddClusterInsts(vals ...ClusterKey) int {
	changes := 0
	cur := make(map[string]struct{})
	for _, v := range m.ClusterInsts {
		cur[v.GetKeyString()] = struct{}{}
	}
	for _, v := range vals {
		if _, found := cur[v.GetKeyString()]; found {
			continue // duplicate
		}
		m.ClusterInsts = append(m.ClusterInsts, v)
		changes++
	}
	return changes
}

func (m *CloudletRefs) RemoveClusterInsts(vals ...ClusterKey) int {
	changes := 0
	remove := make(map[string]struct{})
	for _, v := range vals {
		remove[v.GetKeyString()] = struct{}{}
	}
	for i := len(m.ClusterInsts); i >= 0; i-- {
		if _, found := remove[m.ClusterInsts[i].GetKeyString()]; found {
			m.ClusterInsts = append(m.ClusterInsts[:i], m.ClusterInsts[i+1:]...)
			changes++
		}
	}
	return changes
}

func (m *CloudletRefs) AddVmAppInsts(vals ...AppInstKey) int {
	changes := 0
	cur := make(map[string]struct{})
	for _, v := range m.VmAppInsts {
		cur[v.GetKeyString()] = struct{}{}
	}
	for _, v := range vals {
		if _, found := cur[v.GetKeyString()]; found {
			continue // duplicate
		}
		m.VmAppInsts = append(m.VmAppInsts, v)
		changes++
	}
	return changes
}

func (m *CloudletRefs) RemoveVmAppInsts(vals ...AppInstKey) int {
	changes := 0
	remove := make(map[string]struct{})
	for _, v := range vals {
		remove[v.GetKeyString()] = struct{}{}
	}
	for i := len(m.VmAppInsts); i >= 0; i-- {
		if _, found := remove[m.VmAppInsts[i].GetKeyString()]; found {
			m.VmAppInsts = append(m.VmAppInsts[:i], m.VmAppInsts[i+1:]...)
			changes++
		}
	}
	return changes
}

func (m *CloudletRefs) AddK8SAppInsts(vals ...AppInstKey) int {
	changes := 0
	cur := make(map[string]struct{})
	for _, v := range m.K8SAppInsts {
		cur[v.GetKeyString()] = struct{}{}
	}
	for _, v := range vals {
		if _, found := cur[v.GetKeyString()]; found {
			continue // duplicate
		}
		m.K8SAppInsts = append(m.K8SAppInsts, v)
		changes++
	}
	return changes
}

func (m *CloudletRefs) RemoveK8SAppInsts(vals ...AppInstKey) int {
	changes := 0
	remove := make(map[string]struct{})
	for _, v := range vals {
		remove[v.GetKeyString()] = struct{}{}
	}
	for i := len(m.K8SAppInsts); i >= 0; i-- {
		if _, found := remove[m.K8SAppInsts[i].GetKeyString()]; found {
			m.K8SAppInsts = append(m.K8SAppInsts[:i], m.K8SAppInsts[i+1:]...)
			changes++
		}
	}
	return changes
}

func (m *CloudletRefs) CopyInFields(src *CloudletRefs) int {
	updateListAction := "replace"
	changed := 0
	if m.Key.Organization != src.Key.Organization {
		m.Key.Organization = src.Key.Organization
		changed++
	}
	if m.Key.Name != src.Key.Name {
		m.Key.Name = src.Key.Name
		changed++
	}
	if m.Key.FederatedOrganization != src.Key.FederatedOrganization {
		m.Key.FederatedOrganization = src.Key.FederatedOrganization
		changed++
	}
	if src.RootLbPorts != nil {
		if updateListAction == "add" {
			for k0, v := range src.RootLbPorts {
				m.RootLbPorts[k0] = v
				changed++
			}
		} else if updateListAction == "remove" {
			for k0, _ := range src.RootLbPorts {
				if _, ok := m.RootLbPorts[k0]; ok {
					delete(m.RootLbPorts, k0)
					changed++
				}
			}
		} else {
			m.RootLbPorts = make(map[int32]int32)
			for k0, v := range src.RootLbPorts {
				m.RootLbPorts[k0] = v
			}
			changed++
		}
	} else if m.RootLbPorts != nil {
		m.RootLbPorts = nil
		changed++
	}
	if m.UsedDynamicIps != src.UsedDynamicIps {
		m.UsedDynamicIps = src.UsedDynamicIps
		changed++
	}
	if m.UsedStaticIps != src.UsedStaticIps {
		m.UsedStaticIps = src.UsedStaticIps
		changed++
	}
	if src.OptResUsedMap != nil {
		if updateListAction == "add" {
			for k0, v := range src.OptResUsedMap {
				m.OptResUsedMap[k0] = v
				changed++
			}
		} else if updateListAction == "remove" {
			for k0, _ := range src.OptResUsedMap {
				if _, ok := m.OptResUsedMap[k0]; ok {
					delete(m.OptResUsedMap, k0)
					changed++
				}
			}
		} else {
			m.OptResUsedMap = make(map[string]uint32)
			for k0, v := range src.OptResUsedMap {
				m.OptResUsedMap[k0] = v
			}
			changed++
		}
	} else if m.OptResUsedMap != nil {
		m.OptResUsedMap = nil
		changed++
	}
	if m.ReservedAutoClusterIds != src.ReservedAutoClusterIds {
		m.ReservedAutoClusterIds = src.ReservedAutoClusterIds
		changed++
	}
	if src.ClusterInsts != nil {
		if updateListAction == "add" {
			changed += m.AddClusterInsts(src.ClusterInsts...)
		} else if updateListAction == "remove" {
			changed += m.RemoveClusterInsts(src.ClusterInsts...)
		} else {
			m.ClusterInsts = make([]ClusterKey, 0)
			for k0, _ := range src.ClusterInsts {
				m.ClusterInsts = append(m.ClusterInsts, *src.ClusterInsts[k0].Clone())
			}
			changed++
		}
	} else if m.ClusterInsts != nil {
		m.ClusterInsts = nil
		changed++
	}
	if src.VmAppInsts != nil {
		if updateListAction == "add" {
			changed += m.AddVmAppInsts(src.VmAppInsts...)
		} else if updateListAction == "remove" {
			changed += m.RemoveVmAppInsts(src.VmAppInsts...)
		} else {
			m.VmAppInsts = make([]AppInstKey, 0)
			for k0, _ := range src.VmAppInsts {
				m.VmAppInsts = append(m.VmAppInsts, *src.VmAppInsts[k0].Clone())
			}
			changed++
		}
	} else if m.VmAppInsts != nil {
		m.VmAppInsts = nil
		changed++
	}
	if src.K8SAppInsts != nil {
		if updateListAction == "add" {
			changed += m.AddK8SAppInsts(src.K8SAppInsts...)
		} else if updateListAction == "remove" {
			changed += m.RemoveK8SAppInsts(src.K8SAppInsts...)
		} else {
			m.K8SAppInsts = make([]AppInstKey, 0)
			for k0, _ := range src.K8SAppInsts {
				m.K8SAppInsts = append(m.K8SAppInsts, *src.K8SAppInsts[k0].Clone())
			}
			changed++
		}
	} else if m.K8SAppInsts != nil {
		m.K8SAppInsts = nil
		changed++
	}
	return changed
}

func (m *CloudletRefs) DeepCopyIn(src *CloudletRefs) {
	m.Key.DeepCopyIn(&src.Key)
	if src.RootLbPorts != nil {
		m.RootLbPorts = make(map[int32]int32)
		for k, v := range src.RootLbPorts {
			m.RootLbPorts[k] = v
		}
	} else {
		m.RootLbPorts = nil
	}
	m.UsedDynamicIps = src.UsedDynamicIps
	m.UsedStaticIps = src.UsedStaticIps
	if src.OptResUsedMap != nil {
		m.OptResUsedMap = make(map[string]uint32)
		for k, v := range src.OptResUsedMap {
			m.OptResUsedMap[k] = v
		}
	} else {
		m.OptResUsedMap = nil
	}
	m.ReservedAutoClusterIds = src.ReservedAutoClusterIds
	if src.ClusterInsts != nil {
		m.ClusterInsts = make([]ClusterKey, len(src.ClusterInsts), len(src.ClusterInsts))
		for ii, s := range src.ClusterInsts {
			m.ClusterInsts[ii].DeepCopyIn(&s)
		}
	} else {
		m.ClusterInsts = nil
	}
	if src.VmAppInsts != nil {
		m.VmAppInsts = make([]AppInstKey, len(src.VmAppInsts), len(src.VmAppInsts))
		for ii, s := range src.VmAppInsts {
			m.VmAppInsts[ii].DeepCopyIn(&s)
		}
	} else {
		m.VmAppInsts = nil
	}
	if src.K8SAppInsts != nil {
		m.K8SAppInsts = make([]AppInstKey, len(src.K8SAppInsts), len(src.K8SAppInsts))
		for ii, s := range src.K8SAppInsts {
			m.K8SAppInsts[ii].DeepCopyIn(&s)
		}
	} else {
		m.K8SAppInsts = nil
	}
}

func (s *CloudletRefs) HasFields() bool {
	return false
}

type CloudletRefsStore interface {
	Create(ctx context.Context, m *CloudletRefs, wait func(int64)) (*Result, error)
	Update(ctx context.Context, m *CloudletRefs, wait func(int64)) (*Result, error)
	Delete(ctx context.Context, m *CloudletRefs, wait func(int64)) (*Result, error)
	Put(ctx context.Context, m *CloudletRefs, wait func(int64), ops ...objstore.KVOp) (*Result, error)
	LoadOne(key string) (*CloudletRefs, int64, error)
	Get(ctx context.Context, key *CloudletKey, buf *CloudletRefs) bool
	STMGet(stm concurrency.STM, key *CloudletKey, buf *CloudletRefs) bool
	STMPut(stm concurrency.STM, obj *CloudletRefs, ops ...objstore.KVOp)
	STMDel(stm concurrency.STM, key *CloudletKey)
	STMHas(stm concurrency.STM, key *CloudletKey) bool
}

type CloudletRefsStoreImpl struct {
	kvstore objstore.KVStore
}

func NewCloudletRefsStore(kvstore objstore.KVStore) *CloudletRefsStoreImpl {
	return &CloudletRefsStoreImpl{kvstore: kvstore}
}

func (s *CloudletRefsStoreImpl) Create(ctx context.Context, m *CloudletRefs, wait func(int64)) (*Result, error) {
	err := m.Validate(nil)
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("CloudletRefs", m.GetKey())
	val, err := json.Marshal(m)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Create(ctx, key, string(val))
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *CloudletRefsStoreImpl) Update(ctx context.Context, m *CloudletRefs, wait func(int64)) (*Result, error) {
	err := m.Validate(nil)
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("CloudletRefs", m.GetKey())
	var vers int64 = 0
	val, err := json.Marshal(m)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Update(ctx, key, string(val), vers)
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *CloudletRefsStoreImpl) Put(ctx context.Context, m *CloudletRefs, wait func(int64), ops ...objstore.KVOp) (*Result, error) {
	err := m.Validate(nil)
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("CloudletRefs", m.GetKey())
	var val []byte
	val, err = json.Marshal(m)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Put(ctx, key, string(val), ops...)
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *CloudletRefsStoreImpl) Delete(ctx context.Context, m *CloudletRefs, wait func(int64)) (*Result, error) {
	err := m.GetKey().ValidateKey()
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("CloudletRefs", m.GetKey())
	rev, err := s.kvstore.Delete(ctx, key)
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *CloudletRefsStoreImpl) LoadOne(key string) (*CloudletRefs, int64, error) {
	val, rev, _, err := s.kvstore.Get(key)
	if err != nil {
		return nil, 0, err
	}
	var obj CloudletRefs
	err = json.Unmarshal(val, &obj)
	if err != nil {
		log.DebugLog(log.DebugLevelApi, "Failed to parse CloudletRefs data", "val", string(val), "err", err)
		return nil, 0, err
	}
	return &obj, rev, nil
}

func (s *CloudletRefsStoreImpl) Get(ctx context.Context, key *CloudletKey, buf *CloudletRefs) bool {
	keystr := objstore.DbKeyString("CloudletRefs", key)
	val, _, _, err := s.kvstore.Get(keystr)
	if err != nil {
		return false
	}
	return s.parseGetData(val, buf)
}

func (s *CloudletRefsStoreImpl) STMGet(stm concurrency.STM, key *CloudletKey, buf *CloudletRefs) bool {
	keystr := objstore.DbKeyString("CloudletRefs", key)
	valstr := stm.Get(keystr)
	return s.parseGetData([]byte(valstr), buf)
}

func (s *CloudletRefsStoreImpl) STMHas(stm concurrency.STM, key *CloudletKey) bool {
	keystr := objstore.DbKeyString("CloudletRefs", key)
	return stm.Get(keystr) != ""
}

func (s *CloudletRefsStoreImpl) parseGetData(val []byte, buf *CloudletRefs) bool {
	if len(val) == 0 {
		return false
	}
	if buf != nil {
		// clear buf, because empty values in val won't
		// overwrite non-empty values in buf.
		*buf = CloudletRefs{}
		err := json.Unmarshal(val, buf)
		if err != nil {
			return false
		}
	}
	return true
}

func (s *CloudletRefsStoreImpl) STMPut(stm concurrency.STM, obj *CloudletRefs, ops ...objstore.KVOp) {
	keystr := objstore.DbKeyString("CloudletRefs", obj.GetKey())

	val, err := json.Marshal(obj)
	if err != nil {
		log.InfoLog("CloudletRefs json marshal failed", "obj", obj, "err", err)
	}
	v3opts := GetSTMOpts(ops...)
	stm.Put(keystr, string(val), v3opts...)
}

func (s *CloudletRefsStoreImpl) STMDel(stm concurrency.STM, key *CloudletKey) {
	keystr := objstore.DbKeyString("CloudletRefs", key)
	stm.Del(keystr)
}

func StoreListCloudletRefs(ctx context.Context, kvstore objstore.KVStore) ([]CloudletRefs, error) {
	keyPrefix := objstore.DbKeyPrefixString("CloudletRefs") + "/"
	objs := []CloudletRefs{}
	err := kvstore.List(keyPrefix, func(key, val []byte, rev, modRev int64) error {
		obj := CloudletRefs{}
		err := json.Unmarshal(val, &obj)
		if err != nil {
			return fmt.Errorf("failed to unmarshal CloudletRefs json %s, %s", string(val), err)
		}
		objs = append(objs, obj)
		return nil
	})
	return objs, err
}

type CloudletRefsKeyWatcher struct {
	cb func(ctx context.Context)
}

type CloudletRefsCacheData struct {
	Obj    *CloudletRefs
	ModRev int64
}

func (s *CloudletRefsCacheData) Clone() *CloudletRefsCacheData {
	cp := CloudletRefsCacheData{}
	if s.Obj != nil {
		cp.Obj = &CloudletRefs{}
		cp.Obj.DeepCopyIn(s.Obj)
	}
	cp.ModRev = s.ModRev
	return &cp
}

// CloudletRefsCache caches CloudletRefs objects in memory in a hash table
// and keeps them in sync with the database.
type CloudletRefsCache struct {
	Objs          map[CloudletKey]*CloudletRefsCacheData
	Mux           util.Mutex
	List          map[CloudletKey]struct{}
	FlushAll      bool
	NotifyCbs     []func(ctx context.Context, obj *CloudletRefs, modRev int64)
	UpdatedCbs    []func(ctx context.Context, old *CloudletRefs, new *CloudletRefs)
	DeletedCbs    []func(ctx context.Context, old *CloudletRefs)
	KeyWatchers   map[CloudletKey][]*CloudletRefsKeyWatcher
	UpdatedKeyCbs []func(ctx context.Context, key *CloudletKey)
	DeletedKeyCbs []func(ctx context.Context, key *CloudletKey)
	Store         CloudletRefsStore
}

func NewCloudletRefsCache() *CloudletRefsCache {
	cache := CloudletRefsCache{}
	InitCloudletRefsCache(&cache)
	return &cache
}

func InitCloudletRefsCache(cache *CloudletRefsCache) {
	cache.Objs = make(map[CloudletKey]*CloudletRefsCacheData)
	cache.KeyWatchers = make(map[CloudletKey][]*CloudletRefsKeyWatcher)
	cache.NotifyCbs = nil
	cache.UpdatedCbs = nil
	cache.DeletedCbs = nil
	cache.UpdatedKeyCbs = nil
	cache.DeletedKeyCbs = nil
}

func (c *CloudletRefsCache) GetTypeString() string {
	return "CloudletRefs"
}

func (c *CloudletRefsCache) Get(key *CloudletKey, valbuf *CloudletRefs) bool {
	var modRev int64
	return c.GetWithRev(key, valbuf, &modRev)
}

func (c *CloudletRefsCache) GetWithRev(key *CloudletKey, valbuf *CloudletRefs, modRev *int64) bool {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	inst, found := c.Objs[*key]
	if found {
		valbuf.DeepCopyIn(inst.Obj)
		*modRev = inst.ModRev
	}
	return found
}

func (c *CloudletRefsCache) HasKey(key *CloudletKey) bool {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	_, found := c.Objs[*key]
	return found
}

func (c *CloudletRefsCache) GetAllKeys(ctx context.Context, cb func(key *CloudletKey, modRev int64)) {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for key, data := range c.Objs {
		cb(&key, data.ModRev)
	}
}

func (c *CloudletRefsCache) GetAllLocked(ctx context.Context, cb func(obj *CloudletRefs, modRev int64)) {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for _, data := range c.Objs {
		cb(data.Obj, data.ModRev)
	}
}

func (c *CloudletRefsCache) Update(ctx context.Context, in *CloudletRefs, modRev int64) {
	c.UpdateModFunc(ctx, in.GetKey(), modRev, func(old *CloudletRefs) (*CloudletRefs, bool) {
		return in, true
	})
}

func (c *CloudletRefsCache) UpdateModFunc(ctx context.Context, key *CloudletKey, modRev int64, modFunc func(old *CloudletRefs) (new *CloudletRefs, changed bool)) {
	c.Mux.Lock()
	var old *CloudletRefs
	if oldData, found := c.Objs[*key]; found {
		old = oldData.Obj
	}
	new, changed := modFunc(old)
	if !changed {
		c.Mux.Unlock()
		return
	}
	if len(c.UpdatedCbs) > 0 || len(c.NotifyCbs) > 0 {
		newCopy := &CloudletRefs{}
		newCopy.DeepCopyIn(new)
		for _, cb := range c.UpdatedCbs {
			defer cb(ctx, old, newCopy)
		}
		for _, cb := range c.NotifyCbs {
			if cb != nil {
				defer cb(ctx, newCopy, modRev)
			}
		}
	}
	for _, cb := range c.UpdatedKeyCbs {
		defer cb(ctx, key)
	}
	store := &CloudletRefs{}
	store.DeepCopyIn(new)
	c.Objs[new.GetKeyVal()] = &CloudletRefsCacheData{
		Obj:    store,
		ModRev: modRev,
	}
	log.SpanLog(ctx, log.DebugLevelApi, "cache update", "new", store)
	c.Mux.Unlock()
	c.TriggerKeyWatchers(ctx, new.GetKey())
}

func (c *CloudletRefsCache) Delete(ctx context.Context, in *CloudletRefs, modRev int64) {
	c.DeleteCondFunc(ctx, in, modRev, func(old *CloudletRefs) bool {
		return true
	})
}

func (c *CloudletRefsCache) DeleteCondFunc(ctx context.Context, in *CloudletRefs, modRev int64, condFunc func(old *CloudletRefs) bool) {
	c.Mux.Lock()
	var old *CloudletRefs
	oldData, found := c.Objs[in.GetKeyVal()]
	if found {
		old = oldData.Obj
		if !condFunc(old) {
			c.Mux.Unlock()
			return
		}
	}
	delete(c.Objs, in.GetKeyVal())
	log.SpanLog(ctx, log.DebugLevelApi, "cache delete", "key", in.GetKeyVal())
	c.Mux.Unlock()
	obj := old
	if obj == nil {
		obj = in
	}
	for _, cb := range c.NotifyCbs {
		if cb != nil {
			cb(ctx, obj, modRev)
		}
	}
	if old != nil {
		for _, cb := range c.DeletedCbs {
			cb(ctx, old)
		}
	}
	for _, cb := range c.DeletedKeyCbs {
		cb(ctx, in.GetKey())
	}
	c.TriggerKeyWatchers(ctx, in.GetKey())
}

func (c *CloudletRefsCache) Prune(ctx context.Context, validKeys map[CloudletKey]struct{}) {
	log.SpanLog(ctx, log.DebugLevelApi, "Prune CloudletRefs", "numValidKeys", len(validKeys))
	notify := make(map[CloudletKey]*CloudletRefsCacheData)
	c.Mux.Lock()
	for key, _ := range c.Objs {
		if _, ok := validKeys[key]; !ok {
			if len(c.NotifyCbs) > 0 || len(c.DeletedKeyCbs) > 0 || len(c.DeletedCbs) > 0 {
				notify[key] = c.Objs[key]
			}
			delete(c.Objs, key)
		}
	}
	c.Mux.Unlock()
	for key, old := range notify {
		obj := old.Obj
		if obj == nil {
			obj = &CloudletRefs{}
			obj.SetKey(&key)
		}
		for _, cb := range c.NotifyCbs {
			if cb != nil {
				cb(ctx, obj, old.ModRev)
			}
		}
		for _, cb := range c.DeletedKeyCbs {
			cb(ctx, &key)
		}
		if old.Obj != nil {
			for _, cb := range c.DeletedCbs {
				cb(ctx, old.Obj)
			}
		}
		c.TriggerKeyWatchers(ctx, &key)
	}
}

func (c *CloudletRefsCache) GetCount() int {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	return len(c.Objs)
}

func (c *CloudletRefsCache) Flush(ctx context.Context, notifyId int64) {
}

func (c *CloudletRefsCache) Show(filter *CloudletRefs, cb func(ret *CloudletRefs) error) error {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for _, data := range c.Objs {
		if !data.Obj.Matches(filter, MatchFilter()) {
			continue
		}
		err := cb(data.Obj)
		if err != nil {
			return err
		}
	}
	return nil
}

func CloudletRefsGenericNotifyCb(fn func(key *CloudletKey, old *CloudletRefs)) func(objstore.ObjKey, objstore.Obj) {
	return func(objkey objstore.ObjKey, obj objstore.Obj) {
		fn(objkey.(*CloudletKey), obj.(*CloudletRefs))
	}
}

func (c *CloudletRefsCache) SetNotifyCb(fn func(ctx context.Context, obj *CloudletRefs, modRev int64)) {
	c.NotifyCbs = []func(ctx context.Context, obj *CloudletRefs, modRev int64){fn}
}

func (c *CloudletRefsCache) SetUpdatedCb(fn func(ctx context.Context, old *CloudletRefs, new *CloudletRefs)) {
	c.UpdatedCbs = []func(ctx context.Context, old *CloudletRefs, new *CloudletRefs){fn}
}

func (c *CloudletRefsCache) SetDeletedCb(fn func(ctx context.Context, old *CloudletRefs)) {
	c.DeletedCbs = []func(ctx context.Context, old *CloudletRefs){fn}
}

func (c *CloudletRefsCache) SetUpdatedKeyCb(fn func(ctx context.Context, key *CloudletKey)) {
	c.UpdatedKeyCbs = []func(ctx context.Context, key *CloudletKey){fn}
}

func (c *CloudletRefsCache) SetDeletedKeyCb(fn func(ctx context.Context, key *CloudletKey)) {
	c.DeletedKeyCbs = []func(ctx context.Context, key *CloudletKey){fn}
}

func (c *CloudletRefsCache) AddUpdatedCb(fn func(ctx context.Context, old *CloudletRefs, new *CloudletRefs)) {
	c.UpdatedCbs = append(c.UpdatedCbs, fn)
}

func (c *CloudletRefsCache) AddDeletedCb(fn func(ctx context.Context, old *CloudletRefs)) {
	c.DeletedCbs = append(c.DeletedCbs, fn)
}

func (c *CloudletRefsCache) AddNotifyCb(fn func(ctx context.Context, obj *CloudletRefs, modRev int64)) {
	c.NotifyCbs = append(c.NotifyCbs, fn)
}

func (c *CloudletRefsCache) AddUpdatedKeyCb(fn func(ctx context.Context, key *CloudletKey)) {
	c.UpdatedKeyCbs = append(c.UpdatedKeyCbs, fn)
}

func (c *CloudletRefsCache) AddDeletedKeyCb(fn func(ctx context.Context, key *CloudletKey)) {
	c.DeletedKeyCbs = append(c.DeletedKeyCbs, fn)
}

func (c *CloudletRefsCache) SetFlushAll() {
	c.FlushAll = true
}

func (c *CloudletRefsCache) WatchKey(key *CloudletKey, cb func(ctx context.Context)) context.CancelFunc {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	list, ok := c.KeyWatchers[*key]
	if !ok {
		list = make([]*CloudletRefsKeyWatcher, 0)
	}
	watcher := CloudletRefsKeyWatcher{cb: cb}
	c.KeyWatchers[*key] = append(list, &watcher)
	log.DebugLog(log.DebugLevelApi, "Watching CloudletRefs", "key", key)
	return func() {
		c.Mux.Lock()
		defer c.Mux.Unlock()
		list, ok := c.KeyWatchers[*key]
		if !ok {
			return
		}
		for ii, _ := range list {
			if list[ii] != &watcher {
				continue
			}
			if len(list) == 1 {
				delete(c.KeyWatchers, *key)
				return
			}
			list[ii] = list[len(list)-1]
			list[len(list)-1] = nil
			c.KeyWatchers[*key] = list[:len(list)-1]
			return
		}
	}
}

func (c *CloudletRefsCache) TriggerKeyWatchers(ctx context.Context, key *CloudletKey) {
	watchers := make([]*CloudletRefsKeyWatcher, 0)
	c.Mux.Lock()
	if list, ok := c.KeyWatchers[*key]; ok {
		watchers = append(watchers, list...)
	}
	c.Mux.Unlock()
	for ii, _ := range watchers {
		watchers[ii].cb(ctx)
	}
}

// Note that we explicitly ignore the global revision number, because of the way
// the notify framework sends updates (by hashing keys and doing lookups, instead
// of sequentially through a history buffer), updates may be done out-of-order
// or multiple updates compressed into one update, so the state of the cache at
// any point in time may not by in sync with a particular database revision number.

func (c *CloudletRefsCache) SyncUpdate(ctx context.Context, key, val []byte, rev, modRev int64) {
	obj := CloudletRefs{}
	err := json.Unmarshal(val, &obj)
	if err != nil {
		log.WarnLog("Failed to parse CloudletRefs data", "val", string(val), "err", err)
		return
	}
	c.Update(ctx, &obj, modRev)
	c.Mux.Lock()
	if c.List != nil {
		c.List[obj.GetKeyVal()] = struct{}{}
	}
	c.Mux.Unlock()
}

func (c *CloudletRefsCache) SyncDelete(ctx context.Context, key []byte, rev, modRev int64) {
	obj := CloudletRefs{}
	keystr := objstore.DbKeyPrefixRemove(string(key))
	CloudletKeyStringParse(keystr, obj.GetKey())
	c.Delete(ctx, &obj, modRev)
}

func (c *CloudletRefsCache) SyncListStart(ctx context.Context) {
	c.List = make(map[CloudletKey]struct{})
}

func (c *CloudletRefsCache) SyncListEnd(ctx context.Context) {
	deleted := make(map[CloudletKey]*CloudletRefsCacheData)
	c.Mux.Lock()
	for key, val := range c.Objs {
		if _, found := c.List[key]; !found {
			deleted[key] = val
			delete(c.Objs, key)
		}
	}
	c.List = nil
	c.Mux.Unlock()
	for key, val := range deleted {
		obj := val.Obj
		if obj == nil {
			obj = &CloudletRefs{}
			obj.SetKey(&key)
		}
		for _, cb := range c.NotifyCbs {
			if cb != nil {
				cb(ctx, obj, val.ModRev)
			}
		}
		for _, cb := range c.DeletedKeyCbs {
			cb(ctx, &key)
		}
		if val.Obj != nil {
			for _, cb := range c.DeletedCbs {
				cb(ctx, val.Obj)
			}
		}
		c.TriggerKeyWatchers(ctx, &key)
	}
}

func (s *CloudletRefsCache) InitCacheWithSync(sync DataSync) {
	InitCloudletRefsCache(s)
	s.InitSync(sync)
}

func (s *CloudletRefsCache) InitSync(sync DataSync) {
	if sync != nil {
		s.Store = NewCloudletRefsStore(sync.GetKVStore())
		sync.RegisterCache(s)
	}
}

func (c *CloudletRefsCache) UsesOrg(org string) bool {
	return false
}

func (m *CloudletRefs) GetObjKey() objstore.ObjKey {
	return m.GetKey()
}

func (m *CloudletRefs) GetKey() *CloudletKey {
	return &m.Key
}

func (m *CloudletRefs) GetKeyVal() CloudletKey {
	return m.Key
}

func (m *CloudletRefs) SetKey(key *CloudletKey) {
	m.Key = *key
}

func CmpSortCloudletRefs(a CloudletRefs, b CloudletRefs) bool {
	return a.Key.GetKeyString() < b.Key.GetKeyString()
}

// Helper method to check that enums have valid values
func (m *CloudletRefs) ValidateEnums() error {
	if err := m.Key.ValidateEnums(); err != nil {
		return err
	}
	for _, e := range m.ClusterInsts {
		if err := e.ValidateEnums(); err != nil {
			return err
		}
	}
	for _, e := range m.VmAppInsts {
		if err := e.ValidateEnums(); err != nil {
			return err
		}
	}
	for _, e := range m.K8SAppInsts {
		if err := e.ValidateEnums(); err != nil {
			return err
		}
	}
	return nil
}

func (s *CloudletRefs) ClearTagged(tags map[string]struct{}) {
	s.Key.ClearTagged(tags)
	if s.ClusterInsts != nil {
		for ii := 0; ii < len(s.ClusterInsts); ii++ {
			s.ClusterInsts[ii].ClearTagged(tags)
		}
	}
	if s.VmAppInsts != nil {
		for ii := 0; ii < len(s.VmAppInsts); ii++ {
			s.VmAppInsts[ii].ClearTagged(tags)
		}
	}
	if s.K8SAppInsts != nil {
		for ii := 0; ii < len(s.K8SAppInsts); ii++ {
			s.K8SAppInsts[ii].ClearTagged(tags)
		}
	}
}

func (m *ClusterRefs) Matches(o *ClusterRefs, fopts ...MatchOpt) bool {
	opts := MatchOptions{}
	applyMatchOptions(&opts, fopts...)
	if o == nil {
		if opts.Filter {
			return true
		}
		return false
	}
	if !m.Key.Matches(&o.Key, fopts...) {
		return false
	}
	if !opts.Filter || o.Apps != nil {
		if len(m.Apps) == 0 && len(o.Apps) > 0 || len(m.Apps) > 0 && len(o.Apps) == 0 {
			return false
		} else if m.Apps != nil && o.Apps != nil {
			if !opts.Filter && len(m.Apps) != len(o.Apps) {
				return false
			}
			if opts.SortArrayedKeys {
				sort.Slice(m.Apps, func(i, j int) bool {
					return m.Apps[i].GetKeyString() < m.Apps[j].GetKeyString()
				})
				sort.Slice(o.Apps, func(i, j int) bool {
					return o.Apps[i].GetKeyString() < o.Apps[j].GetKeyString()
				})
			}
			found := 0
			for oIndex, _ := range o.Apps {
				for mIndex, _ := range m.Apps {
					if m.Apps[mIndex].Matches(&o.Apps[oIndex], fopts...) {
						found++
						break
					}
				}
			}
			if found != len(o.Apps) {
				return false
			}
		}
	}
	return true
}

func (m *ClusterRefs) Clone() *ClusterRefs {
	cp := &ClusterRefs{}
	cp.DeepCopyIn(m)
	return cp
}

func (m *ClusterRefs) AddApps(vals ...AppInstKey) int {
	changes := 0
	cur := make(map[string]struct{})
	for _, v := range m.Apps {
		cur[v.GetKeyString()] = struct{}{}
	}
	for _, v := range vals {
		if _, found := cur[v.GetKeyString()]; found {
			continue // duplicate
		}
		m.Apps = append(m.Apps, v)
		changes++
	}
	return changes
}

func (m *ClusterRefs) RemoveApps(vals ...AppInstKey) int {
	changes := 0
	remove := make(map[string]struct{})
	for _, v := range vals {
		remove[v.GetKeyString()] = struct{}{}
	}
	for i := len(m.Apps); i >= 0; i-- {
		if _, found := remove[m.Apps[i].GetKeyString()]; found {
			m.Apps = append(m.Apps[:i], m.Apps[i+1:]...)
			changes++
		}
	}
	return changes
}

func (m *ClusterRefs) CopyInFields(src *ClusterRefs) int {
	updateListAction := "replace"
	changed := 0
	if m.Key.Name != src.Key.Name {
		m.Key.Name = src.Key.Name
		changed++
	}
	if m.Key.Organization != src.Key.Organization {
		m.Key.Organization = src.Key.Organization
		changed++
	}
	if src.Apps != nil {
		if updateListAction == "add" {
			changed += m.AddApps(src.Apps...)
		} else if updateListAction == "remove" {
			changed += m.RemoveApps(src.Apps...)
		} else {
			m.Apps = make([]AppInstKey, 0)
			for k0, _ := range src.Apps {
				m.Apps = append(m.Apps, *src.Apps[k0].Clone())
			}
			changed++
		}
	} else if m.Apps != nil {
		m.Apps = nil
		changed++
	}
	return changed
}

func (m *ClusterRefs) DeepCopyIn(src *ClusterRefs) {
	m.Key.DeepCopyIn(&src.Key)
	if src.Apps != nil {
		m.Apps = make([]AppInstKey, len(src.Apps), len(src.Apps))
		for ii, s := range src.Apps {
			m.Apps[ii].DeepCopyIn(&s)
		}
	} else {
		m.Apps = nil
	}
}

func (s *ClusterRefs) HasFields() bool {
	return false
}

type ClusterRefsStore interface {
	Create(ctx context.Context, m *ClusterRefs, wait func(int64)) (*Result, error)
	Update(ctx context.Context, m *ClusterRefs, wait func(int64)) (*Result, error)
	Delete(ctx context.Context, m *ClusterRefs, wait func(int64)) (*Result, error)
	Put(ctx context.Context, m *ClusterRefs, wait func(int64), ops ...objstore.KVOp) (*Result, error)
	LoadOne(key string) (*ClusterRefs, int64, error)
	Get(ctx context.Context, key *ClusterKey, buf *ClusterRefs) bool
	STMGet(stm concurrency.STM, key *ClusterKey, buf *ClusterRefs) bool
	STMPut(stm concurrency.STM, obj *ClusterRefs, ops ...objstore.KVOp)
	STMDel(stm concurrency.STM, key *ClusterKey)
	STMHas(stm concurrency.STM, key *ClusterKey) bool
}

type ClusterRefsStoreImpl struct {
	kvstore objstore.KVStore
}

func NewClusterRefsStore(kvstore objstore.KVStore) *ClusterRefsStoreImpl {
	return &ClusterRefsStoreImpl{kvstore: kvstore}
}

func (s *ClusterRefsStoreImpl) Create(ctx context.Context, m *ClusterRefs, wait func(int64)) (*Result, error) {
	err := m.Validate(nil)
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("ClusterRefs", m.GetKey())
	val, err := json.Marshal(m)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Create(ctx, key, string(val))
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *ClusterRefsStoreImpl) Update(ctx context.Context, m *ClusterRefs, wait func(int64)) (*Result, error) {
	err := m.Validate(nil)
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("ClusterRefs", m.GetKey())
	var vers int64 = 0
	val, err := json.Marshal(m)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Update(ctx, key, string(val), vers)
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *ClusterRefsStoreImpl) Put(ctx context.Context, m *ClusterRefs, wait func(int64), ops ...objstore.KVOp) (*Result, error) {
	err := m.Validate(nil)
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("ClusterRefs", m.GetKey())
	var val []byte
	val, err = json.Marshal(m)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Put(ctx, key, string(val), ops...)
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *ClusterRefsStoreImpl) Delete(ctx context.Context, m *ClusterRefs, wait func(int64)) (*Result, error) {
	err := m.GetKey().ValidateKey()
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("ClusterRefs", m.GetKey())
	rev, err := s.kvstore.Delete(ctx, key)
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *ClusterRefsStoreImpl) LoadOne(key string) (*ClusterRefs, int64, error) {
	val, rev, _, err := s.kvstore.Get(key)
	if err != nil {
		return nil, 0, err
	}
	var obj ClusterRefs
	err = json.Unmarshal(val, &obj)
	if err != nil {
		log.DebugLog(log.DebugLevelApi, "Failed to parse ClusterRefs data", "val", string(val), "err", err)
		return nil, 0, err
	}
	return &obj, rev, nil
}

func (s *ClusterRefsStoreImpl) Get(ctx context.Context, key *ClusterKey, buf *ClusterRefs) bool {
	keystr := objstore.DbKeyString("ClusterRefs", key)
	val, _, _, err := s.kvstore.Get(keystr)
	if err != nil {
		return false
	}
	return s.parseGetData(val, buf)
}

func (s *ClusterRefsStoreImpl) STMGet(stm concurrency.STM, key *ClusterKey, buf *ClusterRefs) bool {
	keystr := objstore.DbKeyString("ClusterRefs", key)
	valstr := stm.Get(keystr)
	return s.parseGetData([]byte(valstr), buf)
}

func (s *ClusterRefsStoreImpl) STMHas(stm concurrency.STM, key *ClusterKey) bool {
	keystr := objstore.DbKeyString("ClusterRefs", key)
	return stm.Get(keystr) != ""
}

func (s *ClusterRefsStoreImpl) parseGetData(val []byte, buf *ClusterRefs) bool {
	if len(val) == 0 {
		return false
	}
	if buf != nil {
		// clear buf, because empty values in val won't
		// overwrite non-empty values in buf.
		*buf = ClusterRefs{}
		err := json.Unmarshal(val, buf)
		if err != nil {
			return false
		}
	}
	return true
}

func (s *ClusterRefsStoreImpl) STMPut(stm concurrency.STM, obj *ClusterRefs, ops ...objstore.KVOp) {
	keystr := objstore.DbKeyString("ClusterRefs", obj.GetKey())

	val, err := json.Marshal(obj)
	if err != nil {
		log.InfoLog("ClusterRefs json marshal failed", "obj", obj, "err", err)
	}
	v3opts := GetSTMOpts(ops...)
	stm.Put(keystr, string(val), v3opts...)
}

func (s *ClusterRefsStoreImpl) STMDel(stm concurrency.STM, key *ClusterKey) {
	keystr := objstore.DbKeyString("ClusterRefs", key)
	stm.Del(keystr)
}

func StoreListClusterRefs(ctx context.Context, kvstore objstore.KVStore) ([]ClusterRefs, error) {
	keyPrefix := objstore.DbKeyPrefixString("ClusterRefs") + "/"
	objs := []ClusterRefs{}
	err := kvstore.List(keyPrefix, func(key, val []byte, rev, modRev int64) error {
		obj := ClusterRefs{}
		err := json.Unmarshal(val, &obj)
		if err != nil {
			return fmt.Errorf("failed to unmarshal ClusterRefs json %s, %s", string(val), err)
		}
		objs = append(objs, obj)
		return nil
	})
	return objs, err
}

type ClusterRefsKeyWatcher struct {
	cb func(ctx context.Context)
}

type ClusterRefsCacheData struct {
	Obj    *ClusterRefs
	ModRev int64
}

func (s *ClusterRefsCacheData) Clone() *ClusterRefsCacheData {
	cp := ClusterRefsCacheData{}
	if s.Obj != nil {
		cp.Obj = &ClusterRefs{}
		cp.Obj.DeepCopyIn(s.Obj)
	}
	cp.ModRev = s.ModRev
	return &cp
}

// ClusterRefsCache caches ClusterRefs objects in memory in a hash table
// and keeps them in sync with the database.
type ClusterRefsCache struct {
	Objs          map[ClusterKey]*ClusterRefsCacheData
	Mux           util.Mutex
	List          map[ClusterKey]struct{}
	FlushAll      bool
	NotifyCbs     []func(ctx context.Context, obj *ClusterRefs, modRev int64)
	UpdatedCbs    []func(ctx context.Context, old *ClusterRefs, new *ClusterRefs)
	DeletedCbs    []func(ctx context.Context, old *ClusterRefs)
	KeyWatchers   map[ClusterKey][]*ClusterRefsKeyWatcher
	UpdatedKeyCbs []func(ctx context.Context, key *ClusterKey)
	DeletedKeyCbs []func(ctx context.Context, key *ClusterKey)
	Store         ClusterRefsStore
}

func NewClusterRefsCache() *ClusterRefsCache {
	cache := ClusterRefsCache{}
	InitClusterRefsCache(&cache)
	return &cache
}

func InitClusterRefsCache(cache *ClusterRefsCache) {
	cache.Objs = make(map[ClusterKey]*ClusterRefsCacheData)
	cache.KeyWatchers = make(map[ClusterKey][]*ClusterRefsKeyWatcher)
	cache.NotifyCbs = nil
	cache.UpdatedCbs = nil
	cache.DeletedCbs = nil
	cache.UpdatedKeyCbs = nil
	cache.DeletedKeyCbs = nil
}

func (c *ClusterRefsCache) GetTypeString() string {
	return "ClusterRefs"
}

func (c *ClusterRefsCache) Get(key *ClusterKey, valbuf *ClusterRefs) bool {
	var modRev int64
	return c.GetWithRev(key, valbuf, &modRev)
}

func (c *ClusterRefsCache) GetWithRev(key *ClusterKey, valbuf *ClusterRefs, modRev *int64) bool {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	inst, found := c.Objs[*key]
	if found {
		valbuf.DeepCopyIn(inst.Obj)
		*modRev = inst.ModRev
	}
	return found
}

func (c *ClusterRefsCache) HasKey(key *ClusterKey) bool {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	_, found := c.Objs[*key]
	return found
}

func (c *ClusterRefsCache) GetAllKeys(ctx context.Context, cb func(key *ClusterKey, modRev int64)) {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for key, data := range c.Objs {
		cb(&key, data.ModRev)
	}
}

func (c *ClusterRefsCache) GetAllLocked(ctx context.Context, cb func(obj *ClusterRefs, modRev int64)) {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for _, data := range c.Objs {
		cb(data.Obj, data.ModRev)
	}
}

func (c *ClusterRefsCache) Update(ctx context.Context, in *ClusterRefs, modRev int64) {
	c.UpdateModFunc(ctx, in.GetKey(), modRev, func(old *ClusterRefs) (*ClusterRefs, bool) {
		return in, true
	})
}

func (c *ClusterRefsCache) UpdateModFunc(ctx context.Context, key *ClusterKey, modRev int64, modFunc func(old *ClusterRefs) (new *ClusterRefs, changed bool)) {
	c.Mux.Lock()
	var old *ClusterRefs
	if oldData, found := c.Objs[*key]; found {
		old = oldData.Obj
	}
	new, changed := modFunc(old)
	if !changed {
		c.Mux.Unlock()
		return
	}
	if len(c.UpdatedCbs) > 0 || len(c.NotifyCbs) > 0 {
		newCopy := &ClusterRefs{}
		newCopy.DeepCopyIn(new)
		for _, cb := range c.UpdatedCbs {
			defer cb(ctx, old, newCopy)
		}
		for _, cb := range c.NotifyCbs {
			if cb != nil {
				defer cb(ctx, newCopy, modRev)
			}
		}
	}
	for _, cb := range c.UpdatedKeyCbs {
		defer cb(ctx, key)
	}
	store := &ClusterRefs{}
	store.DeepCopyIn(new)
	c.Objs[new.GetKeyVal()] = &ClusterRefsCacheData{
		Obj:    store,
		ModRev: modRev,
	}
	log.SpanLog(ctx, log.DebugLevelApi, "cache update", "new", store)
	c.Mux.Unlock()
	c.TriggerKeyWatchers(ctx, new.GetKey())
}

func (c *ClusterRefsCache) Delete(ctx context.Context, in *ClusterRefs, modRev int64) {
	c.DeleteCondFunc(ctx, in, modRev, func(old *ClusterRefs) bool {
		return true
	})
}

func (c *ClusterRefsCache) DeleteCondFunc(ctx context.Context, in *ClusterRefs, modRev int64, condFunc func(old *ClusterRefs) bool) {
	c.Mux.Lock()
	var old *ClusterRefs
	oldData, found := c.Objs[in.GetKeyVal()]
	if found {
		old = oldData.Obj
		if !condFunc(old) {
			c.Mux.Unlock()
			return
		}
	}
	delete(c.Objs, in.GetKeyVal())
	log.SpanLog(ctx, log.DebugLevelApi, "cache delete", "key", in.GetKeyVal())
	c.Mux.Unlock()
	obj := old
	if obj == nil {
		obj = in
	}
	for _, cb := range c.NotifyCbs {
		if cb != nil {
			cb(ctx, obj, modRev)
		}
	}
	if old != nil {
		for _, cb := range c.DeletedCbs {
			cb(ctx, old)
		}
	}
	for _, cb := range c.DeletedKeyCbs {
		cb(ctx, in.GetKey())
	}
	c.TriggerKeyWatchers(ctx, in.GetKey())
}

func (c *ClusterRefsCache) Prune(ctx context.Context, validKeys map[ClusterKey]struct{}) {
	log.SpanLog(ctx, log.DebugLevelApi, "Prune ClusterRefs", "numValidKeys", len(validKeys))
	notify := make(map[ClusterKey]*ClusterRefsCacheData)
	c.Mux.Lock()
	for key, _ := range c.Objs {
		if _, ok := validKeys[key]; !ok {
			if len(c.NotifyCbs) > 0 || len(c.DeletedKeyCbs) > 0 || len(c.DeletedCbs) > 0 {
				notify[key] = c.Objs[key]
			}
			delete(c.Objs, key)
		}
	}
	c.Mux.Unlock()
	for key, old := range notify {
		obj := old.Obj
		if obj == nil {
			obj = &ClusterRefs{}
			obj.SetKey(&key)
		}
		for _, cb := range c.NotifyCbs {
			if cb != nil {
				cb(ctx, obj, old.ModRev)
			}
		}
		for _, cb := range c.DeletedKeyCbs {
			cb(ctx, &key)
		}
		if old.Obj != nil {
			for _, cb := range c.DeletedCbs {
				cb(ctx, old.Obj)
			}
		}
		c.TriggerKeyWatchers(ctx, &key)
	}
}

func (c *ClusterRefsCache) GetCount() int {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	return len(c.Objs)
}

func (c *ClusterRefsCache) Flush(ctx context.Context, notifyId int64) {
}

func (c *ClusterRefsCache) Show(filter *ClusterRefs, cb func(ret *ClusterRefs) error) error {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for _, data := range c.Objs {
		if !data.Obj.Matches(filter, MatchFilter()) {
			continue
		}
		err := cb(data.Obj)
		if err != nil {
			return err
		}
	}
	return nil
}

func ClusterRefsGenericNotifyCb(fn func(key *ClusterKey, old *ClusterRefs)) func(objstore.ObjKey, objstore.Obj) {
	return func(objkey objstore.ObjKey, obj objstore.Obj) {
		fn(objkey.(*ClusterKey), obj.(*ClusterRefs))
	}
}

func (c *ClusterRefsCache) SetNotifyCb(fn func(ctx context.Context, obj *ClusterRefs, modRev int64)) {
	c.NotifyCbs = []func(ctx context.Context, obj *ClusterRefs, modRev int64){fn}
}

func (c *ClusterRefsCache) SetUpdatedCb(fn func(ctx context.Context, old *ClusterRefs, new *ClusterRefs)) {
	c.UpdatedCbs = []func(ctx context.Context, old *ClusterRefs, new *ClusterRefs){fn}
}

func (c *ClusterRefsCache) SetDeletedCb(fn func(ctx context.Context, old *ClusterRefs)) {
	c.DeletedCbs = []func(ctx context.Context, old *ClusterRefs){fn}
}

func (c *ClusterRefsCache) SetUpdatedKeyCb(fn func(ctx context.Context, key *ClusterKey)) {
	c.UpdatedKeyCbs = []func(ctx context.Context, key *ClusterKey){fn}
}

func (c *ClusterRefsCache) SetDeletedKeyCb(fn func(ctx context.Context, key *ClusterKey)) {
	c.DeletedKeyCbs = []func(ctx context.Context, key *ClusterKey){fn}
}

func (c *ClusterRefsCache) AddUpdatedCb(fn func(ctx context.Context, old *ClusterRefs, new *ClusterRefs)) {
	c.UpdatedCbs = append(c.UpdatedCbs, fn)
}

func (c *ClusterRefsCache) AddDeletedCb(fn func(ctx context.Context, old *ClusterRefs)) {
	c.DeletedCbs = append(c.DeletedCbs, fn)
}

func (c *ClusterRefsCache) AddNotifyCb(fn func(ctx context.Context, obj *ClusterRefs, modRev int64)) {
	c.NotifyCbs = append(c.NotifyCbs, fn)
}

func (c *ClusterRefsCache) AddUpdatedKeyCb(fn func(ctx context.Context, key *ClusterKey)) {
	c.UpdatedKeyCbs = append(c.UpdatedKeyCbs, fn)
}

func (c *ClusterRefsCache) AddDeletedKeyCb(fn func(ctx context.Context, key *ClusterKey)) {
	c.DeletedKeyCbs = append(c.DeletedKeyCbs, fn)
}

func (c *ClusterRefsCache) SetFlushAll() {
	c.FlushAll = true
}

func (c *ClusterRefsCache) WatchKey(key *ClusterKey, cb func(ctx context.Context)) context.CancelFunc {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	list, ok := c.KeyWatchers[*key]
	if !ok {
		list = make([]*ClusterRefsKeyWatcher, 0)
	}
	watcher := ClusterRefsKeyWatcher{cb: cb}
	c.KeyWatchers[*key] = append(list, &watcher)
	log.DebugLog(log.DebugLevelApi, "Watching ClusterRefs", "key", key)
	return func() {
		c.Mux.Lock()
		defer c.Mux.Unlock()
		list, ok := c.KeyWatchers[*key]
		if !ok {
			return
		}
		for ii, _ := range list {
			if list[ii] != &watcher {
				continue
			}
			if len(list) == 1 {
				delete(c.KeyWatchers, *key)
				return
			}
			list[ii] = list[len(list)-1]
			list[len(list)-1] = nil
			c.KeyWatchers[*key] = list[:len(list)-1]
			return
		}
	}
}

func (c *ClusterRefsCache) TriggerKeyWatchers(ctx context.Context, key *ClusterKey) {
	watchers := make([]*ClusterRefsKeyWatcher, 0)
	c.Mux.Lock()
	if list, ok := c.KeyWatchers[*key]; ok {
		watchers = append(watchers, list...)
	}
	c.Mux.Unlock()
	for ii, _ := range watchers {
		watchers[ii].cb(ctx)
	}
}

// Note that we explicitly ignore the global revision number, because of the way
// the notify framework sends updates (by hashing keys and doing lookups, instead
// of sequentially through a history buffer), updates may be done out-of-order
// or multiple updates compressed into one update, so the state of the cache at
// any point in time may not by in sync with a particular database revision number.

func (c *ClusterRefsCache) SyncUpdate(ctx context.Context, key, val []byte, rev, modRev int64) {
	obj := ClusterRefs{}
	err := json.Unmarshal(val, &obj)
	if err != nil {
		log.WarnLog("Failed to parse ClusterRefs data", "val", string(val), "err", err)
		return
	}
	c.Update(ctx, &obj, modRev)
	c.Mux.Lock()
	if c.List != nil {
		c.List[obj.GetKeyVal()] = struct{}{}
	}
	c.Mux.Unlock()
}

func (c *ClusterRefsCache) SyncDelete(ctx context.Context, key []byte, rev, modRev int64) {
	obj := ClusterRefs{}
	keystr := objstore.DbKeyPrefixRemove(string(key))
	ClusterKeyStringParse(keystr, obj.GetKey())
	c.Delete(ctx, &obj, modRev)
}

func (c *ClusterRefsCache) SyncListStart(ctx context.Context) {
	c.List = make(map[ClusterKey]struct{})
}

func (c *ClusterRefsCache) SyncListEnd(ctx context.Context) {
	deleted := make(map[ClusterKey]*ClusterRefsCacheData)
	c.Mux.Lock()
	for key, val := range c.Objs {
		if _, found := c.List[key]; !found {
			deleted[key] = val
			delete(c.Objs, key)
		}
	}
	c.List = nil
	c.Mux.Unlock()
	for key, val := range deleted {
		obj := val.Obj
		if obj == nil {
			obj = &ClusterRefs{}
			obj.SetKey(&key)
		}
		for _, cb := range c.NotifyCbs {
			if cb != nil {
				cb(ctx, obj, val.ModRev)
			}
		}
		for _, cb := range c.DeletedKeyCbs {
			cb(ctx, &key)
		}
		if val.Obj != nil {
			for _, cb := range c.DeletedCbs {
				cb(ctx, val.Obj)
			}
		}
		c.TriggerKeyWatchers(ctx, &key)
	}
}

func (s *ClusterRefsCache) InitCacheWithSync(sync DataSync) {
	InitClusterRefsCache(s)
	s.InitSync(sync)
}

func (s *ClusterRefsCache) InitSync(sync DataSync) {
	if sync != nil {
		s.Store = NewClusterRefsStore(sync.GetKVStore())
		sync.RegisterCache(s)
	}
}

func (c *ClusterRefsCache) UsesOrg(org string) bool {
	return false
}

func (m *ClusterRefs) GetObjKey() objstore.ObjKey {
	return m.GetKey()
}

func (m *ClusterRefs) GetKey() *ClusterKey {
	return &m.Key
}

func (m *ClusterRefs) GetKeyVal() ClusterKey {
	return m.Key
}

func (m *ClusterRefs) SetKey(key *ClusterKey) {
	m.Key = *key
}

func CmpSortClusterRefs(a ClusterRefs, b ClusterRefs) bool {
	return a.Key.GetKeyString() < b.Key.GetKeyString()
}

// Helper method to check that enums have valid values
func (m *ClusterRefs) ValidateEnums() error {
	if err := m.Key.ValidateEnums(); err != nil {
		return err
	}
	for _, e := range m.Apps {
		if err := e.ValidateEnums(); err != nil {
			return err
		}
	}
	return nil
}

func (s *ClusterRefs) ClearTagged(tags map[string]struct{}) {
	s.Key.ClearTagged(tags)
	if s.Apps != nil {
		for ii := 0; ii < len(s.Apps); ii++ {
			s.Apps[ii].ClearTagged(tags)
		}
	}
}

func (m *AppInstRefs) Matches(o *AppInstRefs, fopts ...MatchOpt) bool {
	opts := MatchOptions{}
	applyMatchOptions(&opts, fopts...)
	if o == nil {
		if opts.Filter {
			return true
		}
		return false
	}
	if !m.Key.Matches(&o.Key, fopts...) {
		return false
	}
	if !opts.Filter || o.Insts != nil {
		if len(m.Insts) == 0 && len(o.Insts) > 0 || len(m.Insts) > 0 && len(o.Insts) == 0 {
			return false
		} else if m.Insts != nil && o.Insts != nil {
			if !opts.Filter && len(m.Insts) != len(o.Insts) {
				return false
			}
			for k, _ := range o.Insts {
				_, ok := m.Insts[k]
				if !ok {
					return false
				}
				if o.Insts[k] != m.Insts[k] {
					return false
				}
			}
		}
	}
	if !opts.Filter || o.DeleteRequestedInsts != nil {
		if len(m.DeleteRequestedInsts) == 0 && len(o.DeleteRequestedInsts) > 0 || len(m.DeleteRequestedInsts) > 0 && len(o.DeleteRequestedInsts) == 0 {
			return false
		} else if m.DeleteRequestedInsts != nil && o.DeleteRequestedInsts != nil {
			if !opts.Filter && len(m.DeleteRequestedInsts) != len(o.DeleteRequestedInsts) {
				return false
			}
			for k, _ := range o.DeleteRequestedInsts {
				_, ok := m.DeleteRequestedInsts[k]
				if !ok {
					return false
				}
				if o.DeleteRequestedInsts[k] != m.DeleteRequestedInsts[k] {
					return false
				}
			}
		}
	}
	return true
}

func (m *AppInstRefs) Clone() *AppInstRefs {
	cp := &AppInstRefs{}
	cp.DeepCopyIn(m)
	return cp
}

func (m *AppInstRefs) CopyInFields(src *AppInstRefs) int {
	updateListAction := "replace"
	changed := 0
	if m.Key.Organization != src.Key.Organization {
		m.Key.Organization = src.Key.Organization
		changed++
	}
	if m.Key.Name != src.Key.Name {
		m.Key.Name = src.Key.Name
		changed++
	}
	if m.Key.Version != src.Key.Version {
		m.Key.Version = src.Key.Version
		changed++
	}
	if src.Insts != nil {
		if updateListAction == "add" {
			for k0, v := range src.Insts {
				m.Insts[k0] = v
				changed++
			}
		} else if updateListAction == "remove" {
			for k0, _ := range src.Insts {
				if _, ok := m.Insts[k0]; ok {
					delete(m.Insts, k0)
					changed++
				}
			}
		} else {
			m.Insts = make(map[string]uint32)
			for k0, v := range src.Insts {
				m.Insts[k0] = v
			}
			changed++
		}
	} else if m.Insts != nil {
		m.Insts = nil
		changed++
	}
	if src.DeleteRequestedInsts != nil {
		if updateListAction == "add" {
			for k0, v := range src.DeleteRequestedInsts {
				m.DeleteRequestedInsts[k0] = v
				changed++
			}
		} else if updateListAction == "remove" {
			for k0, _ := range src.DeleteRequestedInsts {
				if _, ok := m.DeleteRequestedInsts[k0]; ok {
					delete(m.DeleteRequestedInsts, k0)
					changed++
				}
			}
		} else {
			m.DeleteRequestedInsts = make(map[string]uint32)
			for k0, v := range src.DeleteRequestedInsts {
				m.DeleteRequestedInsts[k0] = v
			}
			changed++
		}
	} else if m.DeleteRequestedInsts != nil {
		m.DeleteRequestedInsts = nil
		changed++
	}
	return changed
}

func (m *AppInstRefs) DeepCopyIn(src *AppInstRefs) {
	m.Key.DeepCopyIn(&src.Key)
	if src.Insts != nil {
		m.Insts = make(map[string]uint32)
		for k, v := range src.Insts {
			m.Insts[k] = v
		}
	} else {
		m.Insts = nil
	}
	if src.DeleteRequestedInsts != nil {
		m.DeleteRequestedInsts = make(map[string]uint32)
		for k, v := range src.DeleteRequestedInsts {
			m.DeleteRequestedInsts[k] = v
		}
	} else {
		m.DeleteRequestedInsts = nil
	}
}

func (s *AppInstRefs) HasFields() bool {
	return false
}

type AppInstRefsStore interface {
	Create(ctx context.Context, m *AppInstRefs, wait func(int64)) (*Result, error)
	Update(ctx context.Context, m *AppInstRefs, wait func(int64)) (*Result, error)
	Delete(ctx context.Context, m *AppInstRefs, wait func(int64)) (*Result, error)
	Put(ctx context.Context, m *AppInstRefs, wait func(int64), ops ...objstore.KVOp) (*Result, error)
	LoadOne(key string) (*AppInstRefs, int64, error)
	Get(ctx context.Context, key *AppKey, buf *AppInstRefs) bool
	STMGet(stm concurrency.STM, key *AppKey, buf *AppInstRefs) bool
	STMPut(stm concurrency.STM, obj *AppInstRefs, ops ...objstore.KVOp)
	STMDel(stm concurrency.STM, key *AppKey)
	STMHas(stm concurrency.STM, key *AppKey) bool
}

type AppInstRefsStoreImpl struct {
	kvstore objstore.KVStore
}

func NewAppInstRefsStore(kvstore objstore.KVStore) *AppInstRefsStoreImpl {
	return &AppInstRefsStoreImpl{kvstore: kvstore}
}

func (s *AppInstRefsStoreImpl) Create(ctx context.Context, m *AppInstRefs, wait func(int64)) (*Result, error) {
	err := m.Validate(nil)
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("AppInstRefs", m.GetKey())
	val, err := json.Marshal(m)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Create(ctx, key, string(val))
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *AppInstRefsStoreImpl) Update(ctx context.Context, m *AppInstRefs, wait func(int64)) (*Result, error) {
	err := m.Validate(nil)
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("AppInstRefs", m.GetKey())
	var vers int64 = 0
	val, err := json.Marshal(m)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Update(ctx, key, string(val), vers)
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *AppInstRefsStoreImpl) Put(ctx context.Context, m *AppInstRefs, wait func(int64), ops ...objstore.KVOp) (*Result, error) {
	err := m.Validate(nil)
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("AppInstRefs", m.GetKey())
	var val []byte
	val, err = json.Marshal(m)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Put(ctx, key, string(val), ops...)
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *AppInstRefsStoreImpl) Delete(ctx context.Context, m *AppInstRefs, wait func(int64)) (*Result, error) {
	err := m.GetKey().ValidateKey()
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("AppInstRefs", m.GetKey())
	rev, err := s.kvstore.Delete(ctx, key)
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *AppInstRefsStoreImpl) LoadOne(key string) (*AppInstRefs, int64, error) {
	val, rev, _, err := s.kvstore.Get(key)
	if err != nil {
		return nil, 0, err
	}
	var obj AppInstRefs
	err = json.Unmarshal(val, &obj)
	if err != nil {
		log.DebugLog(log.DebugLevelApi, "Failed to parse AppInstRefs data", "val", string(val), "err", err)
		return nil, 0, err
	}
	return &obj, rev, nil
}

func (s *AppInstRefsStoreImpl) Get(ctx context.Context, key *AppKey, buf *AppInstRefs) bool {
	keystr := objstore.DbKeyString("AppInstRefs", key)
	val, _, _, err := s.kvstore.Get(keystr)
	if err != nil {
		return false
	}
	return s.parseGetData(val, buf)
}

func (s *AppInstRefsStoreImpl) STMGet(stm concurrency.STM, key *AppKey, buf *AppInstRefs) bool {
	keystr := objstore.DbKeyString("AppInstRefs", key)
	valstr := stm.Get(keystr)
	return s.parseGetData([]byte(valstr), buf)
}

func (s *AppInstRefsStoreImpl) STMHas(stm concurrency.STM, key *AppKey) bool {
	keystr := objstore.DbKeyString("AppInstRefs", key)
	return stm.Get(keystr) != ""
}

func (s *AppInstRefsStoreImpl) parseGetData(val []byte, buf *AppInstRefs) bool {
	if len(val) == 0 {
		return false
	}
	if buf != nil {
		// clear buf, because empty values in val won't
		// overwrite non-empty values in buf.
		*buf = AppInstRefs{}
		err := json.Unmarshal(val, buf)
		if err != nil {
			return false
		}
	}
	return true
}

func (s *AppInstRefsStoreImpl) STMPut(stm concurrency.STM, obj *AppInstRefs, ops ...objstore.KVOp) {
	keystr := objstore.DbKeyString("AppInstRefs", obj.GetKey())

	val, err := json.Marshal(obj)
	if err != nil {
		log.InfoLog("AppInstRefs json marshal failed", "obj", obj, "err", err)
	}
	v3opts := GetSTMOpts(ops...)
	stm.Put(keystr, string(val), v3opts...)
}

func (s *AppInstRefsStoreImpl) STMDel(stm concurrency.STM, key *AppKey) {
	keystr := objstore.DbKeyString("AppInstRefs", key)
	stm.Del(keystr)
}

func StoreListAppInstRefs(ctx context.Context, kvstore objstore.KVStore) ([]AppInstRefs, error) {
	keyPrefix := objstore.DbKeyPrefixString("AppInstRefs") + "/"
	objs := []AppInstRefs{}
	err := kvstore.List(keyPrefix, func(key, val []byte, rev, modRev int64) error {
		obj := AppInstRefs{}
		err := json.Unmarshal(val, &obj)
		if err != nil {
			return fmt.Errorf("failed to unmarshal AppInstRefs json %s, %s", string(val), err)
		}
		objs = append(objs, obj)
		return nil
	})
	return objs, err
}

type AppInstRefsKeyWatcher struct {
	cb func(ctx context.Context)
}

type AppInstRefsCacheData struct {
	Obj    *AppInstRefs
	ModRev int64
}

func (s *AppInstRefsCacheData) Clone() *AppInstRefsCacheData {
	cp := AppInstRefsCacheData{}
	if s.Obj != nil {
		cp.Obj = &AppInstRefs{}
		cp.Obj.DeepCopyIn(s.Obj)
	}
	cp.ModRev = s.ModRev
	return &cp
}

// AppInstRefsCache caches AppInstRefs objects in memory in a hash table
// and keeps them in sync with the database.
type AppInstRefsCache struct {
	Objs          map[AppKey]*AppInstRefsCacheData
	Mux           util.Mutex
	List          map[AppKey]struct{}
	FlushAll      bool
	NotifyCbs     []func(ctx context.Context, obj *AppInstRefs, modRev int64)
	UpdatedCbs    []func(ctx context.Context, old *AppInstRefs, new *AppInstRefs)
	DeletedCbs    []func(ctx context.Context, old *AppInstRefs)
	KeyWatchers   map[AppKey][]*AppInstRefsKeyWatcher
	UpdatedKeyCbs []func(ctx context.Context, key *AppKey)
	DeletedKeyCbs []func(ctx context.Context, key *AppKey)
	Store         AppInstRefsStore
}

func NewAppInstRefsCache() *AppInstRefsCache {
	cache := AppInstRefsCache{}
	InitAppInstRefsCache(&cache)
	return &cache
}

func InitAppInstRefsCache(cache *AppInstRefsCache) {
	cache.Objs = make(map[AppKey]*AppInstRefsCacheData)
	cache.KeyWatchers = make(map[AppKey][]*AppInstRefsKeyWatcher)
	cache.NotifyCbs = nil
	cache.UpdatedCbs = nil
	cache.DeletedCbs = nil
	cache.UpdatedKeyCbs = nil
	cache.DeletedKeyCbs = nil
}

func (c *AppInstRefsCache) GetTypeString() string {
	return "AppInstRefs"
}

func (c *AppInstRefsCache) Get(key *AppKey, valbuf *AppInstRefs) bool {
	var modRev int64
	return c.GetWithRev(key, valbuf, &modRev)
}

func (c *AppInstRefsCache) GetWithRev(key *AppKey, valbuf *AppInstRefs, modRev *int64) bool {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	inst, found := c.Objs[*key]
	if found {
		valbuf.DeepCopyIn(inst.Obj)
		*modRev = inst.ModRev
	}
	return found
}

func (c *AppInstRefsCache) HasKey(key *AppKey) bool {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	_, found := c.Objs[*key]
	return found
}

func (c *AppInstRefsCache) GetAllKeys(ctx context.Context, cb func(key *AppKey, modRev int64)) {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for key, data := range c.Objs {
		cb(&key, data.ModRev)
	}
}

func (c *AppInstRefsCache) GetAllLocked(ctx context.Context, cb func(obj *AppInstRefs, modRev int64)) {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for _, data := range c.Objs {
		cb(data.Obj, data.ModRev)
	}
}

func (c *AppInstRefsCache) Update(ctx context.Context, in *AppInstRefs, modRev int64) {
	c.UpdateModFunc(ctx, in.GetKey(), modRev, func(old *AppInstRefs) (*AppInstRefs, bool) {
		return in, true
	})
}

func (c *AppInstRefsCache) UpdateModFunc(ctx context.Context, key *AppKey, modRev int64, modFunc func(old *AppInstRefs) (new *AppInstRefs, changed bool)) {
	c.Mux.Lock()
	var old *AppInstRefs
	if oldData, found := c.Objs[*key]; found {
		old = oldData.Obj
	}
	new, changed := modFunc(old)
	if !changed {
		c.Mux.Unlock()
		return
	}
	if len(c.UpdatedCbs) > 0 || len(c.NotifyCbs) > 0 {
		newCopy := &AppInstRefs{}
		newCopy.DeepCopyIn(new)
		for _, cb := range c.UpdatedCbs {
			defer cb(ctx, old, newCopy)
		}
		for _, cb := range c.NotifyCbs {
			if cb != nil {
				defer cb(ctx, newCopy, modRev)
			}
		}
	}
	for _, cb := range c.UpdatedKeyCbs {
		defer cb(ctx, key)
	}
	store := &AppInstRefs{}
	store.DeepCopyIn(new)
	c.Objs[new.GetKeyVal()] = &AppInstRefsCacheData{
		Obj:    store,
		ModRev: modRev,
	}
	log.SpanLog(ctx, log.DebugLevelApi, "cache update", "new", store)
	c.Mux.Unlock()
	c.TriggerKeyWatchers(ctx, new.GetKey())
}

func (c *AppInstRefsCache) Delete(ctx context.Context, in *AppInstRefs, modRev int64) {
	c.DeleteCondFunc(ctx, in, modRev, func(old *AppInstRefs) bool {
		return true
	})
}

func (c *AppInstRefsCache) DeleteCondFunc(ctx context.Context, in *AppInstRefs, modRev int64, condFunc func(old *AppInstRefs) bool) {
	c.Mux.Lock()
	var old *AppInstRefs
	oldData, found := c.Objs[in.GetKeyVal()]
	if found {
		old = oldData.Obj
		if !condFunc(old) {
			c.Mux.Unlock()
			return
		}
	}
	delete(c.Objs, in.GetKeyVal())
	log.SpanLog(ctx, log.DebugLevelApi, "cache delete", "key", in.GetKeyVal())
	c.Mux.Unlock()
	obj := old
	if obj == nil {
		obj = in
	}
	for _, cb := range c.NotifyCbs {
		if cb != nil {
			cb(ctx, obj, modRev)
		}
	}
	if old != nil {
		for _, cb := range c.DeletedCbs {
			cb(ctx, old)
		}
	}
	for _, cb := range c.DeletedKeyCbs {
		cb(ctx, in.GetKey())
	}
	c.TriggerKeyWatchers(ctx, in.GetKey())
}

func (c *AppInstRefsCache) Prune(ctx context.Context, validKeys map[AppKey]struct{}) {
	log.SpanLog(ctx, log.DebugLevelApi, "Prune AppInstRefs", "numValidKeys", len(validKeys))
	notify := make(map[AppKey]*AppInstRefsCacheData)
	c.Mux.Lock()
	for key, _ := range c.Objs {
		if _, ok := validKeys[key]; !ok {
			if len(c.NotifyCbs) > 0 || len(c.DeletedKeyCbs) > 0 || len(c.DeletedCbs) > 0 {
				notify[key] = c.Objs[key]
			}
			delete(c.Objs, key)
		}
	}
	c.Mux.Unlock()
	for key, old := range notify {
		obj := old.Obj
		if obj == nil {
			obj = &AppInstRefs{}
			obj.SetKey(&key)
		}
		for _, cb := range c.NotifyCbs {
			if cb != nil {
				cb(ctx, obj, old.ModRev)
			}
		}
		for _, cb := range c.DeletedKeyCbs {
			cb(ctx, &key)
		}
		if old.Obj != nil {
			for _, cb := range c.DeletedCbs {
				cb(ctx, old.Obj)
			}
		}
		c.TriggerKeyWatchers(ctx, &key)
	}
}

func (c *AppInstRefsCache) GetCount() int {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	return len(c.Objs)
}

func (c *AppInstRefsCache) Flush(ctx context.Context, notifyId int64) {
}

func (c *AppInstRefsCache) Show(filter *AppInstRefs, cb func(ret *AppInstRefs) error) error {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for _, data := range c.Objs {
		if !data.Obj.Matches(filter, MatchFilter()) {
			continue
		}
		err := cb(data.Obj)
		if err != nil {
			return err
		}
	}
	return nil
}

func AppInstRefsGenericNotifyCb(fn func(key *AppKey, old *AppInstRefs)) func(objstore.ObjKey, objstore.Obj) {
	return func(objkey objstore.ObjKey, obj objstore.Obj) {
		fn(objkey.(*AppKey), obj.(*AppInstRefs))
	}
}

func (c *AppInstRefsCache) SetNotifyCb(fn func(ctx context.Context, obj *AppInstRefs, modRev int64)) {
	c.NotifyCbs = []func(ctx context.Context, obj *AppInstRefs, modRev int64){fn}
}

func (c *AppInstRefsCache) SetUpdatedCb(fn func(ctx context.Context, old *AppInstRefs, new *AppInstRefs)) {
	c.UpdatedCbs = []func(ctx context.Context, old *AppInstRefs, new *AppInstRefs){fn}
}

func (c *AppInstRefsCache) SetDeletedCb(fn func(ctx context.Context, old *AppInstRefs)) {
	c.DeletedCbs = []func(ctx context.Context, old *AppInstRefs){fn}
}

func (c *AppInstRefsCache) SetUpdatedKeyCb(fn func(ctx context.Context, key *AppKey)) {
	c.UpdatedKeyCbs = []func(ctx context.Context, key *AppKey){fn}
}

func (c *AppInstRefsCache) SetDeletedKeyCb(fn func(ctx context.Context, key *AppKey)) {
	c.DeletedKeyCbs = []func(ctx context.Context, key *AppKey){fn}
}

func (c *AppInstRefsCache) AddUpdatedCb(fn func(ctx context.Context, old *AppInstRefs, new *AppInstRefs)) {
	c.UpdatedCbs = append(c.UpdatedCbs, fn)
}

func (c *AppInstRefsCache) AddDeletedCb(fn func(ctx context.Context, old *AppInstRefs)) {
	c.DeletedCbs = append(c.DeletedCbs, fn)
}

func (c *AppInstRefsCache) AddNotifyCb(fn func(ctx context.Context, obj *AppInstRefs, modRev int64)) {
	c.NotifyCbs = append(c.NotifyCbs, fn)
}

func (c *AppInstRefsCache) AddUpdatedKeyCb(fn func(ctx context.Context, key *AppKey)) {
	c.UpdatedKeyCbs = append(c.UpdatedKeyCbs, fn)
}

func (c *AppInstRefsCache) AddDeletedKeyCb(fn func(ctx context.Context, key *AppKey)) {
	c.DeletedKeyCbs = append(c.DeletedKeyCbs, fn)
}

func (c *AppInstRefsCache) SetFlushAll() {
	c.FlushAll = true
}

func (c *AppInstRefsCache) WatchKey(key *AppKey, cb func(ctx context.Context)) context.CancelFunc {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	list, ok := c.KeyWatchers[*key]
	if !ok {
		list = make([]*AppInstRefsKeyWatcher, 0)
	}
	watcher := AppInstRefsKeyWatcher{cb: cb}
	c.KeyWatchers[*key] = append(list, &watcher)
	log.DebugLog(log.DebugLevelApi, "Watching AppInstRefs", "key", key)
	return func() {
		c.Mux.Lock()
		defer c.Mux.Unlock()
		list, ok := c.KeyWatchers[*key]
		if !ok {
			return
		}
		for ii, _ := range list {
			if list[ii] != &watcher {
				continue
			}
			if len(list) == 1 {
				delete(c.KeyWatchers, *key)
				return
			}
			list[ii] = list[len(list)-1]
			list[len(list)-1] = nil
			c.KeyWatchers[*key] = list[:len(list)-1]
			return
		}
	}
}

func (c *AppInstRefsCache) TriggerKeyWatchers(ctx context.Context, key *AppKey) {
	watchers := make([]*AppInstRefsKeyWatcher, 0)
	c.Mux.Lock()
	if list, ok := c.KeyWatchers[*key]; ok {
		watchers = append(watchers, list...)
	}
	c.Mux.Unlock()
	for ii, _ := range watchers {
		watchers[ii].cb(ctx)
	}
}

// Note that we explicitly ignore the global revision number, because of the way
// the notify framework sends updates (by hashing keys and doing lookups, instead
// of sequentially through a history buffer), updates may be done out-of-order
// or multiple updates compressed into one update, so the state of the cache at
// any point in time may not by in sync with a particular database revision number.

func (c *AppInstRefsCache) SyncUpdate(ctx context.Context, key, val []byte, rev, modRev int64) {
	obj := AppInstRefs{}
	err := json.Unmarshal(val, &obj)
	if err != nil {
		log.WarnLog("Failed to parse AppInstRefs data", "val", string(val), "err", err)
		return
	}
	c.Update(ctx, &obj, modRev)
	c.Mux.Lock()
	if c.List != nil {
		c.List[obj.GetKeyVal()] = struct{}{}
	}
	c.Mux.Unlock()
}

func (c *AppInstRefsCache) SyncDelete(ctx context.Context, key []byte, rev, modRev int64) {
	obj := AppInstRefs{}
	keystr := objstore.DbKeyPrefixRemove(string(key))
	AppKeyStringParse(keystr, obj.GetKey())
	c.Delete(ctx, &obj, modRev)
}

func (c *AppInstRefsCache) SyncListStart(ctx context.Context) {
	c.List = make(map[AppKey]struct{})
}

func (c *AppInstRefsCache) SyncListEnd(ctx context.Context) {
	deleted := make(map[AppKey]*AppInstRefsCacheData)
	c.Mux.Lock()
	for key, val := range c.Objs {
		if _, found := c.List[key]; !found {
			deleted[key] = val
			delete(c.Objs, key)
		}
	}
	c.List = nil
	c.Mux.Unlock()
	for key, val := range deleted {
		obj := val.Obj
		if obj == nil {
			obj = &AppInstRefs{}
			obj.SetKey(&key)
		}
		for _, cb := range c.NotifyCbs {
			if cb != nil {
				cb(ctx, obj, val.ModRev)
			}
		}
		for _, cb := range c.DeletedKeyCbs {
			cb(ctx, &key)
		}
		if val.Obj != nil {
			for _, cb := range c.DeletedCbs {
				cb(ctx, val.Obj)
			}
		}
		c.TriggerKeyWatchers(ctx, &key)
	}
}

func (s *AppInstRefsCache) InitCacheWithSync(sync DataSync) {
	InitAppInstRefsCache(s)
	s.InitSync(sync)
}

func (s *AppInstRefsCache) InitSync(sync DataSync) {
	if sync != nil {
		s.Store = NewAppInstRefsStore(sync.GetKVStore())
		sync.RegisterCache(s)
	}
}

func (c *AppInstRefsCache) UsesOrg(org string) bool {
	return false
}

func (m *AppInstRefs) GetObjKey() objstore.ObjKey {
	return m.GetKey()
}

func (m *AppInstRefs) GetKey() *AppKey {
	return &m.Key
}

func (m *AppInstRefs) GetKeyVal() AppKey {
	return m.Key
}

func (m *AppInstRefs) SetKey(key *AppKey) {
	m.Key = *key
}

func CmpSortAppInstRefs(a AppInstRefs, b AppInstRefs) bool {
	return a.Key.GetKeyString() < b.Key.GetKeyString()
}

// Helper method to check that enums have valid values
func (m *AppInstRefs) ValidateEnums() error {
	if err := m.Key.ValidateEnums(); err != nil {
		return err
	}
	return nil
}

func (s *AppInstRefs) ClearTagged(tags map[string]struct{}) {
	s.Key.ClearTagged(tags)
}

func (m *VMResource) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = m.Key.Size()
	n += 1 + l + sovRefs(uint64(l))
	l = len(m.VmFlavor)
	if l > 0 {
		n += 1 + l + sovRefs(uint64(l))
	}
	l = len(m.Type)
	if l > 0 {
		n += 1 + l + sovRefs(uint64(l))
	}
	if m.Count != 0 {
		n += 1 + sovRefs(uint64(m.Count))
	}
	return n
}

func (m *CloudletRefs) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = m.Key.Size()
	n += 1 + l + sovRefs(uint64(l))
	if len(m.RootLbPorts) > 0 {
		for k, v := range m.RootLbPorts {
			_ = k
			_ = v
			mapEntrySize := 1 + sovRefs(uint64(k)) + 1 + sovRefs(uint64(v))
			n += mapEntrySize + 1 + sovRefs(uint64(mapEntrySize))
		}
	}
	if m.UsedDynamicIps != 0 {
		n += 1 + sovRefs(uint64(m.UsedDynamicIps))
	}
	l = len(m.UsedStaticIps)
	if l > 0 {
		n += 1 + l + sovRefs(uint64(l))
	}
	if len(m.OptResUsedMap) > 0 {
		for k, v := range m.OptResUsedMap {
			_ = k
			_ = v
			mapEntrySize := 1 + len(k) + sovRefs(uint64(len(k))) + 1 + sovRefs(uint64(v))
			n += mapEntrySize + 1 + sovRefs(uint64(mapEntrySize))
		}
	}
	if m.ReservedAutoClusterIds != 0 {
		n += 9
	}
	if len(m.ClusterInsts) > 0 {
		for _, e := range m.ClusterInsts {
			l = e.Size()
			n += 1 + l + sovRefs(uint64(l))
		}
	}
	if len(m.VmAppInsts) > 0 {
		for _, e := range m.VmAppInsts {
			l = e.Size()
			n += 1 + l + sovRefs(uint64(l))
		}
	}
	if len(m.K8SAppInsts) > 0 {
		for _, e := range m.K8SAppInsts {
			l = e.Size()
			n += 1 + l + sovRefs(uint64(l))
		}
	}
	return n
}

func (m *ClusterRefs) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = m.Key.Size()
	n += 1 + l + sovRefs(uint64(l))
	if len(m.Apps) > 0 {
		for _, e := range m.Apps {
			l = e.Size()
			n += 1 + l + sovRefs(uint64(l))
		}
	}
	return n
}

func (m *AppInstRefs) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = m.Key.Size()
	n += 1 + l + sovRefs(uint64(l))
	if len(m.Insts) > 0 {
		for k, v := range m.Insts {
			_ = k
			_ = v
			mapEntrySize := 1 + len(k) + sovRefs(uint64(len(k))) + 1 + sovRefs(uint64(v))
			n += mapEntrySize + 1 + sovRefs(uint64(mapEntrySize))
		}
	}
	if len(m.DeleteRequestedInsts) > 0 {
		for k, v := range m.DeleteRequestedInsts {
			_ = k
			_ = v
			mapEntrySize := 1 + len(k) + sovRefs(uint64(len(k))) + 1 + sovRefs(uint64(v))
			n += mapEntrySize + 1 + sovRefs(uint64(mapEntrySize))
		}
	}
	return n
}

func sovRefs(x uint64) (n int) {
	return (math_bits.Len64(x|1) + 6) / 7
}
func sozRefs(x uint64) (n int) {
	return sovRefs(uint64((x << 1) ^ uint64((int64(x) >> 63))))
}
func (m *VMResource) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowRefs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: VMResource: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: VMResource: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Key", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthRefs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Key.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field VmFlavor", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthRefs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.VmFlavor = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Type", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthRefs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Type = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Count", wireType)
			}
			m.Count = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Count |= uint32(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipRefs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthRefs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *CloudletRefs) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowRefs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: CloudletRefs: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: CloudletRefs: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Key", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthRefs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Key.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 8:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field RootLbPorts", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthRefs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.RootLbPorts == nil {
				m.RootLbPorts = make(map[int32]int32)
			}
			var mapkey int32
			var mapvalue int32
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowRefs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowRefs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapkey |= int32(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
				} else if fieldNum == 2 {
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowRefs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapvalue |= int32(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipRefs(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthRefs
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.RootLbPorts[mapkey] = mapvalue
			iNdEx = postIndex
		case 9:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field UsedDynamicIps", wireType)
			}
			m.UsedDynamicIps = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.UsedDynamicIps |= int32(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 10:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field UsedStaticIps", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthRefs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.UsedStaticIps = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 11:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OptResUsedMap", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthRefs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.OptResUsedMap == nil {
				m.OptResUsedMap = make(map[string]uint32)
			}
			var mapkey string
			var mapvalue uint32
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowRefs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					var stringLenmapkey uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowRefs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapkey |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapkey := int(stringLenmapkey)
					if intStringLenmapkey < 0 {
						return ErrInvalidLengthRefs
					}
					postStringIndexmapkey := iNdEx + intStringLenmapkey
					if postStringIndexmapkey < 0 {
						return ErrInvalidLengthRefs
					}
					if postStringIndexmapkey > l {
						return io.ErrUnexpectedEOF
					}
					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
					iNdEx = postStringIndexmapkey
				} else if fieldNum == 2 {
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowRefs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapvalue |= uint32(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipRefs(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthRefs
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.OptResUsedMap[mapkey] = mapvalue
			iNdEx = postIndex
		case 12:
			if wireType != 1 {
				return fmt.Errorf("proto: wrong wireType = %d for field ReservedAutoClusterIds", wireType)
			}
			m.ReservedAutoClusterIds = 0
			if (iNdEx + 8) > l {
				return io.ErrUnexpectedEOF
			}
			m.ReservedAutoClusterIds = uint64(encoding_binary.LittleEndian.Uint64(dAtA[iNdEx:]))
			iNdEx += 8
		case 13:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ClusterInsts", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthRefs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ClusterInsts = append(m.ClusterInsts, ClusterKey{})
			if err := m.ClusterInsts[len(m.ClusterInsts)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 14:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field VmAppInsts", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthRefs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.VmAppInsts = append(m.VmAppInsts, AppInstKey{})
			if err := m.VmAppInsts[len(m.VmAppInsts)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 15:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field K8SAppInsts", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthRefs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.K8SAppInsts = append(m.K8SAppInsts, AppInstKey{})
			if err := m.K8SAppInsts[len(m.K8SAppInsts)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipRefs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthRefs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ClusterRefs) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowRefs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ClusterRefs: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ClusterRefs: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Key", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthRefs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Key.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Apps", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthRefs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Apps = append(m.Apps, AppInstKey{})
			if err := m.Apps[len(m.Apps)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipRefs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthRefs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AppInstRefs) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowRefs
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AppInstRefs: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AppInstRefs: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Key", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthRefs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Key.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Insts", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthRefs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Insts == nil {
				m.Insts = make(map[string]uint32)
			}
			var mapkey string
			var mapvalue uint32
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowRefs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					var stringLenmapkey uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowRefs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapkey |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapkey := int(stringLenmapkey)
					if intStringLenmapkey < 0 {
						return ErrInvalidLengthRefs
					}
					postStringIndexmapkey := iNdEx + intStringLenmapkey
					if postStringIndexmapkey < 0 {
						return ErrInvalidLengthRefs
					}
					if postStringIndexmapkey > l {
						return io.ErrUnexpectedEOF
					}
					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
					iNdEx = postStringIndexmapkey
				} else if fieldNum == 2 {
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowRefs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapvalue |= uint32(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipRefs(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthRefs
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.Insts[mapkey] = mapvalue
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field DeleteRequestedInsts", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthRefs
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthRefs
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.DeleteRequestedInsts == nil {
				m.DeleteRequestedInsts = make(map[string]uint32)
			}
			var mapkey string
			var mapvalue uint32
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowRefs
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					var stringLenmapkey uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowRefs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapkey |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapkey := int(stringLenmapkey)
					if intStringLenmapkey < 0 {
						return ErrInvalidLengthRefs
					}
					postStringIndexmapkey := iNdEx + intStringLenmapkey
					if postStringIndexmapkey < 0 {
						return ErrInvalidLengthRefs
					}
					if postStringIndexmapkey > l {
						return io.ErrUnexpectedEOF
					}
					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
					iNdEx = postStringIndexmapkey
				} else if fieldNum == 2 {
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowRefs
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapvalue |= uint32(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipRefs(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthRefs
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.DeleteRequestedInsts[mapkey] = mapvalue
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipRefs(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthRefs
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func skipRefs(dAtA []byte) (n int, err error) {
	l := len(dAtA)
	iNdEx := 0
	depth := 0
	for iNdEx < l {
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return 0, ErrIntOverflowRefs
			}
			if iNdEx >= l {
				return 0, io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		wireType := int(wire & 0x7)
		switch wireType {
		case 0:
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				iNdEx++
				if dAtA[iNdEx-1] < 0x80 {
					break
				}
			}
		case 1:
			iNdEx += 8
		case 2:
			var length int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowRefs
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				length |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if length < 0 {
				return 0, ErrInvalidLengthRefs
			}
			iNdEx += length
		case 3:
			depth++
		case 4:
			if depth == 0 {
				return 0, ErrUnexpectedEndOfGroupRefs
			}
			depth--
		case 5:
			iNdEx += 4
		default:
			return 0, fmt.Errorf("proto: illegal wireType %d", wireType)
		}
		if iNdEx < 0 {
			return 0, ErrInvalidLengthRefs
		}
		if depth == 0 {
			return iNdEx, nil
		}
	}
	return 0, io.ErrUnexpectedEOF
}

var (
	ErrInvalidLengthRefs        = fmt.Errorf("proto: negative length found during unmarshaling")
	ErrIntOverflowRefs          = fmt.Errorf("proto: integer overflow")
	ErrUnexpectedEndOfGroupRefs = fmt.Errorf("proto: unexpected end of group")
)
