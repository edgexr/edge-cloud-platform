// Code generated by protoc-gen-gogo. DO NOT EDIT.
// source: vmpool.proto

package edgeproto

import (
	context "context"
	"encoding/json"
	"errors"
	fmt "fmt"
	"github.com/edgexr/edge-cloud-platform/pkg/log"
	"github.com/edgexr/edge-cloud-platform/pkg/objstore"
	"github.com/edgexr/edge-cloud-platform/pkg/util"
	_ "github.com/edgexr/edge-cloud-platform/tools/protogen"
	"github.com/go-redis/redis/v8"
	_ "github.com/gogo/googleapis/google/api"
	_ "github.com/gogo/protobuf/gogoproto"
	proto "github.com/gogo/protobuf/proto"
	types "github.com/gogo/protobuf/types"
	"github.com/google/go-cmp/cmp"
	"github.com/google/go-cmp/cmp/cmpopts"
	"go.etcd.io/etcd/client/v3/concurrency"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
	io "io"
	math "math"
	math_bits "math/bits"
	reflect "reflect"
	"strconv"
	strings "strings"
	"sync"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.GoGoProtoPackageIsVersion3 // please upgrade the proto package

// VM State
//
// # VMState is the state of the VM
//
// 0: `VM_FREE`
// 1: `VM_IN_PROGRESS`
// 2: `VM_IN_USE`
// 3: `VM_ADD`
// 4: `VM_REMOVE`
// 5: `VM_UPDATE`
// 6: `VM_FORCE_FREE`
type VMState int32

const (
	// VM is free to use
	VMState_VM_FREE VMState = 0
	// VM is in progress
	VMState_VM_IN_PROGRESS VMState = 1
	// VM is in use
	VMState_VM_IN_USE VMState = 2
	// Add VM
	VMState_VM_ADD VMState = 3
	// Remove VM
	VMState_VM_REMOVE VMState = 4
	// Update VM
	VMState_VM_UPDATE VMState = 5
	// Forcefully free a VM, to be used at user's discretion
	VMState_VM_FORCE_FREE VMState = 6
)

var VMState_name = map[int32]string{
	0: "VM_FREE",
	1: "VM_IN_PROGRESS",
	2: "VM_IN_USE",
	3: "VM_ADD",
	4: "VM_REMOVE",
	5: "VM_UPDATE",
	6: "VM_FORCE_FREE",
}

var VMState_value = map[string]int32{
	"VM_FREE":        0,
	"VM_IN_PROGRESS": 1,
	"VM_IN_USE":      2,
	"VM_ADD":         3,
	"VM_REMOVE":      4,
	"VM_UPDATE":      5,
	"VM_FORCE_FREE":  6,
}

func (x VMState) String() string {
	return proto.EnumName(VMState_name, int32(x))
}

func (VMState) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_5168f4b4bc6cb855, []int{0}
}

// VM Action
//
// # VMAction is the action to be performed on VM Pool
//
// 0: `VM_ACTION_DONE`
// 1: `VM_ACTION_ALLOCATE`
// 2: `VM_ACTION_RELEASE`
type VMAction int32

const (
	// Done performing action
	VMAction_VM_ACTION_DONE VMAction = 0
	// Allocate VMs from VM Pool
	VMAction_VM_ACTION_ALLOCATE VMAction = 1
	// Release VMs from VM Pool
	VMAction_VM_ACTION_RELEASE VMAction = 2
)

var VMAction_name = map[int32]string{
	0: "VM_ACTION_DONE",
	1: "VM_ACTION_ALLOCATE",
	2: "VM_ACTION_RELEASE",
}

var VMAction_value = map[string]int32{
	"VM_ACTION_DONE":     0,
	"VM_ACTION_ALLOCATE": 1,
	"VM_ACTION_RELEASE":  2,
}

func (x VMAction) String() string {
	return proto.EnumName(VMAction_name, int32(x))
}

func (VMAction) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_5168f4b4bc6cb855, []int{1}
}

type VMNetInfo struct {
	// External IP
	ExternalIp string `protobuf:"bytes,1,opt,name=external_ip,json=externalIp,proto3" json:"external_ip,omitempty"`
	// Internal IP
	InternalIp string `protobuf:"bytes,2,opt,name=internal_ip,json=internalIp,proto3" json:"internal_ip,omitempty"`
}

func (m *VMNetInfo) Reset()         { *m = VMNetInfo{} }
func (m *VMNetInfo) String() string { return proto.CompactTextString(m) }
func (*VMNetInfo) ProtoMessage()    {}
func (*VMNetInfo) Descriptor() ([]byte, []int) {
	return fileDescriptor_5168f4b4bc6cb855, []int{0}
}
func (m *VMNetInfo) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *VMNetInfo) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_VMNetInfo.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *VMNetInfo) XXX_Merge(src proto.Message) {
	xxx_messageInfo_VMNetInfo.Merge(m, src)
}
func (m *VMNetInfo) XXX_Size() int {
	return m.Size()
}
func (m *VMNetInfo) XXX_DiscardUnknown() {
	xxx_messageInfo_VMNetInfo.DiscardUnknown(m)
}

var xxx_messageInfo_VMNetInfo proto.InternalMessageInfo

type VM struct {
	// VM Name
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// VM IP
	NetInfo VMNetInfo `protobuf:"bytes,2,opt,name=net_info,json=netInfo,proto3" json:"net_info"`
	// VM Group Name
	GroupName string `protobuf:"bytes,3,opt,name=group_name,json=groupName,proto3" json:"group_name,omitempty"`
	// VM State
	State VMState `protobuf:"varint,4,opt,name=state,proto3,enum=edgeproto.VMState" json:"state,omitempty"`
	// Last updated time
	UpdatedAt types.Timestamp `protobuf:"bytes,5,opt,name=updated_at,json=updatedAt,proto3" json:"updated_at"`
	// VM Internal Name
	InternalName string `protobuf:"bytes,6,opt,name=internal_name,json=internalName,proto3" json:"internal_name,omitempty"`
	// VM Flavor
	Flavor *FlavorInfo `protobuf:"bytes,7,opt,name=flavor,proto3" json:"flavor,omitempty"`
}

func (m *VM) Reset()         { *m = VM{} }
func (m *VM) String() string { return proto.CompactTextString(m) }
func (*VM) ProtoMessage()    {}
func (*VM) Descriptor() ([]byte, []int) {
	return fileDescriptor_5168f4b4bc6cb855, []int{1}
}
func (m *VM) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *VM) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_VM.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *VM) XXX_Merge(src proto.Message) {
	xxx_messageInfo_VM.Merge(m, src)
}
func (m *VM) XXX_Size() int {
	return m.Size()
}
func (m *VM) XXX_DiscardUnknown() {
	xxx_messageInfo_VM.DiscardUnknown(m)
}

var xxx_messageInfo_VM proto.InternalMessageInfo

// VMPool unique key
//
// VMPoolKey uniquely identifies a VMPool.
type VMPoolKey struct {
	// Organization of the vmpool
	Organization string `protobuf:"bytes,1,opt,name=organization,proto3" json:"organization,omitempty"`
	// Name of the vmpool
	Name string `protobuf:"bytes,2,opt,name=name,proto3" json:"name,omitempty"`
}

func (m *VMPoolKey) Reset()         { *m = VMPoolKey{} }
func (m *VMPoolKey) String() string { return proto.CompactTextString(m) }
func (*VMPoolKey) ProtoMessage()    {}
func (*VMPoolKey) Descriptor() ([]byte, []int) {
	return fileDescriptor_5168f4b4bc6cb855, []int{2}
}
func (m *VMPoolKey) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *VMPoolKey) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_VMPoolKey.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *VMPoolKey) XXX_Merge(src proto.Message) {
	xxx_messageInfo_VMPoolKey.Merge(m, src)
}
func (m *VMPoolKey) XXX_Size() int {
	return m.Size()
}
func (m *VMPoolKey) XXX_DiscardUnknown() {
	xxx_messageInfo_VMPoolKey.DiscardUnknown(m)
}

var xxx_messageInfo_VMPoolKey proto.InternalMessageInfo

// VMPool defines a pool of VMs to be part of a Cloudlet
type VMPool struct {
	// Fields are used for the Update API to specify which fields to apply
	Fields []string `protobuf:"bytes,1,rep,name=fields,proto3" json:"fields,omitempty"`
	// VMPool Key
	Key VMPoolKey `protobuf:"bytes,2,opt,name=key,proto3" json:"key"`
	// list of VMs to be part of VM pool
	Vms []VM `protobuf:"bytes,3,rep,name=vms,proto3" json:"vms"`
	// Current state of the VM pool
	State TrackedState `protobuf:"varint,4,opt,name=state,proto3,enum=edgeproto.TrackedState" json:"state,omitempty"`
	// Any errors trying to add/remove VM to/from VM Pool
	Errors []string `protobuf:"bytes,5,rep,name=errors,proto3" json:"errors,omitempty"`
	// Override actions to CRM
	CrmOverride CRMOverride `protobuf:"varint,7,opt,name=crm_override,json=crmOverride,proto3,enum=edgeproto.CRMOverride" json:"crm_override,omitempty"`
	// Preparing to be deleted
	DeletePrepare bool `protobuf:"varint,8,opt,name=delete_prepare,json=deletePrepare,proto3" json:"delete_prepare,omitempty"`
}

func (m *VMPool) Reset()         { *m = VMPool{} }
func (m *VMPool) String() string { return proto.CompactTextString(m) }
func (*VMPool) ProtoMessage()    {}
func (*VMPool) Descriptor() ([]byte, []int) {
	return fileDescriptor_5168f4b4bc6cb855, []int{3}
}
func (m *VMPool) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *VMPool) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_VMPool.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *VMPool) XXX_Merge(src proto.Message) {
	xxx_messageInfo_VMPool.Merge(m, src)
}
func (m *VMPool) XXX_Size() int {
	return m.Size()
}
func (m *VMPool) XXX_DiscardUnknown() {
	xxx_messageInfo_VMPool.DiscardUnknown(m)
}

var xxx_messageInfo_VMPool proto.InternalMessageInfo

// VMPoolMember is used to add and remove VM from VM Pool
type VMPoolMember struct {
	// VMPool key
	Key VMPoolKey `protobuf:"bytes,1,opt,name=key,proto3" json:"key"`
	// VM part of VM Pool
	Vm VM `protobuf:"bytes,2,opt,name=vm,proto3" json:"vm"`
	// Override actions to CRM
	CrmOverride CRMOverride `protobuf:"varint,3,opt,name=crm_override,json=crmOverride,proto3,enum=edgeproto.CRMOverride" json:"crm_override,omitempty"`
}

func (m *VMPoolMember) Reset()         { *m = VMPoolMember{} }
func (m *VMPoolMember) String() string { return proto.CompactTextString(m) }
func (*VMPoolMember) ProtoMessage()    {}
func (*VMPoolMember) Descriptor() ([]byte, []int) {
	return fileDescriptor_5168f4b4bc6cb855, []int{4}
}
func (m *VMPoolMember) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *VMPoolMember) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_VMPoolMember.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *VMPoolMember) XXX_Merge(src proto.Message) {
	xxx_messageInfo_VMPoolMember.Merge(m, src)
}
func (m *VMPoolMember) XXX_Size() int {
	return m.Size()
}
func (m *VMPoolMember) XXX_DiscardUnknown() {
	xxx_messageInfo_VMPoolMember.DiscardUnknown(m)
}

var xxx_messageInfo_VMPoolMember proto.InternalMessageInfo

// VMSpec defines the specification of VM required by CRM
type VMSpec struct {
	// VM internal name
	InternalName string `protobuf:"bytes,1,opt,name=internal_name,json=internalName,proto3" json:"internal_name,omitempty"`
	// VM has external network defined or not
	ExternalNetwork bool `protobuf:"varint,2,opt,name=external_network,json=externalNetwork,proto3" json:"external_network,omitempty"`
	// VM has internal network defined or not
	InternalNetwork bool `protobuf:"varint,3,opt,name=internal_network,json=internalNetwork,proto3" json:"internal_network,omitempty"`
	// VM flavor
	Flavor Flavor `protobuf:"bytes,4,opt,name=flavor,proto3" json:"flavor"`
}

func (m *VMSpec) Reset()         { *m = VMSpec{} }
func (m *VMSpec) String() string { return proto.CompactTextString(m) }
func (*VMSpec) ProtoMessage()    {}
func (*VMSpec) Descriptor() ([]byte, []int) {
	return fileDescriptor_5168f4b4bc6cb855, []int{5}
}
func (m *VMSpec) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *VMSpec) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_VMSpec.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *VMSpec) XXX_Merge(src proto.Message) {
	xxx_messageInfo_VMSpec.Merge(m, src)
}
func (m *VMSpec) XXX_Size() int {
	return m.Size()
}
func (m *VMSpec) XXX_DiscardUnknown() {
	xxx_messageInfo_VMSpec.DiscardUnknown(m)
}

var xxx_messageInfo_VMSpec proto.InternalMessageInfo

// VMPoolInfo is used to manage VM pool from Cloudlet
type VMPoolInfo struct {
	// Fields are used for the Update API to specify which fields to apply
	Fields []string `protobuf:"bytes,1,rep,name=fields,proto3" json:"fields,omitempty"`
	// Unique identifier key
	Key VMPoolKey `protobuf:"bytes,2,opt,name=key,proto3" json:"key"`
	// Id of client assigned by server (internal use only)
	NotifyId int64 `protobuf:"varint,3,opt,name=notify_id,json=notifyId,proto3" json:"notify_id,omitempty"`
	// list of VMs
	Vms []VM `protobuf:"bytes,4,rep,name=vms,proto3" json:"vms"`
	// Current state of the VM pool on the Cloudlet
	State TrackedState `protobuf:"varint,5,opt,name=state,proto3,enum=edgeproto.TrackedState" json:"state,omitempty"`
	// Any errors trying to add/remove VM to/from VM Pool
	Errors []string `protobuf:"bytes,6,rep,name=errors,proto3" json:"errors,omitempty"`
	// status is used to reflect progress of creation or other events
	Status StatusInfo `protobuf:"bytes,7,opt,name=status,proto3" json:"status"`
}

func (m *VMPoolInfo) Reset()         { *m = VMPoolInfo{} }
func (m *VMPoolInfo) String() string { return proto.CompactTextString(m) }
func (*VMPoolInfo) ProtoMessage()    {}
func (*VMPoolInfo) Descriptor() ([]byte, []int) {
	return fileDescriptor_5168f4b4bc6cb855, []int{6}
}
func (m *VMPoolInfo) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *VMPoolInfo) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_VMPoolInfo.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *VMPoolInfo) XXX_Merge(src proto.Message) {
	xxx_messageInfo_VMPoolInfo.Merge(m, src)
}
func (m *VMPoolInfo) XXX_Size() int {
	return m.Size()
}
func (m *VMPoolInfo) XXX_DiscardUnknown() {
	xxx_messageInfo_VMPoolInfo.DiscardUnknown(m)
}

var xxx_messageInfo_VMPoolInfo proto.InternalMessageInfo

func init() {
	proto.RegisterEnum("edgeproto.VMState", VMState_name, VMState_value)
	proto.RegisterEnum("edgeproto.VMAction", VMAction_name, VMAction_value)
	proto.RegisterType((*VMNetInfo)(nil), "edgeproto.VMNetInfo")
	proto.RegisterType((*VM)(nil), "edgeproto.VM")
	proto.RegisterType((*VMPoolKey)(nil), "edgeproto.VMPoolKey")
	proto.RegisterType((*VMPool)(nil), "edgeproto.VMPool")
	proto.RegisterType((*VMPoolMember)(nil), "edgeproto.VMPoolMember")
	proto.RegisterType((*VMSpec)(nil), "edgeproto.VMSpec")
	proto.RegisterType((*VMPoolInfo)(nil), "edgeproto.VMPoolInfo")
}

func init() { proto.RegisterFile("vmpool.proto", fileDescriptor_5168f4b4bc6cb855) }

var fileDescriptor_5168f4b4bc6cb855 = []byte{
	// 1401 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xac, 0x57, 0x4d, 0x68, 0x1b, 0x47,
	0x14, 0xf6, 0x48, 0xb2, 0x6c, 0x8d, 0x65, 0x47, 0x9a, 0xc4, 0xce, 0xd4, 0x24, 0xb2, 0x51, 0x48,
	0x71, 0x5d, 0x57, 0xdb, 0x3a, 0x84, 0x52, 0x43, 0x0e, 0x92, 0xad, 0x04, 0x11, 0x4b, 0x32, 0x2b,
	0x47, 0x3d, 0x8a, 0x8d, 0x76, 0xac, 0x6c, 0xad, 0xdd, 0x59, 0x76, 0x57, 0x72, 0xdd, 0x53, 0xc9,
	0xa1, 0xd0, 0x5b, 0x48, 0x2f, 0x6d, 0x68, 0x21, 0x97, 0x42, 0xe9, 0xa5, 0x25, 0xf4, 0x14, 0x4a,
	0xcf, 0x3e, 0x06, 0x4a, 0x69, 0x28, 0xb4, 0xa4, 0x4e, 0x0f, 0x25, 0xa7, 0x42, 0x64, 0xa7, 0xc7,
	0x32, 0x3f, 0xbb, 0x92, 0x2c, 0x51, 0x1c, 0x93, 0xdb, 0xcc, 0x7b, 0x9f, 0x66, 0xbf, 0xf9, 0xbe,
	0xb7, 0xef, 0xad, 0x60, 0xbc, 0x6d, 0xda, 0x94, 0x36, 0x33, 0xb6, 0x43, 0x3d, 0x8a, 0x62, 0x44,
	0x6f, 0x10, 0xbe, 0x9c, 0x3d, 0xd7, 0xa0, 0xb4, 0xd1, 0x24, 0x8a, 0x66, 0x1b, 0x8a, 0x66, 0x59,
	0xd4, 0xd3, 0x3c, 0x83, 0x5a, 0xae, 0x00, 0xce, 0x9e, 0xf7, 0x28, 0x6d, 0xba, 0x0a, 0xdf, 0x34,
	0x88, 0x15, 0x2c, 0x64, 0x3a, 0xee, 0x10, 0xb7, 0xd5, 0xf4, 0xfc, 0x5d, 0x9d, 0x9a, 0x26, 0xf5,
	0x73, 0x53, 0xf5, 0x26, 0x6d, 0xe9, 0x4d, 0x12, 0x64, 0xb7, 0x9a, 0x5a, 0x9b, 0x3a, 0x72, 0x77,
	0xa6, 0x41, 0x1b, 0x94, 0x2f, 0x15, 0xb6, 0x92, 0xd1, 0x39, 0x49, 0x86, 0xef, 0x6e, 0xb6, 0xb6,
	0x14, 0xcf, 0x30, 0x89, 0xeb, 0x69, 0xa6, 0x2d, 0x01, 0x28, 0x20, 0x1e, 0x90, 0x48, 0x17, 0x61,
	0xac, 0x5a, 0x2c, 0x11, 0xaf, 0x60, 0x6d, 0x51, 0x34, 0x07, 0x27, 0xc8, 0x87, 0x1e, 0x71, 0x2c,
	0xad, 0x59, 0x33, 0x6c, 0x0c, 0xe6, 0xc1, 0x42, 0x4c, 0x85, 0x7e, 0xa8, 0x60, 0x33, 0x80, 0x61,
	0x75, 0x01, 0x21, 0x01, 0xf0, 0x43, 0x05, 0x3b, 0xfd, 0x53, 0x08, 0x86, 0xaa, 0x45, 0x84, 0x60,
	0xc4, 0xd2, 0x4c, 0x22, 0x4f, 0xe0, 0x6b, 0x74, 0x19, 0x8e, 0x5b, 0xc4, 0xab, 0x19, 0xd6, 0x16,
	0xe5, 0x3f, 0x9c, 0x58, 0x3e, 0x93, 0x09, 0x08, 0x65, 0x02, 0x12, 0xb9, 0xc8, 0xde, 0x1f, 0x73,
	0x23, 0xea, 0x98, 0x25, 0x39, 0x9d, 0x87, 0xb0, 0xe1, 0xd0, 0x96, 0x5d, 0xe3, 0x07, 0x86, 0xf9,
	0x81, 0x31, 0x1e, 0x29, 0xb1, 0x53, 0x17, 0xe0, 0xa8, 0xeb, 0x69, 0x1e, 0xc1, 0x91, 0x79, 0xb0,
	0x30, 0xb5, 0x8c, 0xfa, 0x8e, 0xac, 0xb0, 0x8c, 0x2a, 0x00, 0x68, 0x03, 0xc2, 0x96, 0xad, 0x6b,
	0x1e, 0xd1, 0x6b, 0x9a, 0x87, 0x47, 0x39, 0x83, 0xd9, 0x8c, 0xd0, 0x2c, 0xe3, 0x6b, 0x96, 0xd9,
	0xf4, 0x35, 0xcb, 0x4d, 0x7f, 0xd3, 0xc1, 0xe0, 0xee, 0x83, 0xd7, 0x62, 0x81, 0x8c, 0x9c, 0x58,
	0x4c, 0x1e, 0x92, 0xf5, 0xd0, 0x05, 0x38, 0x19, 0xa8, 0xc1, 0xd9, 0x45, 0x39, 0xbb, 0xb8, 0x1f,
	0xe4, 0x04, 0xdf, 0x82, 0x51, 0xe1, 0x1d, 0x1e, 0xe3, 0x8f, 0x9c, 0xee, 0x61, 0x78, 0x95, 0x27,
	0xd8, 0x35, 0x55, 0x09, 0x4a, 0x37, 0x99, 0x1f, 0x1b, 0x94, 0x36, 0xaf, 0x93, 0x5d, 0xf4, 0x0e,
	0x8c, 0x53, 0xa7, 0xa1, 0x59, 0xc6, 0x47, 0xbc, 0xae, 0x84, 0x9c, 0xb9, 0xc9, 0x87, 0x87, 0x38,
	0x26, 0x2a, 0x92, 0x3a, 0x0d, 0xb5, 0x0f, 0x82, 0x52, 0x52, 0x79, 0x6e, 0x4d, 0x0e, 0x3e, 0x3c,
	0xc4, 0x51, 0x01, 0x15, 0x2e, 0xac, 0xc4, 0xff, 0x7e, 0x8e, 0xc1, 0xbf, 0xcf, 0x31, 0xf8, 0xfe,
	0xfe, 0x1c, 0x48, 0x7f, 0x11, 0x81, 0x51, 0xf1, 0x38, 0x34, 0x03, 0xa3, 0x5b, 0x06, 0x69, 0xea,
	0x2e, 0x06, 0xf3, 0xe1, 0x85, 0x98, 0x2a, 0x77, 0x68, 0x09, 0x86, 0xb7, 0xc9, 0xee, 0x50, 0xc7,
	0x24, 0x4d, 0xe9, 0x18, 0x83, 0xa1, 0x8b, 0x30, 0xdc, 0x36, 0x5d, 0x1c, 0x9e, 0x0f, 0x2f, 0x4c,
	0x2c, 0x4f, 0xf6, 0xa1, 0x7d, 0x58, 0xdb, 0x74, 0xd1, 0xa5, 0x7e, 0xd7, 0xce, 0xf6, 0x00, 0x37,
	0x1d, 0xad, 0xbe, 0x4d, 0x74, 0x6e, 0x5d, 0x2e, 0xc2, 0x3c, 0xf0, 0x0d, 0xbc, 0x08, 0xa3, 0xc4,
	0x71, 0xa8, 0xe3, 0xe2, 0x51, 0xc6, 0x30, 0x37, 0x29, 0x0d, 0x1a, 0xb5, 0x68, 0xdd, 0xb4, 0x55,
	0x99, 0x44, 0xef, 0xc1, 0x78, 0xdd, 0x31, 0x6b, 0xb4, 0x4d, 0x1c, 0xc7, 0xd0, 0x09, 0x97, 0x7d,
	0x6a, 0x79, 0xa6, 0xe7, 0x11, 0xab, 0x6a, 0xb1, 0x2c, 0xb3, 0xea, 0x44, 0xdd, 0x31, 0xfd, 0x0d,
	0x7a, 0x13, 0x4e, 0xe9, 0xa4, 0x49, 0x3c, 0x52, 0xb3, 0x1d, 0x62, 0x6b, 0x0e, 0xc1, 0xe3, 0xf3,
	0x60, 0x61, 0x5c, 0xd2, 0x98, 0x14, 0xb9, 0x0d, 0x91, 0x5a, 0xf9, 0x1d, 0x30, 0x29, 0xff, 0x79,
	0x8e, 0xc1, 0xc7, 0x1d, 0x0c, 0xee, 0x74, 0x30, 0xf8, 0xbc, 0x83, 0xc1, 0x5e, 0x07, 0x83, 0xc7,
	0x8c, 0xd7, 0x01, 0xfe, 0xa0, 0x6a, 0xba, 0x2b, 0x17, 0x32, 0xd7, 0xfc, 0x5a, 0x5d, 0x12, 0xfb,
	0x42, 0x4f, 0x75, 0xc8, 0xd0, 0x0d, 0xbf, 0xa4, 0x32, 0x15, 0x52, 0xa7, 0x96, 0xee, 0x0e, 0xc4,
	0x4b, 0x9a, 0x45, 0xdd, 0x25, 0x2e, 0xca, 0x52, 0x9e, 0xdf, 0x53, 0x42, 0x44, 0x09, 0xdd, 0x3b,
	0xc0, 0x8b, 0xc2, 0xe6, 0x2b, 0xd7, 0xc9, 0x6e, 0x86, 0x1f, 0x1d, 0x54, 0x08, 0x0f, 0x95, 0x7b,
	0x8a, 0xe4, 0xc1, 0x21, 0x4e, 0x6c, 0x93, 0xdd, 0x2b, 0xbd, 0xb1, 0xdb, 0x2f, 0x58, 0x4d, 0x31,
	0x47, 0xb3, 0xb6, 0x71, 0xff, 0x05, 0x06, 0xe9, 0x1f, 0x43, 0x30, 0x2e, 0x3c, 0x2e, 0x12, 0xf3,
	0x26, 0x71, 0xfc, 0x4a, 0x00, 0xc7, 0xab, 0x84, 0x0b, 0x30, 0xd4, 0x36, 0x65, 0xd9, 0x0c, 0x2d,
	0x84, 0x50, 0xdb, 0x1c, 0xf0, 0x2a, 0x7c, 0x6c, 0xaf, 0x56, 0xbe, 0x62, 0x12, 0xbf, 0x5f, 0x35,
	0xfb, 0xf4, 0xcd, 0x08, 0x85, 0xaa, 0xe6, 0x50, 0x49, 0x07, 0xf4, 0xac, 0x9a, 0x47, 0xdd, 0x78,
	0x65, 0x7a, 0xa6, 0x7f, 0x00, 0xec, 0xd5, 0xaa, 0xd8, 0xa4, 0x3e, 0xd8, 0x27, 0xc0, 0x90, 0x3e,
	0xf1, 0x06, 0x4c, 0x04, 0xbd, 0xd7, 0x22, 0xde, 0x0e, 0x75, 0xb6, 0xb9, 0x7a, 0xe3, 0xea, 0x29,
	0x3f, 0x5e, 0x12, 0x61, 0x06, 0xed, 0x9e, 0x27, 0xa1, 0x61, 0x01, 0x0d, 0x8e, 0x94, 0x50, 0x25,
	0xe8, 0x3e, 0x11, 0xee, 0x44, 0x72, 0xa0, 0xfb, 0x48, 0x37, 0xfc, 0xfe, 0xf3, 0x65, 0x18, 0x42,
	0xe1, 0x27, 0xef, 0xbe, 0xaf, 0xa6, 0x2b, 0xbc, 0x0e, 0x63, 0x16, 0xf5, 0x8c, 0xad, 0xdd, 0x9a,
	0xa1, 0x73, 0xa6, 0xe1, 0x5c, 0xac, 0xfb, 0xe2, 0x8e, 0x8b, 0x5c, 0x41, 0xf7, 0xbb, 0x47, 0xe4,
	0xb8, 0xdd, 0x63, 0xf4, 0x44, 0xdd, 0x23, 0xfa, 0x7f, 0xdd, 0xe3, 0x5d, 0x18, 0x65, 0xf8, 0x96,
	0x3b, 0xa4, 0x5d, 0x57, 0x78, 0x82, 0x0f, 0xa9, 0x71, 0xf6, 0x6b, 0x21, 0x9c, 0x80, 0xaf, 0xe8,
	0x47, 0xbb, 0xc1, 0xc3, 0x0e, 0x8e, 0xf7, 0xd2, 0x79, 0xd2, 0xc1, 0xe0, 0xa5, 0xeb, 0x2a, 0x62,
	0x51, 0x8b, 0x3c, 0x78, 0x81, 0x65, 0x97, 0x5e, 0xbc, 0x07, 0xe0, 0x98, 0x9c, 0x6b, 0x28, 0xc9,
	0x96, 0xb5, 0xab, 0x6a, 0x3e, 0x9f, 0x18, 0x99, 0x8d, 0xdc, 0x39, 0xc4, 0x00, 0x61, 0x38, 0x55,
	0x2d, 0xd6, 0x0a, 0xa5, 0xda, 0x86, 0x5a, 0xbe, 0xa6, 0xe6, 0x2b, 0x95, 0x04, 0x90, 0x99, 0xd3,
	0x6c, 0xae, 0xb0, 0xcc, 0x8d, 0x4a, 0x3e, 0x11, 0x92, 0xc1, 0x04, 0x2b, 0xd1, 0x5a, 0x76, 0x6d,
	0x2d, 0x11, 0xee, 0x83, 0xa9, 0xf9, 0x62, 0xb9, 0x9a, 0x4f, 0x44, 0xfa, 0x82, 0x37, 0x36, 0xd6,
	0xb2, 0x9b, 0xf9, 0xc4, 0xa8, 0x0c, 0x26, 0xe1, 0x24, 0x7b, 0x7a, 0x59, 0x5d, 0xcd, 0x0b, 0x0e,
	0xd1, 0xc5, 0x22, 0x1c, 0xaf, 0x16, 0xb3, 0x75, 0x3e, 0x87, 0x10, 0x67, 0x92, 0x5d, 0xdd, 0x2c,
	0x94, 0x4b, 0xb5, 0xb5, 0x72, 0x29, 0x9f, 0x18, 0x41, 0x33, 0x10, 0x75, 0x63, 0xd9, 0xf5, 0xf5,
	0xf2, 0x2a, 0x3b, 0x10, 0xa0, 0x69, 0x98, 0xec, 0xc6, 0xd5, 0xfc, 0x7a, 0x3e, 0xcb, 0x38, 0x2e,
	0xff, 0x3a, 0xe6, 0xcf, 0xc2, 0xac, 0x6d, 0xa0, 0xaf, 0x01, 0x8c, 0xaf, 0x3a, 0x44, 0xf3, 0x88,
	0x1c, 0x58, 0xc9, 0x81, 0xaa, 0x9b, 0xed, 0x0d, 0xa9, 0xfc, 0xe3, 0x2a, 0x4d, 0x9f, 0x75, 0xb0,
	0xa2, 0x12, 0x97, 0xb6, 0x9c, 0x3a, 0x59, 0x95, 0x1f, 0x55, 0xee, 0x92, 0x60, 0x59, 0xd4, 0x2c,
	0xad, 0x41, 0x96, 0x8e, 0xea, 0xfe, 0xdb, 0x01, 0x9e, 0x10, 0xdd, 0x95, 0x0b, 0xfd, 0xed, 0x21,
	0x4e, 0x1c, 0x85, 0xdc, 0xfe, 0xf9, 0xaf, 0xcf, 0x42, 0xa7, 0xd3, 0x53, 0x4a, 0x9d, 0x53, 0x52,
	0x84, 0x89, 0x2b, 0x60, 0x11, 0x7d, 0x0a, 0x60, 0x7c, 0x8d, 0x0f, 0x8a, 0x97, 0xe2, 0x59, 0x39,
	0x01, 0x4f, 0x4e, 0x62, 0x36, 0x3d, 0xad, 0x88, 0xc1, 0xa4, 0xf0, 0x6f, 0x46, 0xe2, 0x75, 0xb9,
	0xdc, 0x06, 0x30, 0x2e, 0x7a, 0xde, 0x4b, 0x71, 0x59, 0x3f, 0x29, 0x17, 0x26, 0x88, 0xf8, 0x3c,
	0xea, 0x11, 0xe4, 0x13, 0x00, 0x61, 0xe5, 0x16, 0xdd, 0x39, 0x1e, 0x05, 0x11, 0x4a, 0x6f, 0x3c,
	0xeb, 0xe0, 0xcb, 0x47, 0x29, 0x64, 0x2d, 0xad, 0xb9, 0xeb, 0x19, 0x75, 0x9f, 0x4a, 0xd5, 0x20,
	0x3b, 0xc3, 0x89, 0x24, 0xd3, 0x71, 0xc5, 0xbd, 0x45, 0x77, 0xba, 0x34, 0xde, 0x06, 0xe8, 0x3b,
	0x00, 0x4f, 0x65, 0x75, 0xbd, 0x6f, 0xa6, 0x9d, 0x1d, 0x78, 0xb4, 0x48, 0x0c, 0x93, 0xc5, 0x3e,
	0x81, 0x2c, 0xfb, 0x07, 0xf8, 0x7c, 0xd5, 0xcc, 0xf8, 0xd3, 0x45, 0x7e, 0xe3, 0x06, 0x53, 0xa7,
	0x60, 0x73, 0xba, 0x33, 0xe9, 0xa4, 0xa2, 0xe9, 0xba, 0x64, 0x6b, 0x72, 0x06, 0x4c, 0xba, 0x5f,
	0x00, 0x44, 0x2a, 0x31, 0x69, 0x9b, 0x9c, 0x98, 0xf4, 0x5d, 0x70, 0xb2, 0x17, 0xe0, 0x72, 0x0f,
	0xdb, 0x7c, 0xf0, 0x07, 0x60, 0xf8, 0x1d, 0xba, 0x73, 0x73, 0xff, 0x00, 0x8f, 0xc9, 0xeb, 0xf2,
	0x8b, 0x4d, 0xa7, 0x13, 0x8a, 0x63, 0x1e, 0xbd, 0x57, 0xee, 0xdc, 0xde, 0x9f, 0xa9, 0x91, 0xbd,
	0xfd, 0x14, 0x78, 0xb4, 0x9f, 0x02, 0x4f, 0xf6, 0x53, 0xe0, 0xce, 0xd3, 0xd4, 0xc8, 0xa3, 0xa7,
	0xa9, 0x91, 0xc7, 0x4f, 0x53, 0x23, 0x37, 0xa3, 0xfc, 0x02, 0x97, 0xfe, 0x0b, 0x00, 0x00, 0xff,
	0xff, 0xd6, 0xec, 0x8f, 0x91, 0x76, 0x0d, 0x00, 0x00,
}

func (this *VMPoolKey) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 6)
	s = append(s, "&edgeproto.VMPoolKey{")
	s = append(s, "Organization: "+fmt.Sprintf("%#v", this.Organization)+",\n")
	s = append(s, "Name: "+fmt.Sprintf("%#v", this.Name)+",\n")
	s = append(s, "}")
	return strings.Join(s, "")
}
func valueToGoStringVmpool(v interface{}, typ string) string {
	rv := reflect.ValueOf(v)
	if rv.IsNil() {
		return "nil"
	}
	pv := reflect.Indirect(rv).Interface()
	return fmt.Sprintf("func(v %v) *%v { return &v } ( %#v )", typ, typ, pv)
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// VMPoolApiClient is the client API for VMPoolApi service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.
type VMPoolApiClient interface {
	// Create VMPool. Creates VM pool which will have
	// VMs defined.
	CreateVMPool(ctx context.Context, in *VMPool, opts ...grpc.CallOption) (*Result, error)
	// Delete VMPool. Deletes VM pool given that none
	// of VMs part of this pool is used.
	DeleteVMPool(ctx context.Context, in *VMPool, opts ...grpc.CallOption) (*Result, error)
	// Update VMPool. Updates a VM pool's VMs.
	UpdateVMPool(ctx context.Context, in *VMPool, opts ...grpc.CallOption) (*Result, error)
	// Show VMPools. Lists all the VMs part of the VM pool.
	ShowVMPool(ctx context.Context, in *VMPool, opts ...grpc.CallOption) (VMPoolApi_ShowVMPoolClient, error)
	// Add VMPoolMember. Adds a VM to existing VM Pool.
	AddVMPoolMember(ctx context.Context, in *VMPoolMember, opts ...grpc.CallOption) (*Result, error)
	// Remove VMPoolMember. Removes a VM from existing VM Pool.
	RemoveVMPoolMember(ctx context.Context, in *VMPoolMember, opts ...grpc.CallOption) (*Result, error)
}

type vMPoolApiClient struct {
	cc *grpc.ClientConn
}

func NewVMPoolApiClient(cc *grpc.ClientConn) VMPoolApiClient {
	return &vMPoolApiClient{cc}
}

func (c *vMPoolApiClient) CreateVMPool(ctx context.Context, in *VMPool, opts ...grpc.CallOption) (*Result, error) {
	out := new(Result)
	err := c.cc.Invoke(ctx, "/edgeproto.VMPoolApi/CreateVMPool", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *vMPoolApiClient) DeleteVMPool(ctx context.Context, in *VMPool, opts ...grpc.CallOption) (*Result, error) {
	out := new(Result)
	err := c.cc.Invoke(ctx, "/edgeproto.VMPoolApi/DeleteVMPool", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *vMPoolApiClient) UpdateVMPool(ctx context.Context, in *VMPool, opts ...grpc.CallOption) (*Result, error) {
	out := new(Result)
	err := c.cc.Invoke(ctx, "/edgeproto.VMPoolApi/UpdateVMPool", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *vMPoolApiClient) ShowVMPool(ctx context.Context, in *VMPool, opts ...grpc.CallOption) (VMPoolApi_ShowVMPoolClient, error) {
	stream, err := c.cc.NewStream(ctx, &_VMPoolApi_serviceDesc.Streams[0], "/edgeproto.VMPoolApi/ShowVMPool", opts...)
	if err != nil {
		return nil, err
	}
	x := &vMPoolApiShowVMPoolClient{stream}
	if err := x.ClientStream.SendMsg(in); err != nil {
		return nil, err
	}
	if err := x.ClientStream.CloseSend(); err != nil {
		return nil, err
	}
	return x, nil
}

type VMPoolApi_ShowVMPoolClient interface {
	Recv() (*VMPool, error)
	grpc.ClientStream
}

type vMPoolApiShowVMPoolClient struct {
	grpc.ClientStream
}

func (x *vMPoolApiShowVMPoolClient) Recv() (*VMPool, error) {
	m := new(VMPool)
	if err := x.ClientStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

func (c *vMPoolApiClient) AddVMPoolMember(ctx context.Context, in *VMPoolMember, opts ...grpc.CallOption) (*Result, error) {
	out := new(Result)
	err := c.cc.Invoke(ctx, "/edgeproto.VMPoolApi/AddVMPoolMember", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *vMPoolApiClient) RemoveVMPoolMember(ctx context.Context, in *VMPoolMember, opts ...grpc.CallOption) (*Result, error) {
	out := new(Result)
	err := c.cc.Invoke(ctx, "/edgeproto.VMPoolApi/RemoveVMPoolMember", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// VMPoolApiServer is the server API for VMPoolApi service.
type VMPoolApiServer interface {
	// Create VMPool. Creates VM pool which will have
	// VMs defined.
	CreateVMPool(context.Context, *VMPool) (*Result, error)
	// Delete VMPool. Deletes VM pool given that none
	// of VMs part of this pool is used.
	DeleteVMPool(context.Context, *VMPool) (*Result, error)
	// Update VMPool. Updates a VM pool's VMs.
	UpdateVMPool(context.Context, *VMPool) (*Result, error)
	// Show VMPools. Lists all the VMs part of the VM pool.
	ShowVMPool(*VMPool, VMPoolApi_ShowVMPoolServer) error
	// Add VMPoolMember. Adds a VM to existing VM Pool.
	AddVMPoolMember(context.Context, *VMPoolMember) (*Result, error)
	// Remove VMPoolMember. Removes a VM from existing VM Pool.
	RemoveVMPoolMember(context.Context, *VMPoolMember) (*Result, error)
}

// UnimplementedVMPoolApiServer can be embedded to have forward compatible implementations.
type UnimplementedVMPoolApiServer struct {
}

func (*UnimplementedVMPoolApiServer) CreateVMPool(ctx context.Context, req *VMPool) (*Result, error) {
	return nil, status.Errorf(codes.Unimplemented, "method CreateVMPool not implemented")
}
func (*UnimplementedVMPoolApiServer) DeleteVMPool(ctx context.Context, req *VMPool) (*Result, error) {
	return nil, status.Errorf(codes.Unimplemented, "method DeleteVMPool not implemented")
}
func (*UnimplementedVMPoolApiServer) UpdateVMPool(ctx context.Context, req *VMPool) (*Result, error) {
	return nil, status.Errorf(codes.Unimplemented, "method UpdateVMPool not implemented")
}
func (*UnimplementedVMPoolApiServer) ShowVMPool(req *VMPool, srv VMPoolApi_ShowVMPoolServer) error {
	return status.Errorf(codes.Unimplemented, "method ShowVMPool not implemented")
}
func (*UnimplementedVMPoolApiServer) AddVMPoolMember(ctx context.Context, req *VMPoolMember) (*Result, error) {
	return nil, status.Errorf(codes.Unimplemented, "method AddVMPoolMember not implemented")
}
func (*UnimplementedVMPoolApiServer) RemoveVMPoolMember(ctx context.Context, req *VMPoolMember) (*Result, error) {
	return nil, status.Errorf(codes.Unimplemented, "method RemoveVMPoolMember not implemented")
}

func RegisterVMPoolApiServer(s *grpc.Server, srv VMPoolApiServer) {
	s.RegisterService(&_VMPoolApi_serviceDesc, srv)
}

func _VMPoolApi_CreateVMPool_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(VMPool)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(VMPoolApiServer).CreateVMPool(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/edgeproto.VMPoolApi/CreateVMPool",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(VMPoolApiServer).CreateVMPool(ctx, req.(*VMPool))
	}
	return interceptor(ctx, in, info, handler)
}

func _VMPoolApi_DeleteVMPool_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(VMPool)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(VMPoolApiServer).DeleteVMPool(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/edgeproto.VMPoolApi/DeleteVMPool",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(VMPoolApiServer).DeleteVMPool(ctx, req.(*VMPool))
	}
	return interceptor(ctx, in, info, handler)
}

func _VMPoolApi_UpdateVMPool_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(VMPool)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(VMPoolApiServer).UpdateVMPool(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/edgeproto.VMPoolApi/UpdateVMPool",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(VMPoolApiServer).UpdateVMPool(ctx, req.(*VMPool))
	}
	return interceptor(ctx, in, info, handler)
}

func _VMPoolApi_ShowVMPool_Handler(srv interface{}, stream grpc.ServerStream) error {
	m := new(VMPool)
	if err := stream.RecvMsg(m); err != nil {
		return err
	}
	return srv.(VMPoolApiServer).ShowVMPool(m, &vMPoolApiShowVMPoolServer{stream})
}

type VMPoolApi_ShowVMPoolServer interface {
	Send(*VMPool) error
	grpc.ServerStream
}

type vMPoolApiShowVMPoolServer struct {
	grpc.ServerStream
}

func (x *vMPoolApiShowVMPoolServer) Send(m *VMPool) error {
	return x.ServerStream.SendMsg(m)
}

func _VMPoolApi_AddVMPoolMember_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(VMPoolMember)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(VMPoolApiServer).AddVMPoolMember(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/edgeproto.VMPoolApi/AddVMPoolMember",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(VMPoolApiServer).AddVMPoolMember(ctx, req.(*VMPoolMember))
	}
	return interceptor(ctx, in, info, handler)
}

func _VMPoolApi_RemoveVMPoolMember_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(VMPoolMember)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(VMPoolApiServer).RemoveVMPoolMember(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/edgeproto.VMPoolApi/RemoveVMPoolMember",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(VMPoolApiServer).RemoveVMPoolMember(ctx, req.(*VMPoolMember))
	}
	return interceptor(ctx, in, info, handler)
}

var _VMPoolApi_serviceDesc = grpc.ServiceDesc{
	ServiceName: "edgeproto.VMPoolApi",
	HandlerType: (*VMPoolApiServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "CreateVMPool",
			Handler:    _VMPoolApi_CreateVMPool_Handler,
		},
		{
			MethodName: "DeleteVMPool",
			Handler:    _VMPoolApi_DeleteVMPool_Handler,
		},
		{
			MethodName: "UpdateVMPool",
			Handler:    _VMPoolApi_UpdateVMPool_Handler,
		},
		{
			MethodName: "AddVMPoolMember",
			Handler:    _VMPoolApi_AddVMPoolMember_Handler,
		},
		{
			MethodName: "RemoveVMPoolMember",
			Handler:    _VMPoolApi_RemoveVMPoolMember_Handler,
		},
	},
	Streams: []grpc.StreamDesc{
		{
			StreamName:    "ShowVMPool",
			Handler:       _VMPoolApi_ShowVMPool_Handler,
			ServerStreams: true,
		},
	},
	Metadata: "vmpool.proto",
}

func (m *VMNetInfo) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *VMNetInfo) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *VMNetInfo) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.InternalIp) > 0 {
		i -= len(m.InternalIp)
		copy(dAtA[i:], m.InternalIp)
		i = encodeVarintVmpool(dAtA, i, uint64(len(m.InternalIp)))
		i--
		dAtA[i] = 0x12
	}
	if len(m.ExternalIp) > 0 {
		i -= len(m.ExternalIp)
		copy(dAtA[i:], m.ExternalIp)
		i = encodeVarintVmpool(dAtA, i, uint64(len(m.ExternalIp)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *VM) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *VM) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *VM) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.Flavor != nil {
		{
			size, err := m.Flavor.MarshalToSizedBuffer(dAtA[:i])
			if err != nil {
				return 0, err
			}
			i -= size
			i = encodeVarintVmpool(dAtA, i, uint64(size))
		}
		i--
		dAtA[i] = 0x3a
	}
	if len(m.InternalName) > 0 {
		i -= len(m.InternalName)
		copy(dAtA[i:], m.InternalName)
		i = encodeVarintVmpool(dAtA, i, uint64(len(m.InternalName)))
		i--
		dAtA[i] = 0x32
	}
	{
		size, err := m.UpdatedAt.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintVmpool(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x2a
	if m.State != 0 {
		i = encodeVarintVmpool(dAtA, i, uint64(m.State))
		i--
		dAtA[i] = 0x20
	}
	if len(m.GroupName) > 0 {
		i -= len(m.GroupName)
		copy(dAtA[i:], m.GroupName)
		i = encodeVarintVmpool(dAtA, i, uint64(len(m.GroupName)))
		i--
		dAtA[i] = 0x1a
	}
	{
		size, err := m.NetInfo.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintVmpool(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x12
	if len(m.Name) > 0 {
		i -= len(m.Name)
		copy(dAtA[i:], m.Name)
		i = encodeVarintVmpool(dAtA, i, uint64(len(m.Name)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *VMPoolKey) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *VMPoolKey) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *VMPoolKey) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.Name) > 0 {
		i -= len(m.Name)
		copy(dAtA[i:], m.Name)
		i = encodeVarintVmpool(dAtA, i, uint64(len(m.Name)))
		i--
		dAtA[i] = 0x12
	}
	if len(m.Organization) > 0 {
		i -= len(m.Organization)
		copy(dAtA[i:], m.Organization)
		i = encodeVarintVmpool(dAtA, i, uint64(len(m.Organization)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *VMPool) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *VMPool) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *VMPool) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.DeletePrepare {
		i--
		if m.DeletePrepare {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x40
	}
	if m.CrmOverride != 0 {
		i = encodeVarintVmpool(dAtA, i, uint64(m.CrmOverride))
		i--
		dAtA[i] = 0x38
	}
	if len(m.Errors) > 0 {
		for iNdEx := len(m.Errors) - 1; iNdEx >= 0; iNdEx-- {
			i -= len(m.Errors[iNdEx])
			copy(dAtA[i:], m.Errors[iNdEx])
			i = encodeVarintVmpool(dAtA, i, uint64(len(m.Errors[iNdEx])))
			i--
			dAtA[i] = 0x2a
		}
	}
	if m.State != 0 {
		i = encodeVarintVmpool(dAtA, i, uint64(m.State))
		i--
		dAtA[i] = 0x20
	}
	if len(m.Vms) > 0 {
		for iNdEx := len(m.Vms) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.Vms[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintVmpool(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x1a
		}
	}
	{
		size, err := m.Key.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintVmpool(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x12
	if len(m.Fields) > 0 {
		for iNdEx := len(m.Fields) - 1; iNdEx >= 0; iNdEx-- {
			i -= len(m.Fields[iNdEx])
			copy(dAtA[i:], m.Fields[iNdEx])
			i = encodeVarintVmpool(dAtA, i, uint64(len(m.Fields[iNdEx])))
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *VMPoolMember) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *VMPoolMember) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *VMPoolMember) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.CrmOverride != 0 {
		i = encodeVarintVmpool(dAtA, i, uint64(m.CrmOverride))
		i--
		dAtA[i] = 0x18
	}
	{
		size, err := m.Vm.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintVmpool(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x12
	{
		size, err := m.Key.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintVmpool(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0xa
	return len(dAtA) - i, nil
}

func (m *VMSpec) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *VMSpec) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *VMSpec) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	{
		size, err := m.Flavor.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintVmpool(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x22
	if m.InternalNetwork {
		i--
		if m.InternalNetwork {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x18
	}
	if m.ExternalNetwork {
		i--
		if m.ExternalNetwork {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x10
	}
	if len(m.InternalName) > 0 {
		i -= len(m.InternalName)
		copy(dAtA[i:], m.InternalName)
		i = encodeVarintVmpool(dAtA, i, uint64(len(m.InternalName)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *VMPoolInfo) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *VMPoolInfo) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *VMPoolInfo) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	{
		size, err := m.Status.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintVmpool(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x3a
	if len(m.Errors) > 0 {
		for iNdEx := len(m.Errors) - 1; iNdEx >= 0; iNdEx-- {
			i -= len(m.Errors[iNdEx])
			copy(dAtA[i:], m.Errors[iNdEx])
			i = encodeVarintVmpool(dAtA, i, uint64(len(m.Errors[iNdEx])))
			i--
			dAtA[i] = 0x32
		}
	}
	if m.State != 0 {
		i = encodeVarintVmpool(dAtA, i, uint64(m.State))
		i--
		dAtA[i] = 0x28
	}
	if len(m.Vms) > 0 {
		for iNdEx := len(m.Vms) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.Vms[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintVmpool(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x22
		}
	}
	if m.NotifyId != 0 {
		i = encodeVarintVmpool(dAtA, i, uint64(m.NotifyId))
		i--
		dAtA[i] = 0x18
	}
	{
		size, err := m.Key.MarshalToSizedBuffer(dAtA[:i])
		if err != nil {
			return 0, err
		}
		i -= size
		i = encodeVarintVmpool(dAtA, i, uint64(size))
	}
	i--
	dAtA[i] = 0x12
	if len(m.Fields) > 0 {
		for iNdEx := len(m.Fields) - 1; iNdEx >= 0; iNdEx-- {
			i -= len(m.Fields[iNdEx])
			copy(dAtA[i:], m.Fields[iNdEx])
			i = encodeVarintVmpool(dAtA, i, uint64(len(m.Fields[iNdEx])))
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func encodeVarintVmpool(dAtA []byte, offset int, v uint64) int {
	offset -= sovVmpool(v)
	base := offset
	for v >= 1<<7 {
		dAtA[offset] = uint8(v&0x7f | 0x80)
		v >>= 7
		offset++
	}
	dAtA[offset] = uint8(v)
	return base
}
func (m *VMNetInfo) Clone() *VMNetInfo {
	cp := &VMNetInfo{}
	cp.DeepCopyIn(m)
	return cp
}

func (m *VMNetInfo) CopyInFields(src *VMNetInfo) int {
	changed := 0
	if m.ExternalIp != src.ExternalIp {
		m.ExternalIp = src.ExternalIp
		changed++
	}
	if m.InternalIp != src.InternalIp {
		m.InternalIp = src.InternalIp
		changed++
	}
	return changed
}

func (m *VMNetInfo) DeepCopyIn(src *VMNetInfo) {
	m.ExternalIp = src.ExternalIp
	m.InternalIp = src.InternalIp
}

// Helper method to check that enums have valid values
func (m *VMNetInfo) ValidateEnums() error {
	return nil
}

func (s *VMNetInfo) ClearTagged(tags map[string]struct{}) {
}

func (m *VM) Clone() *VM {
	cp := &VM{}
	cp.DeepCopyIn(m)
	return cp
}

func (m *VM) CopyInFields(src *VM) int {
	updateListAction := "replace"
	changed := 0
	if m.Name != src.Name {
		m.Name = src.Name
		changed++
	}
	if m.NetInfo.ExternalIp != src.NetInfo.ExternalIp {
		m.NetInfo.ExternalIp = src.NetInfo.ExternalIp
		changed++
	}
	if m.NetInfo.InternalIp != src.NetInfo.InternalIp {
		m.NetInfo.InternalIp = src.NetInfo.InternalIp
		changed++
	}
	if m.GroupName != src.GroupName {
		m.GroupName = src.GroupName
		changed++
	}
	if m.State != src.State {
		m.State = src.State
		changed++
	}
	if m.UpdatedAt.Seconds != src.UpdatedAt.Seconds {
		m.UpdatedAt.Seconds = src.UpdatedAt.Seconds
		changed++
	}
	if m.UpdatedAt.Nanos != src.UpdatedAt.Nanos {
		m.UpdatedAt.Nanos = src.UpdatedAt.Nanos
		changed++
	}
	if m.InternalName != src.InternalName {
		m.InternalName = src.InternalName
		changed++
	}
	if src.Flavor != nil {
		if m.Flavor == nil {
			m.Flavor = &FlavorInfo{}
		}
		if m.Flavor.Name != src.Flavor.Name {
			m.Flavor.Name = src.Flavor.Name
			changed++
		}
		if m.Flavor.Vcpus != src.Flavor.Vcpus {
			m.Flavor.Vcpus = src.Flavor.Vcpus
			changed++
		}
		if m.Flavor.Ram != src.Flavor.Ram {
			m.Flavor.Ram = src.Flavor.Ram
			changed++
		}
		if m.Flavor.Disk != src.Flavor.Disk {
			m.Flavor.Disk = src.Flavor.Disk
			changed++
		}
		if src.Flavor.PropMap != nil {
			if updateListAction == "add" {
				for k1, v := range src.Flavor.PropMap {
					m.Flavor.PropMap[k1] = v
					changed++
				}
			} else if updateListAction == "remove" {
				for k1, _ := range src.Flavor.PropMap {
					if _, ok := m.Flavor.PropMap[k1]; ok {
						delete(m.Flavor.PropMap, k1)
						changed++
					}
				}
			} else {
				m.Flavor.PropMap = make(map[string]string)
				for k1, v := range src.Flavor.PropMap {
					m.Flavor.PropMap[k1] = v
				}
				changed++
			}
		} else if m.Flavor.PropMap != nil {
			m.Flavor.PropMap = nil
			changed++
		}
	} else if m.Flavor != nil {
		m.Flavor = nil
		changed++
	}
	return changed
}

func (m *VM) DeepCopyIn(src *VM) {
	m.Name = src.Name
	m.NetInfo.DeepCopyIn(&src.NetInfo)
	m.GroupName = src.GroupName
	m.State = src.State
	m.UpdatedAt = src.UpdatedAt
	m.InternalName = src.InternalName
	if src.Flavor != nil {
		var tmp_Flavor FlavorInfo
		tmp_Flavor.DeepCopyIn(src.Flavor)
		m.Flavor = &tmp_Flavor
	} else {
		m.Flavor = nil
	}
}

// Helper method to check that enums have valid values
func (m *VM) ValidateEnums() error {
	if err := m.NetInfo.ValidateEnums(); err != nil {
		return err
	}
	if _, ok := VMState_name[int32(m.State)]; !ok {
		return errors.New("invalid State")
	}
	if m.Flavor != nil {
		if err := m.Flavor.ValidateEnums(); err != nil {
			return err
		}
	}
	return nil
}

func (s *VM) ClearTagged(tags map[string]struct{}) {
	s.NetInfo.ClearTagged(tags)
	if _, found := tags["timestamp"]; found {
		s.UpdatedAt = types.Timestamp{}
	}
	if s.Flavor != nil {
		s.Flavor.ClearTagged(tags)
	}
}

func IgnoreVMFields(taglist string) cmp.Option {
	names := []string{}
	tags := make(map[string]struct{})
	for _, tag := range strings.Split(taglist, ",") {
		tags[tag] = struct{}{}
	}
	if _, found := tags["timestamp"]; found {
		names = append(names, "UpdatedAt")
	}
	return cmpopts.IgnoreFields(VM{}, names...)
}

func (m *VMPoolKey) Matches(o *VMPoolKey, fopts ...MatchOpt) bool {
	opts := MatchOptions{}
	applyMatchOptions(&opts, fopts...)
	if o == nil {
		if opts.Filter {
			return true
		}
		return false
	}
	if !opts.Filter || o.Organization != "" {
		if o.Organization != m.Organization {
			return false
		}
	}
	if !opts.Filter || o.Name != "" {
		if o.Name != m.Name {
			return false
		}
	}
	return true
}

func (m *VMPoolKey) Clone() *VMPoolKey {
	cp := &VMPoolKey{}
	cp.DeepCopyIn(m)
	return cp
}

func (m *VMPoolKey) CopyInFields(src *VMPoolKey) int {
	changed := 0
	if m.Organization != src.Organization {
		m.Organization = src.Organization
		changed++
	}
	if m.Name != src.Name {
		m.Name = src.Name
		changed++
	}
	return changed
}

func (m *VMPoolKey) DeepCopyIn(src *VMPoolKey) {
	m.Organization = src.Organization
	m.Name = src.Name
}

func (m *VMPoolKey) GetKeyString() string {
	key, err := json.Marshal(m)
	if err != nil {
		log.FatalLog("Failed to marshal VMPoolKey key string", "obj", m)
	}
	return string(key)
}

func VMPoolKeyStringParse(str string, key *VMPoolKey) {
	err := json.Unmarshal([]byte(str), key)
	if err != nil {
		log.FatalLog("Failed to unmarshal VMPoolKey key string", "str", str)
	}
}

func (m *VMPoolKey) NotFoundError() error {
	return fmt.Errorf("VMPool key %s not found", m.GetKeyString())
}

func (m *VMPoolKey) ExistsError() error {
	return fmt.Errorf("VMPool key %s already exists", m.GetKeyString())
}

func (m *VMPoolKey) BeingDeletedError() error {
	return fmt.Errorf("VMPool %s is being deleted", m.GetKeyString())
}

var VMPoolKeyTagOrganization = "vmpoolorg"
var VMPoolKeyTagName = "vmpool"

func (m *VMPoolKey) GetTags() map[string]string {
	tags := make(map[string]string)
	m.AddTags(tags)
	return tags
}

func (m *VMPoolKey) AddTagsByFunc(addTag AddTagFunc) {
	addTag("vmpoolorg", m.Organization)
	addTag("vmpool", m.Name)
}

func (m *VMPoolKey) AddTags(tags map[string]string) {
	tagMap := TagMap(tags)
	m.AddTagsByFunc(tagMap.AddTag)
}

// Helper method to check that enums have valid values
func (m *VMPoolKey) ValidateEnums() error {
	return nil
}

func (s *VMPoolKey) ClearTagged(tags map[string]struct{}) {
}

func (m *VMPool) Matches(o *VMPool, fopts ...MatchOpt) bool {
	opts := MatchOptions{}
	applyMatchOptions(&opts, fopts...)
	if o == nil {
		if opts.Filter {
			return true
		}
		return false
	}
	if !m.Key.Matches(&o.Key, fopts...) {
		return false
	}
	if !opts.Filter || o.Vms != nil {
		if len(m.Vms) == 0 && len(o.Vms) > 0 || len(m.Vms) > 0 && len(o.Vms) == 0 {
			return false
		} else if m.Vms != nil && o.Vms != nil {
			if !opts.Filter && len(m.Vms) != len(o.Vms) {
				return false
			}
		}
	}
	if !opts.IgnoreBackend {
		if !opts.Filter || o.State != 0 {
			if o.State != m.State {
				return false
			}
		}
	}
	if !opts.IgnoreBackend {
		if !opts.Filter || o.Errors != nil {
			if len(m.Errors) == 0 && len(o.Errors) > 0 || len(m.Errors) > 0 && len(o.Errors) == 0 {
				return false
			} else if m.Errors != nil && o.Errors != nil {
				if !opts.Filter && len(m.Errors) != len(o.Errors) {
					return false
				}
				found := 0
				for oIndex, _ := range o.Errors {
					for mIndex, _ := range m.Errors {
						if o.Errors[oIndex] == m.Errors[mIndex] {
							found++
							break
						}
					}
				}
				if found != len(o.Errors) {
					return false
				}
			}
		}
	}
	if !opts.Filter || o.CrmOverride != 0 {
		if o.CrmOverride != m.CrmOverride {
			return false
		}
	}
	if !opts.IgnoreBackend {
		if !opts.Filter || o.DeletePrepare != false {
			if o.DeletePrepare != m.DeletePrepare {
				return false
			}
		}
	}
	return true
}

const VMPoolFieldKey = "2"
const VMPoolFieldKeyOrganization = "2.1"
const VMPoolFieldKeyName = "2.2"
const VMPoolFieldVms = "3"
const VMPoolFieldVmsName = "3.1"
const VMPoolFieldVmsNetInfo = "3.2"
const VMPoolFieldVmsNetInfoExternalIp = "3.2.1"
const VMPoolFieldVmsNetInfoInternalIp = "3.2.2"
const VMPoolFieldVmsGroupName = "3.3"
const VMPoolFieldVmsState = "3.4"
const VMPoolFieldVmsUpdatedAt = "3.5"
const VMPoolFieldVmsUpdatedAtSeconds = "3.5.1"
const VMPoolFieldVmsUpdatedAtNanos = "3.5.2"
const VMPoolFieldVmsInternalName = "3.6"
const VMPoolFieldVmsFlavor = "3.7"
const VMPoolFieldVmsFlavorName = "3.7.1"
const VMPoolFieldVmsFlavorVcpus = "3.7.2"
const VMPoolFieldVmsFlavorRam = "3.7.3"
const VMPoolFieldVmsFlavorDisk = "3.7.4"
const VMPoolFieldVmsFlavorPropMap = "3.7.5"
const VMPoolFieldVmsFlavorPropMapKey = "3.7.5.1"
const VMPoolFieldVmsFlavorPropMapValue = "3.7.5.2"
const VMPoolFieldState = "4"
const VMPoolFieldErrors = "5"
const VMPoolFieldCrmOverride = "7"
const VMPoolFieldDeletePrepare = "8"

var VMPoolAllFields = []string{
	VMPoolFieldKeyOrganization,
	VMPoolFieldKeyName,
	VMPoolFieldVmsName,
	VMPoolFieldVmsNetInfoExternalIp,
	VMPoolFieldVmsNetInfoInternalIp,
	VMPoolFieldVmsGroupName,
	VMPoolFieldVmsState,
	VMPoolFieldVmsUpdatedAtSeconds,
	VMPoolFieldVmsUpdatedAtNanos,
	VMPoolFieldVmsInternalName,
	VMPoolFieldVmsFlavorName,
	VMPoolFieldVmsFlavorVcpus,
	VMPoolFieldVmsFlavorRam,
	VMPoolFieldVmsFlavorDisk,
	VMPoolFieldVmsFlavorPropMapKey,
	VMPoolFieldVmsFlavorPropMapValue,
	VMPoolFieldState,
	VMPoolFieldErrors,
	VMPoolFieldCrmOverride,
	VMPoolFieldDeletePrepare,
}

var VMPoolAllFieldsMap = NewFieldMap(map[string]struct{}{
	VMPoolFieldKeyOrganization:       struct{}{},
	VMPoolFieldKeyName:               struct{}{},
	VMPoolFieldVmsName:               struct{}{},
	VMPoolFieldVmsNetInfoExternalIp:  struct{}{},
	VMPoolFieldVmsNetInfoInternalIp:  struct{}{},
	VMPoolFieldVmsGroupName:          struct{}{},
	VMPoolFieldVmsState:              struct{}{},
	VMPoolFieldVmsUpdatedAtSeconds:   struct{}{},
	VMPoolFieldVmsUpdatedAtNanos:     struct{}{},
	VMPoolFieldVmsInternalName:       struct{}{},
	VMPoolFieldVmsFlavorName:         struct{}{},
	VMPoolFieldVmsFlavorVcpus:        struct{}{},
	VMPoolFieldVmsFlavorRam:          struct{}{},
	VMPoolFieldVmsFlavorDisk:         struct{}{},
	VMPoolFieldVmsFlavorPropMapKey:   struct{}{},
	VMPoolFieldVmsFlavorPropMapValue: struct{}{},
	VMPoolFieldState:                 struct{}{},
	VMPoolFieldErrors:                struct{}{},
	VMPoolFieldCrmOverride:           struct{}{},
	VMPoolFieldDeletePrepare:         struct{}{},
})

var VMPoolAllFieldsStringMap = map[string]string{
	VMPoolFieldKeyOrganization:       "Key Organization",
	VMPoolFieldKeyName:               "Key Name",
	VMPoolFieldVmsName:               "Vms Name",
	VMPoolFieldVmsNetInfoExternalIp:  "Vms Net Info External Ip",
	VMPoolFieldVmsNetInfoInternalIp:  "Vms Net Info Internal Ip",
	VMPoolFieldVmsGroupName:          "Vms Group Name",
	VMPoolFieldVmsState:              "Vms State",
	VMPoolFieldVmsUpdatedAtSeconds:   "Vms Updated At Seconds",
	VMPoolFieldVmsUpdatedAtNanos:     "Vms Updated At Nanos",
	VMPoolFieldVmsInternalName:       "Vms Internal Name",
	VMPoolFieldVmsFlavorName:         "Vms Flavor Name",
	VMPoolFieldVmsFlavorVcpus:        "Vms Flavor Vcpus",
	VMPoolFieldVmsFlavorRam:          "Vms Flavor Ram",
	VMPoolFieldVmsFlavorDisk:         "Vms Flavor Disk",
	VMPoolFieldVmsFlavorPropMapKey:   "Vms Flavor Prop Map Key",
	VMPoolFieldVmsFlavorPropMapValue: "Vms Flavor Prop Map Value",
	VMPoolFieldState:                 "State",
	VMPoolFieldErrors:                "Errors",
	VMPoolFieldCrmOverride:           "Crm Override",
	VMPoolFieldDeletePrepare:         "Delete Prepare",
}

func (m *VMPool) IsKeyField(s string) bool {
	return strings.HasPrefix(s, VMPoolFieldKey+".") || s == VMPoolFieldKey
}

func (m *VMPool) DiffFields(o *VMPool, fields *FieldMap) {
	if m.Key.Organization != o.Key.Organization {
		fields.Set(VMPoolFieldKeyOrganization)
		fields.Set(VMPoolFieldKey)
	}
	if m.Key.Name != o.Key.Name {
		fields.Set(VMPoolFieldKeyName)
		fields.Set(VMPoolFieldKey)
	}
	if len(m.Vms) != len(o.Vms) {
		fields.Set(VMPoolFieldVms)
	} else {
		for i0 := 0; i0 < len(m.Vms); i0++ {
			if m.Vms[i0].Name != o.Vms[i0].Name {
				fields.Set(VMPoolFieldVmsName)
				fields.Set(VMPoolFieldVms)
			}
			if m.Vms[i0].NetInfo.ExternalIp != o.Vms[i0].NetInfo.ExternalIp {
				fields.Set(VMPoolFieldVmsNetInfoExternalIp)
				fields.Set(VMPoolFieldVmsNetInfo)
				fields.Set(VMPoolFieldVms)
			}
			if m.Vms[i0].NetInfo.InternalIp != o.Vms[i0].NetInfo.InternalIp {
				fields.Set(VMPoolFieldVmsNetInfoInternalIp)
				fields.Set(VMPoolFieldVmsNetInfo)
				fields.Set(VMPoolFieldVms)
			}
			if m.Vms[i0].GroupName != o.Vms[i0].GroupName {
				fields.Set(VMPoolFieldVmsGroupName)
				fields.Set(VMPoolFieldVms)
			}
			if m.Vms[i0].State != o.Vms[i0].State {
				fields.Set(VMPoolFieldVmsState)
				fields.Set(VMPoolFieldVms)
			}
			if m.Vms[i0].UpdatedAt.Seconds != o.Vms[i0].UpdatedAt.Seconds {
				fields.Set(VMPoolFieldVmsUpdatedAtSeconds)
				fields.Set(VMPoolFieldVmsUpdatedAt)
				fields.Set(VMPoolFieldVms)
			}
			if m.Vms[i0].UpdatedAt.Nanos != o.Vms[i0].UpdatedAt.Nanos {
				fields.Set(VMPoolFieldVmsUpdatedAtNanos)
				fields.Set(VMPoolFieldVmsUpdatedAt)
				fields.Set(VMPoolFieldVms)
			}
			if m.Vms[i0].InternalName != o.Vms[i0].InternalName {
				fields.Set(VMPoolFieldVmsInternalName)
				fields.Set(VMPoolFieldVms)
			}
			if m.Vms[i0].Flavor != nil && o.Vms[i0].Flavor != nil {
				if m.Vms[i0].Flavor.Name != o.Vms[i0].Flavor.Name {
					fields.Set(VMPoolFieldVmsFlavorName)
					fields.Set(VMPoolFieldVmsFlavor)
					fields.Set(VMPoolFieldVms)
				}
				if m.Vms[i0].Flavor.Vcpus != o.Vms[i0].Flavor.Vcpus {
					fields.Set(VMPoolFieldVmsFlavorVcpus)
					fields.Set(VMPoolFieldVmsFlavor)
					fields.Set(VMPoolFieldVms)
				}
				if m.Vms[i0].Flavor.Ram != o.Vms[i0].Flavor.Ram {
					fields.Set(VMPoolFieldVmsFlavorRam)
					fields.Set(VMPoolFieldVmsFlavor)
					fields.Set(VMPoolFieldVms)
				}
				if m.Vms[i0].Flavor.Disk != o.Vms[i0].Flavor.Disk {
					fields.Set(VMPoolFieldVmsFlavorDisk)
					fields.Set(VMPoolFieldVmsFlavor)
					fields.Set(VMPoolFieldVms)
				}
				if m.Vms[i0].Flavor.PropMap != nil && o.Vms[i0].Flavor.PropMap != nil {
					if len(m.Vms[i0].Flavor.PropMap) != len(o.Vms[i0].Flavor.PropMap) {
						fields.Set(VMPoolFieldVmsFlavorPropMap)
						fields.Set(VMPoolFieldVmsFlavor)
						fields.Set(VMPoolFieldVms)
					} else {
						for k2, _ := range m.Vms[i0].Flavor.PropMap {
							_, vok2 := o.Vms[i0].Flavor.PropMap[k2]
							if !vok2 {
								fields.Set(VMPoolFieldVmsFlavorPropMap)
								fields.Set(VMPoolFieldVmsFlavor)
								fields.Set(VMPoolFieldVms)
							} else {
								if m.Vms[i0].Flavor.PropMap[k2] != o.Vms[i0].Flavor.PropMap[k2] {
									fields.Set(VMPoolFieldVmsFlavorPropMap)
									fields.Set(VMPoolFieldVmsFlavor)
									fields.Set(VMPoolFieldVms)
									break
								}
							}
						}
					}
				} else if (m.Vms[i0].Flavor.PropMap != nil && o.Vms[i0].Flavor.PropMap == nil) || (m.Vms[i0].Flavor.PropMap == nil && o.Vms[i0].Flavor.PropMap != nil) {
					fields.Set(VMPoolFieldVmsFlavorPropMap)
					fields.Set(VMPoolFieldVmsFlavor)
					fields.Set(VMPoolFieldVms)
				}
			} else if (m.Vms[i0].Flavor != nil && o.Vms[i0].Flavor == nil) || (m.Vms[i0].Flavor == nil && o.Vms[i0].Flavor != nil) {
				fields.Set(VMPoolFieldVmsFlavor)
				fields.Set(VMPoolFieldVms)
			}
		}
	}
	if m.State != o.State {
		fields.Set(VMPoolFieldState)
	}
	if len(m.Errors) != len(o.Errors) {
		fields.Set(VMPoolFieldErrors)
	} else {
		for i0 := 0; i0 < len(m.Errors); i0++ {
			if m.Errors[i0] != o.Errors[i0] {
				fields.Set(VMPoolFieldErrors)
				break
			}
		}
	}
	if m.CrmOverride != o.CrmOverride {
		fields.Set(VMPoolFieldCrmOverride)
	}
	if m.DeletePrepare != o.DeletePrepare {
		fields.Set(VMPoolFieldDeletePrepare)
	}
}

func (m *VMPool) GetDiffFields(o *VMPool) *FieldMap {
	diffFields := NewFieldMap(nil)
	m.DiffFields(o, diffFields)
	return diffFields
}

var UpdateVMPoolFieldsMap = NewFieldMap(map[string]struct{}{
	VMPoolFieldVms:                   struct{}{},
	VMPoolFieldVmsName:               struct{}{},
	VMPoolFieldVmsNetInfo:            struct{}{},
	VMPoolFieldVmsNetInfoExternalIp:  struct{}{},
	VMPoolFieldVmsNetInfoInternalIp:  struct{}{},
	VMPoolFieldVmsGroupName:          struct{}{},
	VMPoolFieldVmsState:              struct{}{},
	VMPoolFieldVmsUpdatedAt:          struct{}{},
	VMPoolFieldVmsUpdatedAtSeconds:   struct{}{},
	VMPoolFieldVmsUpdatedAtNanos:     struct{}{},
	VMPoolFieldVmsInternalName:       struct{}{},
	VMPoolFieldVmsFlavor:             struct{}{},
	VMPoolFieldVmsFlavorName:         struct{}{},
	VMPoolFieldVmsFlavorVcpus:        struct{}{},
	VMPoolFieldVmsFlavorRam:          struct{}{},
	VMPoolFieldVmsFlavorDisk:         struct{}{},
	VMPoolFieldVmsFlavorPropMap:      struct{}{},
	VMPoolFieldVmsFlavorPropMapKey:   struct{}{},
	VMPoolFieldVmsFlavorPropMapValue: struct{}{},
	VMPoolFieldCrmOverride:           struct{}{},
	VMPoolFieldDeletePrepare:         struct{}{},
})

func (m *VMPool) ValidateUpdateFields() error {
	if m.Fields == nil {
		return fmt.Errorf("nothing specified to update")
	}
	fmap := MakeFieldMap(m.Fields)
	badFieldStrs := []string{}
	for _, field := range fmap.Fields() {
		if m.IsKeyField(field) {
			continue
		}
		if !UpdateVMPoolFieldsMap.Has(field) {
			if _, ok := VMPoolAllFieldsStringMap[field]; !ok {
				continue
			}
			badFieldStrs = append(badFieldStrs, VMPoolAllFieldsStringMap[field])
		}
	}
	if len(badFieldStrs) > 0 {
		return fmt.Errorf("specified field(s) %s cannot be modified", strings.Join(badFieldStrs, ","))
	}
	return nil
}

func (m *VMPool) Clone() *VMPool {
	cp := &VMPool{}
	cp.DeepCopyIn(m)
	return cp
}

func (m *VMPool) AddVms(vals ...VM) int {
	changes := 0
	cur := make(map[string]struct{})
	for _, v := range m.Vms {
		cur[v.String()] = struct{}{}
	}
	for _, v := range vals {
		if _, found := cur[v.String()]; found {
			continue // duplicate
		}
		m.Vms = append(m.Vms, v)
		changes++
	}
	return changes
}

func (m *VMPool) RemoveVms(vals ...VM) int {
	changes := 0
	remove := make(map[string]struct{})
	for _, v := range vals {
		remove[v.String()] = struct{}{}
	}
	for i := len(m.Vms); i >= 0; i-- {
		if _, found := remove[m.Vms[i].String()]; found {
			m.Vms = append(m.Vms[:i], m.Vms[i+1:]...)
			changes++
		}
	}
	return changes
}

func (m *VMPool) AddErrors(vals ...string) int {
	changes := 0
	cur := make(map[string]struct{})
	for _, v := range m.Errors {
		cur[v] = struct{}{}
	}
	for _, v := range vals {
		if _, found := cur[v]; found {
			continue // duplicate
		}
		m.Errors = append(m.Errors, v)
		changes++
	}
	return changes
}

func (m *VMPool) RemoveErrors(vals ...string) int {
	changes := 0
	remove := make(map[string]struct{})
	for _, v := range vals {
		remove[v] = struct{}{}
	}
	for i := len(m.Errors); i >= 0; i-- {
		if _, found := remove[m.Errors[i]]; found {
			m.Errors = append(m.Errors[:i], m.Errors[i+1:]...)
			changes++
		}
	}
	return changes
}

func (m *VMPool) CopyInFields(src *VMPool) int {
	updateListAction := "replace"
	changed := 0
	fmap := MakeFieldMap(src.Fields)
	if fmap.HasOrHasChild("2") {
		if fmap.Has("2.1") {
			if m.Key.Organization != src.Key.Organization {
				m.Key.Organization = src.Key.Organization
				changed++
			}
		}
		if fmap.Has("2.2") {
			if m.Key.Name != src.Key.Name {
				m.Key.Name = src.Key.Name
				changed++
			}
		}
	}
	if fmap.HasOrHasChild("3") {
		if src.Vms != nil {
			if updateListAction == "add" {
				changed += m.AddVms(src.Vms...)
			} else if updateListAction == "remove" {
				changed += m.RemoveVms(src.Vms...)
			} else {
				m.Vms = make([]VM, 0)
				for k0, _ := range src.Vms {
					m.Vms = append(m.Vms, *src.Vms[k0].Clone())
				}
				changed++
			}
		} else if m.Vms != nil {
			m.Vms = nil
			changed++
		}
	}
	if fmap.Has("4") {
		if m.State != src.State {
			m.State = src.State
			changed++
		}
	}
	if fmap.Has("5") {
		if src.Errors != nil {
			if updateListAction == "add" {
				changed += m.AddErrors(src.Errors...)
			} else if updateListAction == "remove" {
				changed += m.RemoveErrors(src.Errors...)
			} else {
				m.Errors = make([]string, 0)
				m.Errors = append(m.Errors, src.Errors...)
				changed++
			}
		} else if m.Errors != nil {
			m.Errors = nil
			changed++
		}
	}
	if fmap.Has("7") {
		if m.CrmOverride != src.CrmOverride {
			m.CrmOverride = src.CrmOverride
			changed++
		}
	}
	if fmap.Has("8") {
		if m.DeletePrepare != src.DeletePrepare {
			m.DeletePrepare = src.DeletePrepare
			changed++
		}
	}
	return changed
}

func (m *VMPool) DeepCopyIn(src *VMPool) {
	m.Key.DeepCopyIn(&src.Key)
	if src.Vms != nil {
		m.Vms = make([]VM, len(src.Vms), len(src.Vms))
		for ii, s := range src.Vms {
			m.Vms[ii].DeepCopyIn(&s)
		}
	} else {
		m.Vms = nil
	}
	m.State = src.State
	if src.Errors != nil {
		m.Errors = make([]string, len(src.Errors), len(src.Errors))
		for ii, s := range src.Errors {
			m.Errors[ii] = s
		}
	} else {
		m.Errors = nil
	}
	m.CrmOverride = src.CrmOverride
	m.DeletePrepare = src.DeletePrepare
}

func (s *VMPool) HasFields() bool {
	return true
}

type VMPoolStore interface {
	Create(ctx context.Context, m *VMPool, wait func(int64)) (*Result, error)
	Update(ctx context.Context, m *VMPool, wait func(int64)) (*Result, error)
	Delete(ctx context.Context, m *VMPool, wait func(int64)) (*Result, error)
	Put(ctx context.Context, m *VMPool, wait func(int64), ops ...objstore.KVOp) (*Result, error)
	LoadOne(key string) (*VMPool, int64, error)
	Get(ctx context.Context, key *VMPoolKey, buf *VMPool) bool
	STMGet(stm concurrency.STM, key *VMPoolKey, buf *VMPool) bool
	STMPut(stm concurrency.STM, obj *VMPool, ops ...objstore.KVOp)
	STMDel(stm concurrency.STM, key *VMPoolKey)
	STMHas(stm concurrency.STM, key *VMPoolKey) bool
}

type VMPoolStoreImpl struct {
	kvstore objstore.KVStore
}

func NewVMPoolStore(kvstore objstore.KVStore) *VMPoolStoreImpl {
	return &VMPoolStoreImpl{kvstore: kvstore}
}

func (s *VMPoolStoreImpl) Create(ctx context.Context, m *VMPool, wait func(int64)) (*Result, error) {
	err := m.Validate(VMPoolAllFieldsMap)
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("VMPool", m.GetKey())
	val, err := json.Marshal(m)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Create(ctx, key, string(val))
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *VMPoolStoreImpl) Update(ctx context.Context, m *VMPool, wait func(int64)) (*Result, error) {
	fmap := MakeFieldMap(m.Fields)
	err := m.Validate(fmap)
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("VMPool", m.GetKey())
	var vers int64 = 0
	curBytes, vers, _, err := s.kvstore.Get(key)
	if err != nil {
		return nil, err
	}
	var cur VMPool
	err = json.Unmarshal(curBytes, &cur)
	if err != nil {
		return nil, err
	}
	cur.CopyInFields(m)
	// never save fields
	cur.Fields = nil
	val, err := json.Marshal(cur)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Update(ctx, key, string(val), vers)
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *VMPoolStoreImpl) Put(ctx context.Context, m *VMPool, wait func(int64), ops ...objstore.KVOp) (*Result, error) {
	err := m.Validate(VMPoolAllFieldsMap)
	m.Fields = nil
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("VMPool", m.GetKey())
	var val []byte
	val, err = json.Marshal(m)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Put(ctx, key, string(val), ops...)
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *VMPoolStoreImpl) Delete(ctx context.Context, m *VMPool, wait func(int64)) (*Result, error) {
	err := m.GetKey().ValidateKey()
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("VMPool", m.GetKey())
	rev, err := s.kvstore.Delete(ctx, key)
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *VMPoolStoreImpl) LoadOne(key string) (*VMPool, int64, error) {
	val, rev, _, err := s.kvstore.Get(key)
	if err != nil {
		return nil, 0, err
	}
	var obj VMPool
	err = json.Unmarshal(val, &obj)
	if err != nil {
		log.DebugLog(log.DebugLevelApi, "Failed to parse VMPool data", "val", string(val), "err", err)
		return nil, 0, err
	}
	return &obj, rev, nil
}

func (s *VMPoolStoreImpl) Get(ctx context.Context, key *VMPoolKey, buf *VMPool) bool {
	keystr := objstore.DbKeyString("VMPool", key)
	val, _, _, err := s.kvstore.Get(keystr)
	if err != nil {
		return false
	}
	return s.parseGetData(val, buf)
}

func (s *VMPoolStoreImpl) STMGet(stm concurrency.STM, key *VMPoolKey, buf *VMPool) bool {
	keystr := objstore.DbKeyString("VMPool", key)
	valstr := stm.Get(keystr)
	return s.parseGetData([]byte(valstr), buf)
}

func (s *VMPoolStoreImpl) STMHas(stm concurrency.STM, key *VMPoolKey) bool {
	keystr := objstore.DbKeyString("VMPool", key)
	return stm.Get(keystr) != ""
}

func (s *VMPoolStoreImpl) parseGetData(val []byte, buf *VMPool) bool {
	if len(val) == 0 {
		return false
	}
	if buf != nil {
		// clear buf, because empty values in val won't
		// overwrite non-empty values in buf.
		*buf = VMPool{}
		err := json.Unmarshal(val, buf)
		if err != nil {
			return false
		}
	}
	return true
}

func (s *VMPoolStoreImpl) STMPut(stm concurrency.STM, obj *VMPool, ops ...objstore.KVOp) {
	keystr := objstore.DbKeyString("VMPool", obj.GetKey())

	val, err := json.Marshal(obj)
	if err != nil {
		log.InfoLog("VMPool json marshal failed", "obj", obj, "err", err)
	}
	v3opts := GetSTMOpts(ops...)
	stm.Put(keystr, string(val), v3opts...)
}

func (s *VMPoolStoreImpl) STMDel(stm concurrency.STM, key *VMPoolKey) {
	keystr := objstore.DbKeyString("VMPool", key)
	stm.Del(keystr)
}

func StoreListVMPool(ctx context.Context, kvstore objstore.KVStore) ([]VMPool, error) {
	keyPrefix := objstore.DbKeyPrefixString("VMPool") + "/"
	objs := []VMPool{}
	err := kvstore.List(keyPrefix, func(key, val []byte, rev, modRev int64) error {
		obj := VMPool{}
		err := json.Unmarshal(val, &obj)
		if err != nil {
			return fmt.Errorf("failed to unmarshal VMPool json %s, %s", string(val), err)
		}
		objs = append(objs, obj)
		return nil
	})
	return objs, err
}

type VMPoolKeyWatcher struct {
	cb func(ctx context.Context)
}

type VMPoolCacheData struct {
	Obj    *VMPool
	ModRev int64
}

func (s *VMPoolCacheData) Clone() *VMPoolCacheData {
	cp := VMPoolCacheData{}
	if s.Obj != nil {
		cp.Obj = &VMPool{}
		cp.Obj.DeepCopyIn(s.Obj)
	}
	cp.ModRev = s.ModRev
	return &cp
}

// VMPoolCache caches VMPool objects in memory in a hash table
// and keeps them in sync with the database.
type VMPoolCache struct {
	Objs          map[VMPoolKey]*VMPoolCacheData
	Mux           util.Mutex
	List          map[VMPoolKey]struct{}
	FlushAll      bool
	NotifyCbs     []func(ctx context.Context, obj *VMPool, modRev int64)
	UpdatedCbs    []func(ctx context.Context, old *VMPool, new *VMPool)
	DeletedCbs    []func(ctx context.Context, old *VMPool)
	KeyWatchers   map[VMPoolKey][]*VMPoolKeyWatcher
	UpdatedKeyCbs []func(ctx context.Context, key *VMPoolKey)
	DeletedKeyCbs []func(ctx context.Context, key *VMPoolKey)
	Store         VMPoolStore
}

func NewVMPoolCache() *VMPoolCache {
	cache := VMPoolCache{}
	InitVMPoolCache(&cache)
	return &cache
}

func InitVMPoolCache(cache *VMPoolCache) {
	cache.Objs = make(map[VMPoolKey]*VMPoolCacheData)
	cache.KeyWatchers = make(map[VMPoolKey][]*VMPoolKeyWatcher)
	cache.NotifyCbs = nil
	cache.UpdatedCbs = nil
	cache.DeletedCbs = nil
	cache.UpdatedKeyCbs = nil
	cache.DeletedKeyCbs = nil
}

func (c *VMPoolCache) GetTypeString() string {
	return "VMPool"
}

func (c *VMPoolCache) Get(key *VMPoolKey, valbuf *VMPool) bool {
	var modRev int64
	return c.GetWithRev(key, valbuf, &modRev)
}

// STMGet gets from the store if STM is set, otherwise gets from cache
func (c *VMPoolCache) STMGet(ostm *OptionalSTM, key *VMPoolKey, valbuf *VMPool) bool {
	if ostm.stm != nil {
		if c.Store == nil {
			// panic, otherwise if we fallback to cache, we may silently
			// introduce race conditions and intermittent failures due to
			// reading from cache during a transaction.
			panic("VMPoolCache store not set, cannot read via STM")
		}
		return c.Store.STMGet(ostm.stm, key, valbuf)
	}
	var modRev int64
	return c.GetWithRev(key, valbuf, &modRev)
}

func (c *VMPoolCache) GetWithRev(key *VMPoolKey, valbuf *VMPool, modRev *int64) bool {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	inst, found := c.Objs[*key]
	if found {
		valbuf.DeepCopyIn(inst.Obj)
		*modRev = inst.ModRev
	}
	return found
}

func (c *VMPoolCache) HasKey(key *VMPoolKey) bool {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	_, found := c.Objs[*key]
	return found
}

func (c *VMPoolCache) GetAllKeys(ctx context.Context, cb func(key *VMPoolKey, modRev int64)) {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for key, data := range c.Objs {
		cb(&key, data.ModRev)
	}
}

func (c *VMPoolCache) GetAllLocked(ctx context.Context, cb func(obj *VMPool, modRev int64)) {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for _, data := range c.Objs {
		cb(data.Obj, data.ModRev)
	}
}

func (c *VMPoolCache) Update(ctx context.Context, in *VMPool, modRev int64) {
	c.UpdateModFunc(ctx, in.GetKey(), modRev, func(old *VMPool) (*VMPool, bool) {
		return in, true
	})
}

func (c *VMPoolCache) UpdateModFunc(ctx context.Context, key *VMPoolKey, modRev int64, modFunc func(old *VMPool) (new *VMPool, changed bool)) {
	c.Mux.Lock()
	var old *VMPool
	if oldData, found := c.Objs[*key]; found {
		old = oldData.Obj
	}
	new, changed := modFunc(old)
	if !changed {
		c.Mux.Unlock()
		return
	}
	if len(c.UpdatedCbs) > 0 || len(c.NotifyCbs) > 0 {
		newCopy := &VMPool{}
		newCopy.DeepCopyIn(new)
		for _, cb := range c.UpdatedCbs {
			defer cb(ctx, old, newCopy)
		}
		for _, cb := range c.NotifyCbs {
			if cb != nil {
				defer cb(ctx, newCopy, modRev)
			}
		}
	}
	for _, cb := range c.UpdatedKeyCbs {
		defer cb(ctx, key)
	}
	store := &VMPool{}
	store.DeepCopyIn(new)
	c.Objs[new.GetKeyVal()] = &VMPoolCacheData{
		Obj:    store,
		ModRev: modRev,
	}
	log.SpanLog(ctx, log.DebugLevelApi, "cache update", "new", store)
	c.Mux.Unlock()
	c.TriggerKeyWatchers(ctx, new.GetKey())
}

func (c *VMPoolCache) Delete(ctx context.Context, in *VMPool, modRev int64) {
	c.DeleteCondFunc(ctx, in, modRev, func(old *VMPool) bool {
		return true
	})
}

func (c *VMPoolCache) DeleteCondFunc(ctx context.Context, in *VMPool, modRev int64, condFunc func(old *VMPool) bool) {
	c.Mux.Lock()
	var old *VMPool
	oldData, found := c.Objs[in.GetKeyVal()]
	if found {
		old = oldData.Obj
		if !condFunc(old) {
			c.Mux.Unlock()
			return
		}
	}
	delete(c.Objs, in.GetKeyVal())
	log.SpanLog(ctx, log.DebugLevelApi, "cache delete", "key", in.GetKeyVal())
	c.Mux.Unlock()
	obj := old
	if obj == nil {
		obj = in
	}
	for _, cb := range c.NotifyCbs {
		if cb != nil {
			cb(ctx, obj, modRev)
		}
	}
	if old != nil {
		for _, cb := range c.DeletedCbs {
			cb(ctx, old)
		}
	}
	for _, cb := range c.DeletedKeyCbs {
		cb(ctx, in.GetKey())
	}
	c.TriggerKeyWatchers(ctx, in.GetKey())
}

func (c *VMPoolCache) Prune(ctx context.Context, validKeys map[VMPoolKey]struct{}) {
	log.SpanLog(ctx, log.DebugLevelApi, "Prune VMPool", "numValidKeys", len(validKeys))
	notify := make(map[VMPoolKey]*VMPoolCacheData)
	c.Mux.Lock()
	for key, _ := range c.Objs {
		if _, ok := validKeys[key]; !ok {
			if len(c.NotifyCbs) > 0 || len(c.DeletedKeyCbs) > 0 || len(c.DeletedCbs) > 0 {
				notify[key] = c.Objs[key]
			}
			delete(c.Objs, key)
		}
	}
	c.Mux.Unlock()
	for key, old := range notify {
		obj := old.Obj
		if obj == nil {
			obj = &VMPool{}
			obj.SetKey(&key)
		}
		for _, cb := range c.NotifyCbs {
			if cb != nil {
				cb(ctx, obj, old.ModRev)
			}
		}
		for _, cb := range c.DeletedKeyCbs {
			cb(ctx, &key)
		}
		if old.Obj != nil {
			for _, cb := range c.DeletedCbs {
				cb(ctx, old.Obj)
			}
		}
		c.TriggerKeyWatchers(ctx, &key)
	}
}

func (c *VMPoolCache) GetCount() int {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	return len(c.Objs)
}

func (c *VMPoolCache) Flush(ctx context.Context, notifyId int64) {
}

func (c *VMPoolCache) Show(filter *VMPool, cb func(ret *VMPool) error) error {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for _, data := range c.Objs {
		if !data.Obj.Matches(filter, MatchFilter()) {
			continue
		}
		err := cb(data.Obj)
		if err != nil {
			return err
		}
	}
	return nil
}

func VMPoolGenericNotifyCb(fn func(key *VMPoolKey, old *VMPool)) func(objstore.ObjKey, objstore.Obj) {
	return func(objkey objstore.ObjKey, obj objstore.Obj) {
		fn(objkey.(*VMPoolKey), obj.(*VMPool))
	}
}

func (c *VMPoolCache) SetNotifyCb(fn func(ctx context.Context, obj *VMPool, modRev int64)) {
	c.NotifyCbs = []func(ctx context.Context, obj *VMPool, modRev int64){fn}
}

func (c *VMPoolCache) SetUpdatedCb(fn func(ctx context.Context, old *VMPool, new *VMPool)) {
	c.UpdatedCbs = []func(ctx context.Context, old *VMPool, new *VMPool){fn}
}

func (c *VMPoolCache) SetDeletedCb(fn func(ctx context.Context, old *VMPool)) {
	c.DeletedCbs = []func(ctx context.Context, old *VMPool){fn}
}

func (c *VMPoolCache) SetUpdatedKeyCb(fn func(ctx context.Context, key *VMPoolKey)) {
	c.UpdatedKeyCbs = []func(ctx context.Context, key *VMPoolKey){fn}
}

func (c *VMPoolCache) SetDeletedKeyCb(fn func(ctx context.Context, key *VMPoolKey)) {
	c.DeletedKeyCbs = []func(ctx context.Context, key *VMPoolKey){fn}
}

func (c *VMPoolCache) AddUpdatedCb(fn func(ctx context.Context, old *VMPool, new *VMPool)) {
	c.UpdatedCbs = append(c.UpdatedCbs, fn)
}

func (c *VMPoolCache) AddDeletedCb(fn func(ctx context.Context, old *VMPool)) {
	c.DeletedCbs = append(c.DeletedCbs, fn)
}

func (c *VMPoolCache) AddNotifyCb(fn func(ctx context.Context, obj *VMPool, modRev int64)) {
	c.NotifyCbs = append(c.NotifyCbs, fn)
}

func (c *VMPoolCache) AddUpdatedKeyCb(fn func(ctx context.Context, key *VMPoolKey)) {
	c.UpdatedKeyCbs = append(c.UpdatedKeyCbs, fn)
}

func (c *VMPoolCache) AddDeletedKeyCb(fn func(ctx context.Context, key *VMPoolKey)) {
	c.DeletedKeyCbs = append(c.DeletedKeyCbs, fn)
}

func (c *VMPoolCache) SetFlushAll() {
	c.FlushAll = true
}

func (c *VMPoolCache) WatchKey(key *VMPoolKey, cb func(ctx context.Context)) context.CancelFunc {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	list, ok := c.KeyWatchers[*key]
	if !ok {
		list = make([]*VMPoolKeyWatcher, 0)
	}
	watcher := VMPoolKeyWatcher{cb: cb}
	c.KeyWatchers[*key] = append(list, &watcher)
	log.DebugLog(log.DebugLevelApi, "Watching VMPool", "key", key)
	return func() {
		c.Mux.Lock()
		defer c.Mux.Unlock()
		list, ok := c.KeyWatchers[*key]
		if !ok {
			return
		}
		for ii, _ := range list {
			if list[ii] != &watcher {
				continue
			}
			if len(list) == 1 {
				delete(c.KeyWatchers, *key)
				return
			}
			list[ii] = list[len(list)-1]
			list[len(list)-1] = nil
			c.KeyWatchers[*key] = list[:len(list)-1]
			return
		}
	}
}

func (c *VMPoolCache) TriggerKeyWatchers(ctx context.Context, key *VMPoolKey) {
	watchers := make([]*VMPoolKeyWatcher, 0)
	c.Mux.Lock()
	if list, ok := c.KeyWatchers[*key]; ok {
		watchers = append(watchers, list...)
	}
	c.Mux.Unlock()
	for ii, _ := range watchers {
		watchers[ii].cb(ctx)
	}
}

// Note that we explicitly ignore the global revision number, because of the way
// the notify framework sends updates (by hashing keys and doing lookups, instead
// of sequentially through a history buffer), updates may be done out-of-order
// or multiple updates compressed into one update, so the state of the cache at
// any point in time may not by in sync with a particular database revision number.

func (c *VMPoolCache) SyncUpdate(ctx context.Context, key, val []byte, rev, modRev int64) {
	obj := VMPool{}
	err := json.Unmarshal(val, &obj)
	if err != nil {
		log.WarnLog("Failed to parse VMPool data", "val", string(val), "err", err)
		return
	}
	c.Update(ctx, &obj, modRev)
	c.Mux.Lock()
	if c.List != nil {
		c.List[obj.GetKeyVal()] = struct{}{}
	}
	c.Mux.Unlock()
}

func (c *VMPoolCache) SyncDelete(ctx context.Context, key []byte, rev, modRev int64) {
	obj := VMPool{}
	keystr := objstore.DbKeyPrefixRemove(string(key))
	VMPoolKeyStringParse(keystr, obj.GetKey())
	c.Delete(ctx, &obj, modRev)
}

func (c *VMPoolCache) SyncListStart(ctx context.Context) {
	c.List = make(map[VMPoolKey]struct{})
}

func (c *VMPoolCache) SyncListEnd(ctx context.Context) {
	deleted := make(map[VMPoolKey]*VMPoolCacheData)
	c.Mux.Lock()
	for key, val := range c.Objs {
		if _, found := c.List[key]; !found {
			deleted[key] = val
			delete(c.Objs, key)
		}
	}
	c.List = nil
	c.Mux.Unlock()
	for key, val := range deleted {
		obj := val.Obj
		if obj == nil {
			obj = &VMPool{}
			obj.SetKey(&key)
		}
		for _, cb := range c.NotifyCbs {
			if cb != nil {
				cb(ctx, obj, val.ModRev)
			}
		}
		for _, cb := range c.DeletedKeyCbs {
			cb(ctx, &key)
		}
		if val.Obj != nil {
			for _, cb := range c.DeletedCbs {
				cb(ctx, val.Obj)
			}
		}
		c.TriggerKeyWatchers(ctx, &key)
	}
}

func (s *VMPoolCache) InitCacheWithSync(sync DataSync) {
	InitVMPoolCache(s)
	s.InitSync(sync)
}

func (s *VMPoolCache) InitSync(sync DataSync) {
	if sync != nil {
		s.Store = NewVMPoolStore(sync.GetKVStore())
		sync.RegisterCache(s)
	}
}

func InitVMPoolCacheWithStore(cache *VMPoolCache, store VMPoolStore) {
	InitVMPoolCache(cache)
	cache.Store = store
}

func (c *VMPoolCache) UsesOrg(org string) bool {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for key, _ := range c.Objs {
		if key.Organization == org {
			return true
		}
	}
	return false
}

func (m *VMPool) GetObjKey() objstore.ObjKey {
	return m.GetKey()
}

func (m *VMPool) GetKey() *VMPoolKey {
	return &m.Key
}

func (m *VMPool) GetKeyVal() VMPoolKey {
	return m.Key
}

func (m *VMPool) SetKey(key *VMPoolKey) {
	m.Key = *key
}

func CmpSortVMPool(a VMPool, b VMPool) bool {
	return a.Key.GetKeyString() < b.Key.GetKeyString()
}
func (m *VMPoolKey) StreamKey() string {
	return fmt.Sprintf("VMPoolStreamKey: %s", m.String())
}

// Helper method to check that enums have valid values
// NOTE: ValidateEnums checks all Fields even if some are not set
func (m *VMPool) ValidateEnums() error {
	if err := m.Key.ValidateEnums(); err != nil {
		return err
	}
	for _, e := range m.Vms {
		if err := e.ValidateEnums(); err != nil {
			return err
		}
	}
	if _, ok := TrackedState_name[int32(m.State)]; !ok {
		return errors.New("invalid State")
	}
	if _, ok := CRMOverride_name[int32(m.CrmOverride)]; !ok {
		return errors.New("invalid CrmOverride")
	}
	return nil
}

func (s *VMPool) ClearTagged(tags map[string]struct{}) {
	s.Key.ClearTagged(tags)
	if s.Vms != nil {
		for ii := 0; ii < len(s.Vms); ii++ {
			s.Vms[ii].ClearTagged(tags)
		}
	}
	if _, found := tags["nocmp"]; found {
		s.Errors = nil
	}
}

func IgnoreVMPoolFields(taglist string) cmp.Option {
	names := []string{}
	tags := make(map[string]struct{})
	for _, tag := range strings.Split(taglist, ",") {
		tags[tag] = struct{}{}
	}
	if _, found := tags["timestamp"]; found {
		names = append(names, "Vms.UpdatedAt")
	}
	if _, found := tags["nocmp"]; found {
		names = append(names, "Errors")
	}
	return cmpopts.IgnoreFields(VMPool{}, names...)
}

func (m *VMPoolMember) Clone() *VMPoolMember {
	cp := &VMPoolMember{}
	cp.DeepCopyIn(m)
	return cp
}

func (m *VMPoolMember) CopyInFields(src *VMPoolMember) int {
	updateListAction := "replace"
	changed := 0
	if m.Key.Organization != src.Key.Organization {
		m.Key.Organization = src.Key.Organization
		changed++
	}
	if m.Key.Name != src.Key.Name {
		m.Key.Name = src.Key.Name
		changed++
	}
	if m.Vm.Name != src.Vm.Name {
		m.Vm.Name = src.Vm.Name
		changed++
	}
	if m.Vm.NetInfo.ExternalIp != src.Vm.NetInfo.ExternalIp {
		m.Vm.NetInfo.ExternalIp = src.Vm.NetInfo.ExternalIp
		changed++
	}
	if m.Vm.NetInfo.InternalIp != src.Vm.NetInfo.InternalIp {
		m.Vm.NetInfo.InternalIp = src.Vm.NetInfo.InternalIp
		changed++
	}
	if m.Vm.GroupName != src.Vm.GroupName {
		m.Vm.GroupName = src.Vm.GroupName
		changed++
	}
	if m.Vm.State != src.Vm.State {
		m.Vm.State = src.Vm.State
		changed++
	}
	if m.Vm.UpdatedAt.Seconds != src.Vm.UpdatedAt.Seconds {
		m.Vm.UpdatedAt.Seconds = src.Vm.UpdatedAt.Seconds
		changed++
	}
	if m.Vm.UpdatedAt.Nanos != src.Vm.UpdatedAt.Nanos {
		m.Vm.UpdatedAt.Nanos = src.Vm.UpdatedAt.Nanos
		changed++
	}
	if m.Vm.InternalName != src.Vm.InternalName {
		m.Vm.InternalName = src.Vm.InternalName
		changed++
	}
	if src.Vm.Flavor != nil {
		if m.Vm.Flavor == nil {
			m.Vm.Flavor = &FlavorInfo{}
		}
		if m.Vm.Flavor.Name != src.Vm.Flavor.Name {
			m.Vm.Flavor.Name = src.Vm.Flavor.Name
			changed++
		}
		if m.Vm.Flavor.Vcpus != src.Vm.Flavor.Vcpus {
			m.Vm.Flavor.Vcpus = src.Vm.Flavor.Vcpus
			changed++
		}
		if m.Vm.Flavor.Ram != src.Vm.Flavor.Ram {
			m.Vm.Flavor.Ram = src.Vm.Flavor.Ram
			changed++
		}
		if m.Vm.Flavor.Disk != src.Vm.Flavor.Disk {
			m.Vm.Flavor.Disk = src.Vm.Flavor.Disk
			changed++
		}
		if src.Vm.Flavor.PropMap != nil {
			if updateListAction == "add" {
				for k2, v := range src.Vm.Flavor.PropMap {
					m.Vm.Flavor.PropMap[k2] = v
					changed++
				}
			} else if updateListAction == "remove" {
				for k2, _ := range src.Vm.Flavor.PropMap {
					if _, ok := m.Vm.Flavor.PropMap[k2]; ok {
						delete(m.Vm.Flavor.PropMap, k2)
						changed++
					}
				}
			} else {
				m.Vm.Flavor.PropMap = make(map[string]string)
				for k2, v := range src.Vm.Flavor.PropMap {
					m.Vm.Flavor.PropMap[k2] = v
				}
				changed++
			}
		} else if m.Vm.Flavor.PropMap != nil {
			m.Vm.Flavor.PropMap = nil
			changed++
		}
	} else if m.Vm.Flavor != nil {
		m.Vm.Flavor = nil
		changed++
	}
	if m.CrmOverride != src.CrmOverride {
		m.CrmOverride = src.CrmOverride
		changed++
	}
	return changed
}

func (m *VMPoolMember) DeepCopyIn(src *VMPoolMember) {
	m.Key.DeepCopyIn(&src.Key)
	m.Vm.DeepCopyIn(&src.Vm)
	m.CrmOverride = src.CrmOverride
}

func (m *VMPoolMember) GetObjKey() objstore.ObjKey {
	return m.GetKey()
}

func (m *VMPoolMember) GetKey() *VMPoolKey {
	return &m.Key
}

func (m *VMPoolMember) GetKeyVal() VMPoolKey {
	return m.Key
}

func (m *VMPoolMember) SetKey(key *VMPoolKey) {
	m.Key = *key
}

func CmpSortVMPoolMember(a VMPoolMember, b VMPoolMember) bool {
	return a.Key.GetKeyString() < b.Key.GetKeyString()
}

// Helper method to check that enums have valid values
func (m *VMPoolMember) ValidateEnums() error {
	if err := m.Key.ValidateEnums(); err != nil {
		return err
	}
	if err := m.Vm.ValidateEnums(); err != nil {
		return err
	}
	if _, ok := CRMOverride_name[int32(m.CrmOverride)]; !ok {
		return errors.New("invalid CrmOverride")
	}
	return nil
}

func (s *VMPoolMember) ClearTagged(tags map[string]struct{}) {
	s.Key.ClearTagged(tags)
	s.Vm.ClearTagged(tags)
}

func IgnoreVMPoolMemberFields(taglist string) cmp.Option {
	names := []string{}
	tags := make(map[string]struct{})
	for _, tag := range strings.Split(taglist, ",") {
		tags[tag] = struct{}{}
	}
	if _, found := tags["timestamp"]; found {
		names = append(names, "Vm.UpdatedAt")
	}
	return cmpopts.IgnoreFields(VMPoolMember{}, names...)
}

func (m *VMSpec) Clone() *VMSpec {
	cp := &VMSpec{}
	cp.DeepCopyIn(m)
	return cp
}

func (m *VMSpec) CopyInFields(src *VMSpec) int {
	updateListAction := "replace"
	changed := 0
	if m.InternalName != src.InternalName {
		m.InternalName = src.InternalName
		changed++
	}
	if m.ExternalNetwork != src.ExternalNetwork {
		m.ExternalNetwork = src.ExternalNetwork
		changed++
	}
	if m.InternalNetwork != src.InternalNetwork {
		m.InternalNetwork = src.InternalNetwork
		changed++
	}
	if m.Flavor.Key.Name != src.Flavor.Key.Name {
		m.Flavor.Key.Name = src.Flavor.Key.Name
		changed++
	}
	if m.Flavor.Ram != src.Flavor.Ram {
		m.Flavor.Ram = src.Flavor.Ram
		changed++
	}
	if m.Flavor.Vcpus != src.Flavor.Vcpus {
		m.Flavor.Vcpus = src.Flavor.Vcpus
		changed++
	}
	if m.Flavor.Disk != src.Flavor.Disk {
		m.Flavor.Disk = src.Flavor.Disk
		changed++
	}
	if src.Flavor.OptResMap != nil {
		if updateListAction == "add" {
			for k1, v := range src.Flavor.OptResMap {
				m.Flavor.OptResMap[k1] = v
				changed++
			}
		} else if updateListAction == "remove" {
			for k1, _ := range src.Flavor.OptResMap {
				if _, ok := m.Flavor.OptResMap[k1]; ok {
					delete(m.Flavor.OptResMap, k1)
					changed++
				}
			}
		} else {
			m.Flavor.OptResMap = make(map[string]string)
			for k1, v := range src.Flavor.OptResMap {
				m.Flavor.OptResMap[k1] = v
			}
			changed++
		}
	} else if m.Flavor.OptResMap != nil {
		m.Flavor.OptResMap = nil
		changed++
	}
	if m.Flavor.DeletePrepare != src.Flavor.DeletePrepare {
		m.Flavor.DeletePrepare = src.Flavor.DeletePrepare
		changed++
	}
	return changed
}

func (m *VMSpec) DeepCopyIn(src *VMSpec) {
	m.InternalName = src.InternalName
	m.ExternalNetwork = src.ExternalNetwork
	m.InternalNetwork = src.InternalNetwork
	m.Flavor.DeepCopyIn(&src.Flavor)
}

// Helper method to check that enums have valid values
func (m *VMSpec) ValidateEnums() error {
	if err := m.Flavor.ValidateEnums(); err != nil {
		return err
	}
	return nil
}

func (s *VMSpec) ClearTagged(tags map[string]struct{}) {
	s.Flavor.ClearTagged(tags)
}

func (m *VMPoolInfo) Matches(o *VMPoolInfo, fopts ...MatchOpt) bool {
	opts := MatchOptions{}
	applyMatchOptions(&opts, fopts...)
	if o == nil {
		if opts.Filter {
			return true
		}
		return false
	}
	if !m.Key.Matches(&o.Key, fopts...) {
		return false
	}
	if !opts.Filter || o.NotifyId != 0 {
		if o.NotifyId != m.NotifyId {
			return false
		}
	}
	if !opts.Filter || o.Vms != nil {
		if len(m.Vms) == 0 && len(o.Vms) > 0 || len(m.Vms) > 0 && len(o.Vms) == 0 {
			return false
		} else if m.Vms != nil && o.Vms != nil {
			if !opts.Filter && len(m.Vms) != len(o.Vms) {
				return false
			}
		}
	}
	if !opts.IgnoreBackend {
		if !opts.Filter || o.State != 0 {
			if o.State != m.State {
				return false
			}
		}
	}
	if !opts.IgnoreBackend {
		if !opts.Filter || o.Errors != nil {
			if len(m.Errors) == 0 && len(o.Errors) > 0 || len(m.Errors) > 0 && len(o.Errors) == 0 {
				return false
			} else if m.Errors != nil && o.Errors != nil {
				if !opts.Filter && len(m.Errors) != len(o.Errors) {
					return false
				}
				found := 0
				for oIndex, _ := range o.Errors {
					for mIndex, _ := range m.Errors {
						if o.Errors[oIndex] == m.Errors[mIndex] {
							found++
							break
						}
					}
				}
				if found != len(o.Errors) {
					return false
				}
			}
		}
	}
	if !opts.IgnoreBackend {
	}
	return true
}

const VMPoolInfoFieldKey = "2"
const VMPoolInfoFieldKeyOrganization = "2.1"
const VMPoolInfoFieldKeyName = "2.2"
const VMPoolInfoFieldNotifyId = "3"
const VMPoolInfoFieldVms = "4"
const VMPoolInfoFieldVmsName = "4.1"
const VMPoolInfoFieldVmsNetInfo = "4.2"
const VMPoolInfoFieldVmsNetInfoExternalIp = "4.2.1"
const VMPoolInfoFieldVmsNetInfoInternalIp = "4.2.2"
const VMPoolInfoFieldVmsGroupName = "4.3"
const VMPoolInfoFieldVmsState = "4.4"
const VMPoolInfoFieldVmsUpdatedAt = "4.5"
const VMPoolInfoFieldVmsUpdatedAtSeconds = "4.5.1"
const VMPoolInfoFieldVmsUpdatedAtNanos = "4.5.2"
const VMPoolInfoFieldVmsInternalName = "4.6"
const VMPoolInfoFieldVmsFlavor = "4.7"
const VMPoolInfoFieldVmsFlavorName = "4.7.1"
const VMPoolInfoFieldVmsFlavorVcpus = "4.7.2"
const VMPoolInfoFieldVmsFlavorRam = "4.7.3"
const VMPoolInfoFieldVmsFlavorDisk = "4.7.4"
const VMPoolInfoFieldVmsFlavorPropMap = "4.7.5"
const VMPoolInfoFieldVmsFlavorPropMapKey = "4.7.5.1"
const VMPoolInfoFieldVmsFlavorPropMapValue = "4.7.5.2"
const VMPoolInfoFieldState = "5"
const VMPoolInfoFieldErrors = "6"
const VMPoolInfoFieldStatus = "7"
const VMPoolInfoFieldStatusTaskNumber = "7.1"
const VMPoolInfoFieldStatusMaxTasks = "7.2"
const VMPoolInfoFieldStatusTaskName = "7.3"
const VMPoolInfoFieldStatusStepName = "7.4"
const VMPoolInfoFieldStatusMsgCount = "7.5"
const VMPoolInfoFieldStatusMsgs = "7.6"

var VMPoolInfoAllFields = []string{
	VMPoolInfoFieldKeyOrganization,
	VMPoolInfoFieldKeyName,
	VMPoolInfoFieldNotifyId,
	VMPoolInfoFieldVmsName,
	VMPoolInfoFieldVmsNetInfoExternalIp,
	VMPoolInfoFieldVmsNetInfoInternalIp,
	VMPoolInfoFieldVmsGroupName,
	VMPoolInfoFieldVmsState,
	VMPoolInfoFieldVmsUpdatedAtSeconds,
	VMPoolInfoFieldVmsUpdatedAtNanos,
	VMPoolInfoFieldVmsInternalName,
	VMPoolInfoFieldVmsFlavorName,
	VMPoolInfoFieldVmsFlavorVcpus,
	VMPoolInfoFieldVmsFlavorRam,
	VMPoolInfoFieldVmsFlavorDisk,
	VMPoolInfoFieldVmsFlavorPropMapKey,
	VMPoolInfoFieldVmsFlavorPropMapValue,
	VMPoolInfoFieldState,
	VMPoolInfoFieldErrors,
	VMPoolInfoFieldStatusTaskNumber,
	VMPoolInfoFieldStatusMaxTasks,
	VMPoolInfoFieldStatusTaskName,
	VMPoolInfoFieldStatusStepName,
	VMPoolInfoFieldStatusMsgCount,
	VMPoolInfoFieldStatusMsgs,
}

var VMPoolInfoAllFieldsMap = NewFieldMap(map[string]struct{}{
	VMPoolInfoFieldKeyOrganization:       struct{}{},
	VMPoolInfoFieldKeyName:               struct{}{},
	VMPoolInfoFieldNotifyId:              struct{}{},
	VMPoolInfoFieldVmsName:               struct{}{},
	VMPoolInfoFieldVmsNetInfoExternalIp:  struct{}{},
	VMPoolInfoFieldVmsNetInfoInternalIp:  struct{}{},
	VMPoolInfoFieldVmsGroupName:          struct{}{},
	VMPoolInfoFieldVmsState:              struct{}{},
	VMPoolInfoFieldVmsUpdatedAtSeconds:   struct{}{},
	VMPoolInfoFieldVmsUpdatedAtNanos:     struct{}{},
	VMPoolInfoFieldVmsInternalName:       struct{}{},
	VMPoolInfoFieldVmsFlavorName:         struct{}{},
	VMPoolInfoFieldVmsFlavorVcpus:        struct{}{},
	VMPoolInfoFieldVmsFlavorRam:          struct{}{},
	VMPoolInfoFieldVmsFlavorDisk:         struct{}{},
	VMPoolInfoFieldVmsFlavorPropMapKey:   struct{}{},
	VMPoolInfoFieldVmsFlavorPropMapValue: struct{}{},
	VMPoolInfoFieldState:                 struct{}{},
	VMPoolInfoFieldErrors:                struct{}{},
	VMPoolInfoFieldStatusTaskNumber:      struct{}{},
	VMPoolInfoFieldStatusMaxTasks:        struct{}{},
	VMPoolInfoFieldStatusTaskName:        struct{}{},
	VMPoolInfoFieldStatusStepName:        struct{}{},
	VMPoolInfoFieldStatusMsgCount:        struct{}{},
	VMPoolInfoFieldStatusMsgs:            struct{}{},
})

var VMPoolInfoAllFieldsStringMap = map[string]string{
	VMPoolInfoFieldKeyOrganization:       "Key Organization",
	VMPoolInfoFieldKeyName:               "Key Name",
	VMPoolInfoFieldNotifyId:              "Notify Id",
	VMPoolInfoFieldVmsName:               "Vms Name",
	VMPoolInfoFieldVmsNetInfoExternalIp:  "Vms Net Info External Ip",
	VMPoolInfoFieldVmsNetInfoInternalIp:  "Vms Net Info Internal Ip",
	VMPoolInfoFieldVmsGroupName:          "Vms Group Name",
	VMPoolInfoFieldVmsState:              "Vms State",
	VMPoolInfoFieldVmsUpdatedAtSeconds:   "Vms Updated At Seconds",
	VMPoolInfoFieldVmsUpdatedAtNanos:     "Vms Updated At Nanos",
	VMPoolInfoFieldVmsInternalName:       "Vms Internal Name",
	VMPoolInfoFieldVmsFlavorName:         "Vms Flavor Name",
	VMPoolInfoFieldVmsFlavorVcpus:        "Vms Flavor Vcpus",
	VMPoolInfoFieldVmsFlavorRam:          "Vms Flavor Ram",
	VMPoolInfoFieldVmsFlavorDisk:         "Vms Flavor Disk",
	VMPoolInfoFieldVmsFlavorPropMapKey:   "Vms Flavor Prop Map Key",
	VMPoolInfoFieldVmsFlavorPropMapValue: "Vms Flavor Prop Map Value",
	VMPoolInfoFieldState:                 "State",
	VMPoolInfoFieldErrors:                "Errors",
	VMPoolInfoFieldStatusTaskNumber:      "Status Task Number",
	VMPoolInfoFieldStatusMaxTasks:        "Status Max Tasks",
	VMPoolInfoFieldStatusTaskName:        "Status Task Name",
	VMPoolInfoFieldStatusStepName:        "Status Step Name",
	VMPoolInfoFieldStatusMsgCount:        "Status Msg Count",
	VMPoolInfoFieldStatusMsgs:            "Status Msgs",
}

func (m *VMPoolInfo) IsKeyField(s string) bool {
	return strings.HasPrefix(s, VMPoolInfoFieldKey+".") || s == VMPoolInfoFieldKey
}

func (m *VMPoolInfo) DiffFields(o *VMPoolInfo, fields *FieldMap) {
	if m.Key.Organization != o.Key.Organization {
		fields.Set(VMPoolInfoFieldKeyOrganization)
		fields.Set(VMPoolInfoFieldKey)
	}
	if m.Key.Name != o.Key.Name {
		fields.Set(VMPoolInfoFieldKeyName)
		fields.Set(VMPoolInfoFieldKey)
	}
	if m.NotifyId != o.NotifyId {
		fields.Set(VMPoolInfoFieldNotifyId)
	}
	if len(m.Vms) != len(o.Vms) {
		fields.Set(VMPoolInfoFieldVms)
	} else {
		for i0 := 0; i0 < len(m.Vms); i0++ {
			if m.Vms[i0].Name != o.Vms[i0].Name {
				fields.Set(VMPoolInfoFieldVmsName)
				fields.Set(VMPoolInfoFieldVms)
			}
			if m.Vms[i0].NetInfo.ExternalIp != o.Vms[i0].NetInfo.ExternalIp {
				fields.Set(VMPoolInfoFieldVmsNetInfoExternalIp)
				fields.Set(VMPoolInfoFieldVmsNetInfo)
				fields.Set(VMPoolInfoFieldVms)
			}
			if m.Vms[i0].NetInfo.InternalIp != o.Vms[i0].NetInfo.InternalIp {
				fields.Set(VMPoolInfoFieldVmsNetInfoInternalIp)
				fields.Set(VMPoolInfoFieldVmsNetInfo)
				fields.Set(VMPoolInfoFieldVms)
			}
			if m.Vms[i0].GroupName != o.Vms[i0].GroupName {
				fields.Set(VMPoolInfoFieldVmsGroupName)
				fields.Set(VMPoolInfoFieldVms)
			}
			if m.Vms[i0].State != o.Vms[i0].State {
				fields.Set(VMPoolInfoFieldVmsState)
				fields.Set(VMPoolInfoFieldVms)
			}
			if m.Vms[i0].UpdatedAt.Seconds != o.Vms[i0].UpdatedAt.Seconds {
				fields.Set(VMPoolInfoFieldVmsUpdatedAtSeconds)
				fields.Set(VMPoolInfoFieldVmsUpdatedAt)
				fields.Set(VMPoolInfoFieldVms)
			}
			if m.Vms[i0].UpdatedAt.Nanos != o.Vms[i0].UpdatedAt.Nanos {
				fields.Set(VMPoolInfoFieldVmsUpdatedAtNanos)
				fields.Set(VMPoolInfoFieldVmsUpdatedAt)
				fields.Set(VMPoolInfoFieldVms)
			}
			if m.Vms[i0].InternalName != o.Vms[i0].InternalName {
				fields.Set(VMPoolInfoFieldVmsInternalName)
				fields.Set(VMPoolInfoFieldVms)
			}
			if m.Vms[i0].Flavor != nil && o.Vms[i0].Flavor != nil {
				if m.Vms[i0].Flavor.Name != o.Vms[i0].Flavor.Name {
					fields.Set(VMPoolInfoFieldVmsFlavorName)
					fields.Set(VMPoolInfoFieldVmsFlavor)
					fields.Set(VMPoolInfoFieldVms)
				}
				if m.Vms[i0].Flavor.Vcpus != o.Vms[i0].Flavor.Vcpus {
					fields.Set(VMPoolInfoFieldVmsFlavorVcpus)
					fields.Set(VMPoolInfoFieldVmsFlavor)
					fields.Set(VMPoolInfoFieldVms)
				}
				if m.Vms[i0].Flavor.Ram != o.Vms[i0].Flavor.Ram {
					fields.Set(VMPoolInfoFieldVmsFlavorRam)
					fields.Set(VMPoolInfoFieldVmsFlavor)
					fields.Set(VMPoolInfoFieldVms)
				}
				if m.Vms[i0].Flavor.Disk != o.Vms[i0].Flavor.Disk {
					fields.Set(VMPoolInfoFieldVmsFlavorDisk)
					fields.Set(VMPoolInfoFieldVmsFlavor)
					fields.Set(VMPoolInfoFieldVms)
				}
				if m.Vms[i0].Flavor.PropMap != nil && o.Vms[i0].Flavor.PropMap != nil {
					if len(m.Vms[i0].Flavor.PropMap) != len(o.Vms[i0].Flavor.PropMap) {
						fields.Set(VMPoolInfoFieldVmsFlavorPropMap)
						fields.Set(VMPoolInfoFieldVmsFlavor)
						fields.Set(VMPoolInfoFieldVms)
					} else {
						for k2, _ := range m.Vms[i0].Flavor.PropMap {
							_, vok2 := o.Vms[i0].Flavor.PropMap[k2]
							if !vok2 {
								fields.Set(VMPoolInfoFieldVmsFlavorPropMap)
								fields.Set(VMPoolInfoFieldVmsFlavor)
								fields.Set(VMPoolInfoFieldVms)
							} else {
								if m.Vms[i0].Flavor.PropMap[k2] != o.Vms[i0].Flavor.PropMap[k2] {
									fields.Set(VMPoolInfoFieldVmsFlavorPropMap)
									fields.Set(VMPoolInfoFieldVmsFlavor)
									fields.Set(VMPoolInfoFieldVms)
									break
								}
							}
						}
					}
				} else if (m.Vms[i0].Flavor.PropMap != nil && o.Vms[i0].Flavor.PropMap == nil) || (m.Vms[i0].Flavor.PropMap == nil && o.Vms[i0].Flavor.PropMap != nil) {
					fields.Set(VMPoolInfoFieldVmsFlavorPropMap)
					fields.Set(VMPoolInfoFieldVmsFlavor)
					fields.Set(VMPoolInfoFieldVms)
				}
			} else if (m.Vms[i0].Flavor != nil && o.Vms[i0].Flavor == nil) || (m.Vms[i0].Flavor == nil && o.Vms[i0].Flavor != nil) {
				fields.Set(VMPoolInfoFieldVmsFlavor)
				fields.Set(VMPoolInfoFieldVms)
			}
		}
	}
	if m.State != o.State {
		fields.Set(VMPoolInfoFieldState)
	}
	if len(m.Errors) != len(o.Errors) {
		fields.Set(VMPoolInfoFieldErrors)
	} else {
		for i0 := 0; i0 < len(m.Errors); i0++ {
			if m.Errors[i0] != o.Errors[i0] {
				fields.Set(VMPoolInfoFieldErrors)
				break
			}
		}
	}
	if m.Status.TaskNumber != o.Status.TaskNumber {
		fields.Set(VMPoolInfoFieldStatusTaskNumber)
		fields.Set(VMPoolInfoFieldStatus)
	}
	if m.Status.MaxTasks != o.Status.MaxTasks {
		fields.Set(VMPoolInfoFieldStatusMaxTasks)
		fields.Set(VMPoolInfoFieldStatus)
	}
	if m.Status.TaskName != o.Status.TaskName {
		fields.Set(VMPoolInfoFieldStatusTaskName)
		fields.Set(VMPoolInfoFieldStatus)
	}
	if m.Status.StepName != o.Status.StepName {
		fields.Set(VMPoolInfoFieldStatusStepName)
		fields.Set(VMPoolInfoFieldStatus)
	}
	if m.Status.MsgCount != o.Status.MsgCount {
		fields.Set(VMPoolInfoFieldStatusMsgCount)
		fields.Set(VMPoolInfoFieldStatus)
	}
	if len(m.Status.Msgs) != len(o.Status.Msgs) {
		fields.Set(VMPoolInfoFieldStatusMsgs)
		fields.Set(VMPoolInfoFieldStatus)
	} else {
		for i1 := 0; i1 < len(m.Status.Msgs); i1++ {
			if m.Status.Msgs[i1] != o.Status.Msgs[i1] {
				fields.Set(VMPoolInfoFieldStatusMsgs)
				fields.Set(VMPoolInfoFieldStatus)
				break
			}
		}
	}
}

func (m *VMPoolInfo) GetDiffFields(o *VMPoolInfo) *FieldMap {
	diffFields := NewFieldMap(nil)
	m.DiffFields(o, diffFields)
	return diffFields
}

func (m *VMPoolInfo) Clone() *VMPoolInfo {
	cp := &VMPoolInfo{}
	cp.DeepCopyIn(m)
	return cp
}

func (m *VMPoolInfo) AddVms(vals ...VM) int {
	changes := 0
	cur := make(map[string]struct{})
	for _, v := range m.Vms {
		cur[v.String()] = struct{}{}
	}
	for _, v := range vals {
		if _, found := cur[v.String()]; found {
			continue // duplicate
		}
		m.Vms = append(m.Vms, v)
		changes++
	}
	return changes
}

func (m *VMPoolInfo) RemoveVms(vals ...VM) int {
	changes := 0
	remove := make(map[string]struct{})
	for _, v := range vals {
		remove[v.String()] = struct{}{}
	}
	for i := len(m.Vms); i >= 0; i-- {
		if _, found := remove[m.Vms[i].String()]; found {
			m.Vms = append(m.Vms[:i], m.Vms[i+1:]...)
			changes++
		}
	}
	return changes
}

func (m *VMPoolInfo) AddErrors(vals ...string) int {
	changes := 0
	cur := make(map[string]struct{})
	for _, v := range m.Errors {
		cur[v] = struct{}{}
	}
	for _, v := range vals {
		if _, found := cur[v]; found {
			continue // duplicate
		}
		m.Errors = append(m.Errors, v)
		changes++
	}
	return changes
}

func (m *VMPoolInfo) RemoveErrors(vals ...string) int {
	changes := 0
	remove := make(map[string]struct{})
	for _, v := range vals {
		remove[v] = struct{}{}
	}
	for i := len(m.Errors); i >= 0; i-- {
		if _, found := remove[m.Errors[i]]; found {
			m.Errors = append(m.Errors[:i], m.Errors[i+1:]...)
			changes++
		}
	}
	return changes
}

func (m *VMPoolInfo) AddStatusMsgs(vals ...string) int {
	changes := 0
	cur := make(map[string]struct{})
	for _, v := range m.Status.Msgs {
		cur[v] = struct{}{}
	}
	for _, v := range vals {
		if _, found := cur[v]; found {
			continue // duplicate
		}
		m.Status.Msgs = append(m.Status.Msgs, v)
		changes++
	}
	return changes
}

func (m *VMPoolInfo) RemoveStatusMsgs(vals ...string) int {
	changes := 0
	remove := make(map[string]struct{})
	for _, v := range vals {
		remove[v] = struct{}{}
	}
	for i := len(m.Status.Msgs); i >= 0; i-- {
		if _, found := remove[m.Status.Msgs[i]]; found {
			m.Status.Msgs = append(m.Status.Msgs[:i], m.Status.Msgs[i+1:]...)
			changes++
		}
	}
	return changes
}

func (m *VMPoolInfo) CopyInFields(src *VMPoolInfo) int {
	updateListAction := "replace"
	changed := 0
	fmap := MakeFieldMap(src.Fields)
	if fmap.HasOrHasChild("2") {
		if fmap.Has("2.1") {
			if m.Key.Organization != src.Key.Organization {
				m.Key.Organization = src.Key.Organization
				changed++
			}
		}
		if fmap.Has("2.2") {
			if m.Key.Name != src.Key.Name {
				m.Key.Name = src.Key.Name
				changed++
			}
		}
	}
	if fmap.Has("3") {
		if m.NotifyId != src.NotifyId {
			m.NotifyId = src.NotifyId
			changed++
		}
	}
	if fmap.HasOrHasChild("4") {
		if src.Vms != nil {
			if updateListAction == "add" {
				changed += m.AddVms(src.Vms...)
			} else if updateListAction == "remove" {
				changed += m.RemoveVms(src.Vms...)
			} else {
				m.Vms = make([]VM, 0)
				for k0, _ := range src.Vms {
					m.Vms = append(m.Vms, *src.Vms[k0].Clone())
				}
				changed++
			}
		} else if m.Vms != nil {
			m.Vms = nil
			changed++
		}
	}
	if fmap.Has("5") {
		if m.State != src.State {
			m.State = src.State
			changed++
		}
	}
	if fmap.Has("6") {
		if src.Errors != nil {
			if updateListAction == "add" {
				changed += m.AddErrors(src.Errors...)
			} else if updateListAction == "remove" {
				changed += m.RemoveErrors(src.Errors...)
			} else {
				m.Errors = make([]string, 0)
				m.Errors = append(m.Errors, src.Errors...)
				changed++
			}
		} else if m.Errors != nil {
			m.Errors = nil
			changed++
		}
	}
	if fmap.HasOrHasChild("7") {
		if fmap.Has("7.1") {
			if m.Status.TaskNumber != src.Status.TaskNumber {
				m.Status.TaskNumber = src.Status.TaskNumber
				changed++
			}
		}
		if fmap.Has("7.2") {
			if m.Status.MaxTasks != src.Status.MaxTasks {
				m.Status.MaxTasks = src.Status.MaxTasks
				changed++
			}
		}
		if fmap.Has("7.3") {
			if m.Status.TaskName != src.Status.TaskName {
				m.Status.TaskName = src.Status.TaskName
				changed++
			}
		}
		if fmap.Has("7.4") {
			if m.Status.StepName != src.Status.StepName {
				m.Status.StepName = src.Status.StepName
				changed++
			}
		}
		if fmap.Has("7.5") {
			if m.Status.MsgCount != src.Status.MsgCount {
				m.Status.MsgCount = src.Status.MsgCount
				changed++
			}
		}
		if fmap.Has("7.6") {
			if src.Status.Msgs != nil {
				if updateListAction == "add" {
					changed += m.AddStatusMsgs(src.Status.Msgs...)
				} else if updateListAction == "remove" {
					changed += m.RemoveStatusMsgs(src.Status.Msgs...)
				} else {
					m.Status.Msgs = make([]string, 0)
					m.Status.Msgs = append(m.Status.Msgs, src.Status.Msgs...)
					changed++
				}
			} else if m.Status.Msgs != nil {
				m.Status.Msgs = nil
				changed++
			}
		}
	}
	return changed
}

func (m *VMPoolInfo) DeepCopyIn(src *VMPoolInfo) {
	m.Key.DeepCopyIn(&src.Key)
	m.NotifyId = src.NotifyId
	if src.Vms != nil {
		m.Vms = make([]VM, len(src.Vms), len(src.Vms))
		for ii, s := range src.Vms {
			m.Vms[ii].DeepCopyIn(&s)
		}
	} else {
		m.Vms = nil
	}
	m.State = src.State
	if src.Errors != nil {
		m.Errors = make([]string, len(src.Errors), len(src.Errors))
		for ii, s := range src.Errors {
			m.Errors[ii] = s
		}
	} else {
		m.Errors = nil
	}
	m.Status.DeepCopyIn(&src.Status)
}

func (s *VMPoolInfo) HasFields() bool {
	return true
}

type VMPoolInfoStore interface {
	Create(ctx context.Context, m *VMPoolInfo, wait func(int64)) (*Result, error)
	Update(ctx context.Context, m *VMPoolInfo, wait func(int64)) (*Result, error)
	Delete(ctx context.Context, m *VMPoolInfo, wait func(int64)) (*Result, error)
	Put(ctx context.Context, m *VMPoolInfo, wait func(int64), ops ...objstore.KVOp) (*Result, error)
	LoadOne(key string) (*VMPoolInfo, int64, error)
	Get(ctx context.Context, key *VMPoolKey, buf *VMPoolInfo) bool
	STMGet(stm concurrency.STM, key *VMPoolKey, buf *VMPoolInfo) bool
	STMPut(stm concurrency.STM, obj *VMPoolInfo, ops ...objstore.KVOp)
	STMDel(stm concurrency.STM, key *VMPoolKey)
	STMHas(stm concurrency.STM, key *VMPoolKey) bool
}

type VMPoolInfoStoreImpl struct {
	kvstore objstore.KVStore
}

func NewVMPoolInfoStore(kvstore objstore.KVStore) *VMPoolInfoStoreImpl {
	return &VMPoolInfoStoreImpl{kvstore: kvstore}
}

func (s *VMPoolInfoStoreImpl) Create(ctx context.Context, m *VMPoolInfo, wait func(int64)) (*Result, error) {
	err := m.Validate(VMPoolInfoAllFieldsMap)
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("VMPoolInfo", m.GetKey())
	val, err := json.Marshal(m)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Create(ctx, key, string(val))
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *VMPoolInfoStoreImpl) Update(ctx context.Context, m *VMPoolInfo, wait func(int64)) (*Result, error) {
	fmap := MakeFieldMap(m.Fields)
	err := m.Validate(fmap)
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("VMPoolInfo", m.GetKey())
	var vers int64 = 0
	curBytes, vers, _, err := s.kvstore.Get(key)
	if err != nil {
		return nil, err
	}
	var cur VMPoolInfo
	err = json.Unmarshal(curBytes, &cur)
	if err != nil {
		return nil, err
	}
	cur.CopyInFields(m)
	// never save fields
	cur.Fields = nil
	val, err := json.Marshal(cur)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Update(ctx, key, string(val), vers)
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *VMPoolInfoStoreImpl) Put(ctx context.Context, m *VMPoolInfo, wait func(int64), ops ...objstore.KVOp) (*Result, error) {
	err := m.Validate(VMPoolInfoAllFieldsMap)
	m.Fields = nil
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("VMPoolInfo", m.GetKey())
	var val []byte
	val, err = json.Marshal(m)
	if err != nil {
		return nil, err
	}
	rev, err := s.kvstore.Put(ctx, key, string(val), ops...)
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *VMPoolInfoStoreImpl) Delete(ctx context.Context, m *VMPoolInfo, wait func(int64)) (*Result, error) {
	err := m.GetKey().ValidateKey()
	if err != nil {
		return nil, err
	}
	key := objstore.DbKeyString("VMPoolInfo", m.GetKey())
	rev, err := s.kvstore.Delete(ctx, key)
	if err != nil {
		return nil, err
	}
	if wait != nil {
		wait(rev)
	}
	return &Result{}, err
}

func (s *VMPoolInfoStoreImpl) LoadOne(key string) (*VMPoolInfo, int64, error) {
	val, rev, _, err := s.kvstore.Get(key)
	if err != nil {
		return nil, 0, err
	}
	var obj VMPoolInfo
	err = json.Unmarshal(val, &obj)
	if err != nil {
		log.DebugLog(log.DebugLevelApi, "Failed to parse VMPoolInfo data", "val", string(val), "err", err)
		return nil, 0, err
	}
	return &obj, rev, nil
}

func (s *VMPoolInfoStoreImpl) Get(ctx context.Context, key *VMPoolKey, buf *VMPoolInfo) bool {
	keystr := objstore.DbKeyString("VMPoolInfo", key)
	val, _, _, err := s.kvstore.Get(keystr)
	if err != nil {
		return false
	}
	return s.parseGetData(val, buf)
}

func (s *VMPoolInfoStoreImpl) STMGet(stm concurrency.STM, key *VMPoolKey, buf *VMPoolInfo) bool {
	keystr := objstore.DbKeyString("VMPoolInfo", key)
	valstr := stm.Get(keystr)
	return s.parseGetData([]byte(valstr), buf)
}

func (s *VMPoolInfoStoreImpl) STMHas(stm concurrency.STM, key *VMPoolKey) bool {
	keystr := objstore.DbKeyString("VMPoolInfo", key)
	return stm.Get(keystr) != ""
}

func (s *VMPoolInfoStoreImpl) parseGetData(val []byte, buf *VMPoolInfo) bool {
	if len(val) == 0 {
		return false
	}
	if buf != nil {
		// clear buf, because empty values in val won't
		// overwrite non-empty values in buf.
		*buf = VMPoolInfo{}
		err := json.Unmarshal(val, buf)
		if err != nil {
			return false
		}
	}
	return true
}

func (s *VMPoolInfoStoreImpl) STMPut(stm concurrency.STM, obj *VMPoolInfo, ops ...objstore.KVOp) {
	keystr := objstore.DbKeyString("VMPoolInfo", obj.GetKey())

	val, err := json.Marshal(obj)
	if err != nil {
		log.InfoLog("VMPoolInfo json marshal failed", "obj", obj, "err", err)
	}
	v3opts := GetSTMOpts(ops...)
	stm.Put(keystr, string(val), v3opts...)
}

func (s *VMPoolInfoStoreImpl) STMDel(stm concurrency.STM, key *VMPoolKey) {
	keystr := objstore.DbKeyString("VMPoolInfo", key)
	stm.Del(keystr)
}

func StoreListVMPoolInfo(ctx context.Context, kvstore objstore.KVStore) ([]VMPoolInfo, error) {
	keyPrefix := objstore.DbKeyPrefixString("VMPoolInfo") + "/"
	objs := []VMPoolInfo{}
	err := kvstore.List(keyPrefix, func(key, val []byte, rev, modRev int64) error {
		obj := VMPoolInfo{}
		err := json.Unmarshal(val, &obj)
		if err != nil {
			return fmt.Errorf("failed to unmarshal VMPoolInfo json %s, %s", string(val), err)
		}
		objs = append(objs, obj)
		return nil
	})
	return objs, err
}

type VMPoolInfoKeyWatcher struct {
	cb func(ctx context.Context)
}

type VMPoolInfoCacheData struct {
	Obj    *VMPoolInfo
	ModRev int64
}

func (s *VMPoolInfoCacheData) Clone() *VMPoolInfoCacheData {
	cp := VMPoolInfoCacheData{}
	if s.Obj != nil {
		cp.Obj = &VMPoolInfo{}
		cp.Obj.DeepCopyIn(s.Obj)
	}
	cp.ModRev = s.ModRev
	return &cp
}

// VMPoolInfoCache caches VMPoolInfo objects in memory in a hash table
// and keeps them in sync with the database.
type VMPoolInfoCache struct {
	Objs          map[VMPoolKey]*VMPoolInfoCacheData
	Mux           util.Mutex
	List          map[VMPoolKey]struct{}
	FlushAll      bool
	NotifyCbs     []func(ctx context.Context, obj *VMPoolInfo, modRev int64)
	UpdatedCbs    []func(ctx context.Context, old *VMPoolInfo, new *VMPoolInfo)
	DeletedCbs    []func(ctx context.Context, old *VMPoolInfo)
	KeyWatchers   map[VMPoolKey][]*VMPoolInfoKeyWatcher
	UpdatedKeyCbs []func(ctx context.Context, key *VMPoolKey)
	DeletedKeyCbs []func(ctx context.Context, key *VMPoolKey)
	Store         VMPoolInfoStore
}

func NewVMPoolInfoCache() *VMPoolInfoCache {
	cache := VMPoolInfoCache{}
	InitVMPoolInfoCache(&cache)
	return &cache
}

func InitVMPoolInfoCache(cache *VMPoolInfoCache) {
	cache.Objs = make(map[VMPoolKey]*VMPoolInfoCacheData)
	cache.KeyWatchers = make(map[VMPoolKey][]*VMPoolInfoKeyWatcher)
	cache.NotifyCbs = nil
	cache.UpdatedCbs = nil
	cache.DeletedCbs = nil
	cache.UpdatedKeyCbs = nil
	cache.DeletedKeyCbs = nil
}

func (c *VMPoolInfoCache) GetTypeString() string {
	return "VMPoolInfo"
}

func (c *VMPoolInfoCache) Get(key *VMPoolKey, valbuf *VMPoolInfo) bool {
	var modRev int64
	return c.GetWithRev(key, valbuf, &modRev)
}

// STMGet gets from the store if STM is set, otherwise gets from cache
func (c *VMPoolInfoCache) STMGet(ostm *OptionalSTM, key *VMPoolKey, valbuf *VMPoolInfo) bool {
	if ostm.stm != nil {
		if c.Store == nil {
			// panic, otherwise if we fallback to cache, we may silently
			// introduce race conditions and intermittent failures due to
			// reading from cache during a transaction.
			panic("VMPoolInfoCache store not set, cannot read via STM")
		}
		return c.Store.STMGet(ostm.stm, key, valbuf)
	}
	var modRev int64
	return c.GetWithRev(key, valbuf, &modRev)
}

func (c *VMPoolInfoCache) GetWithRev(key *VMPoolKey, valbuf *VMPoolInfo, modRev *int64) bool {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	inst, found := c.Objs[*key]
	if found {
		valbuf.DeepCopyIn(inst.Obj)
		*modRev = inst.ModRev
	}
	return found
}

func (c *VMPoolInfoCache) HasKey(key *VMPoolKey) bool {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	_, found := c.Objs[*key]
	return found
}

func (c *VMPoolInfoCache) GetAllKeys(ctx context.Context, cb func(key *VMPoolKey, modRev int64)) {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for key, data := range c.Objs {
		cb(&key, data.ModRev)
	}
}

func (c *VMPoolInfoCache) GetAllLocked(ctx context.Context, cb func(obj *VMPoolInfo, modRev int64)) {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for _, data := range c.Objs {
		cb(data.Obj, data.ModRev)
	}
}

func (c *VMPoolInfoCache) Update(ctx context.Context, in *VMPoolInfo, modRev int64) {
	c.UpdateModFunc(ctx, in.GetKey(), modRev, func(old *VMPoolInfo) (*VMPoolInfo, bool) {
		return in, true
	})
}

func (c *VMPoolInfoCache) UpdateModFunc(ctx context.Context, key *VMPoolKey, modRev int64, modFunc func(old *VMPoolInfo) (new *VMPoolInfo, changed bool)) {
	c.Mux.Lock()
	var old *VMPoolInfo
	if oldData, found := c.Objs[*key]; found {
		old = oldData.Obj
	}
	new, changed := modFunc(old)
	if !changed {
		c.Mux.Unlock()
		return
	}
	if len(c.UpdatedCbs) > 0 || len(c.NotifyCbs) > 0 {
		newCopy := &VMPoolInfo{}
		newCopy.DeepCopyIn(new)
		for _, cb := range c.UpdatedCbs {
			defer cb(ctx, old, newCopy)
		}
		for _, cb := range c.NotifyCbs {
			if cb != nil {
				defer cb(ctx, newCopy, modRev)
			}
		}
	}
	for _, cb := range c.UpdatedKeyCbs {
		defer cb(ctx, key)
	}
	store := &VMPoolInfo{}
	store.DeepCopyIn(new)
	c.Objs[new.GetKeyVal()] = &VMPoolInfoCacheData{
		Obj:    store,
		ModRev: modRev,
	}
	log.SpanLog(ctx, log.DebugLevelApi, "cache update", "new", store)
	c.Mux.Unlock()
	c.TriggerKeyWatchers(ctx, new.GetKey())
}

func (c *VMPoolInfoCache) Delete(ctx context.Context, in *VMPoolInfo, modRev int64) {
	c.DeleteCondFunc(ctx, in, modRev, func(old *VMPoolInfo) bool {
		return true
	})
}

func (c *VMPoolInfoCache) DeleteCondFunc(ctx context.Context, in *VMPoolInfo, modRev int64, condFunc func(old *VMPoolInfo) bool) {
	c.Mux.Lock()
	var old *VMPoolInfo
	oldData, found := c.Objs[in.GetKeyVal()]
	if found {
		old = oldData.Obj
		if !condFunc(old) {
			c.Mux.Unlock()
			return
		}
	}
	delete(c.Objs, in.GetKeyVal())
	log.SpanLog(ctx, log.DebugLevelApi, "cache delete", "key", in.GetKeyVal())
	c.Mux.Unlock()
	obj := old
	if obj == nil {
		obj = in
	}
	for _, cb := range c.NotifyCbs {
		if cb != nil {
			cb(ctx, obj, modRev)
		}
	}
	if old != nil {
		for _, cb := range c.DeletedCbs {
			cb(ctx, old)
		}
	}
	for _, cb := range c.DeletedKeyCbs {
		cb(ctx, in.GetKey())
	}
	c.TriggerKeyWatchers(ctx, in.GetKey())
}

func (c *VMPoolInfoCache) Prune(ctx context.Context, validKeys map[VMPoolKey]struct{}) {
	log.SpanLog(ctx, log.DebugLevelApi, "Prune VMPoolInfo", "numValidKeys", len(validKeys))
	notify := make(map[VMPoolKey]*VMPoolInfoCacheData)
	c.Mux.Lock()
	for key, _ := range c.Objs {
		if _, ok := validKeys[key]; !ok {
			if len(c.NotifyCbs) > 0 || len(c.DeletedKeyCbs) > 0 || len(c.DeletedCbs) > 0 {
				notify[key] = c.Objs[key]
			}
			delete(c.Objs, key)
		}
	}
	c.Mux.Unlock()
	for key, old := range notify {
		obj := old.Obj
		if obj == nil {
			obj = &VMPoolInfo{}
			obj.SetKey(&key)
		}
		for _, cb := range c.NotifyCbs {
			if cb != nil {
				cb(ctx, obj, old.ModRev)
			}
		}
		for _, cb := range c.DeletedKeyCbs {
			cb(ctx, &key)
		}
		if old.Obj != nil {
			for _, cb := range c.DeletedCbs {
				cb(ctx, old.Obj)
			}
		}
		c.TriggerKeyWatchers(ctx, &key)
	}
}

func (c *VMPoolInfoCache) GetCount() int {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	return len(c.Objs)
}

func (c *VMPoolInfoCache) Flush(ctx context.Context, notifyId int64) {
	log.SpanLog(ctx, log.DebugLevelApi, "CacheFlush VMPoolInfo", "notifyId", notifyId, "FlushAll", c.FlushAll)
	flushed := make(map[VMPoolKey]*VMPoolInfoCacheData)
	c.Mux.Lock()
	for key, val := range c.Objs {
		if !c.FlushAll && val.Obj.NotifyId != notifyId {
			continue
		}
		flushed[key] = c.Objs[key]
		log.SpanLog(ctx, log.DebugLevelApi, "CacheFlush VMPoolInfo delete", "key", key)
		delete(c.Objs, key)
	}
	c.Mux.Unlock()
	if len(flushed) > 0 {
		for key, old := range flushed {
			obj := old.Obj
			if obj == nil {
				obj = &VMPoolInfo{}
				obj.SetKey(&key)
			}
			for _, cb := range c.NotifyCbs {
				if cb != nil {
					cb(ctx, obj, old.ModRev)
				}
			}
			for _, cb := range c.DeletedKeyCbs {
				cb(ctx, &key)
			}
			if old.Obj != nil {
				for _, cb := range c.DeletedCbs {
					cb(ctx, old.Obj)
				}
			}
			c.TriggerKeyWatchers(ctx, &key)
		}
	}
}

func (c *VMPoolInfoCache) Show(filter *VMPoolInfo, cb func(ret *VMPoolInfo) error) error {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	for _, data := range c.Objs {
		if !data.Obj.Matches(filter, MatchFilter()) {
			continue
		}
		err := cb(data.Obj)
		if err != nil {
			return err
		}
	}
	return nil
}

func VMPoolInfoGenericNotifyCb(fn func(key *VMPoolKey, old *VMPoolInfo)) func(objstore.ObjKey, objstore.Obj) {
	return func(objkey objstore.ObjKey, obj objstore.Obj) {
		fn(objkey.(*VMPoolKey), obj.(*VMPoolInfo))
	}
}

func (c *VMPoolInfoCache) SetNotifyCb(fn func(ctx context.Context, obj *VMPoolInfo, modRev int64)) {
	c.NotifyCbs = []func(ctx context.Context, obj *VMPoolInfo, modRev int64){fn}
}

func (c *VMPoolInfoCache) SetUpdatedCb(fn func(ctx context.Context, old *VMPoolInfo, new *VMPoolInfo)) {
	c.UpdatedCbs = []func(ctx context.Context, old *VMPoolInfo, new *VMPoolInfo){fn}
}

func (c *VMPoolInfoCache) SetDeletedCb(fn func(ctx context.Context, old *VMPoolInfo)) {
	c.DeletedCbs = []func(ctx context.Context, old *VMPoolInfo){fn}
}

func (c *VMPoolInfoCache) SetUpdatedKeyCb(fn func(ctx context.Context, key *VMPoolKey)) {
	c.UpdatedKeyCbs = []func(ctx context.Context, key *VMPoolKey){fn}
}

func (c *VMPoolInfoCache) SetDeletedKeyCb(fn func(ctx context.Context, key *VMPoolKey)) {
	c.DeletedKeyCbs = []func(ctx context.Context, key *VMPoolKey){fn}
}

func (c *VMPoolInfoCache) AddUpdatedCb(fn func(ctx context.Context, old *VMPoolInfo, new *VMPoolInfo)) {
	c.UpdatedCbs = append(c.UpdatedCbs, fn)
}

func (c *VMPoolInfoCache) AddDeletedCb(fn func(ctx context.Context, old *VMPoolInfo)) {
	c.DeletedCbs = append(c.DeletedCbs, fn)
}

func (c *VMPoolInfoCache) AddNotifyCb(fn func(ctx context.Context, obj *VMPoolInfo, modRev int64)) {
	c.NotifyCbs = append(c.NotifyCbs, fn)
}

func (c *VMPoolInfoCache) AddUpdatedKeyCb(fn func(ctx context.Context, key *VMPoolKey)) {
	c.UpdatedKeyCbs = append(c.UpdatedKeyCbs, fn)
}

func (c *VMPoolInfoCache) AddDeletedKeyCb(fn func(ctx context.Context, key *VMPoolKey)) {
	c.DeletedKeyCbs = append(c.DeletedKeyCbs, fn)
}

func (c *VMPoolInfoCache) SetFlushAll() {
	c.FlushAll = true
}

func (c *VMPoolInfoCache) WatchKey(key *VMPoolKey, cb func(ctx context.Context)) context.CancelFunc {
	c.Mux.Lock()
	defer c.Mux.Unlock()
	list, ok := c.KeyWatchers[*key]
	if !ok {
		list = make([]*VMPoolInfoKeyWatcher, 0)
	}
	watcher := VMPoolInfoKeyWatcher{cb: cb}
	c.KeyWatchers[*key] = append(list, &watcher)
	log.DebugLog(log.DebugLevelApi, "Watching VMPoolInfo", "key", key)
	return func() {
		c.Mux.Lock()
		defer c.Mux.Unlock()
		list, ok := c.KeyWatchers[*key]
		if !ok {
			return
		}
		for ii, _ := range list {
			if list[ii] != &watcher {
				continue
			}
			if len(list) == 1 {
				delete(c.KeyWatchers, *key)
				return
			}
			list[ii] = list[len(list)-1]
			list[len(list)-1] = nil
			c.KeyWatchers[*key] = list[:len(list)-1]
			return
		}
	}
}

func (c *VMPoolInfoCache) TriggerKeyWatchers(ctx context.Context, key *VMPoolKey) {
	watchers := make([]*VMPoolInfoKeyWatcher, 0)
	c.Mux.Lock()
	if list, ok := c.KeyWatchers[*key]; ok {
		watchers = append(watchers, list...)
	}
	c.Mux.Unlock()
	for ii, _ := range watchers {
		watchers[ii].cb(ctx)
	}
}

// Note that we explicitly ignore the global revision number, because of the way
// the notify framework sends updates (by hashing keys and doing lookups, instead
// of sequentially through a history buffer), updates may be done out-of-order
// or multiple updates compressed into one update, so the state of the cache at
// any point in time may not by in sync with a particular database revision number.

func (c *VMPoolInfoCache) SyncUpdate(ctx context.Context, key, val []byte, rev, modRev int64) {
	obj := VMPoolInfo{}
	err := json.Unmarshal(val, &obj)
	if err != nil {
		log.WarnLog("Failed to parse VMPoolInfo data", "val", string(val), "err", err)
		return
	}
	c.Update(ctx, &obj, modRev)
	c.Mux.Lock()
	if c.List != nil {
		c.List[obj.GetKeyVal()] = struct{}{}
	}
	c.Mux.Unlock()
}

func (c *VMPoolInfoCache) SyncDelete(ctx context.Context, key []byte, rev, modRev int64) {
	obj := VMPoolInfo{}
	keystr := objstore.DbKeyPrefixRemove(string(key))
	VMPoolKeyStringParse(keystr, obj.GetKey())
	c.Delete(ctx, &obj, modRev)
}

func (c *VMPoolInfoCache) SyncListStart(ctx context.Context) {
	c.List = make(map[VMPoolKey]struct{})
}

func (c *VMPoolInfoCache) SyncListEnd(ctx context.Context) {
	deleted := make(map[VMPoolKey]*VMPoolInfoCacheData)
	c.Mux.Lock()
	for key, val := range c.Objs {
		if _, found := c.List[key]; !found {
			deleted[key] = val
			delete(c.Objs, key)
		}
	}
	c.List = nil
	c.Mux.Unlock()
	for key, val := range deleted {
		obj := val.Obj
		if obj == nil {
			obj = &VMPoolInfo{}
			obj.SetKey(&key)
		}
		for _, cb := range c.NotifyCbs {
			if cb != nil {
				cb(ctx, obj, val.ModRev)
			}
		}
		for _, cb := range c.DeletedKeyCbs {
			cb(ctx, &key)
		}
		if val.Obj != nil {
			for _, cb := range c.DeletedCbs {
				cb(ctx, val.Obj)
			}
		}
		c.TriggerKeyWatchers(ctx, &key)
	}
}

func (s *VMPoolInfoCache) InitCacheWithSync(sync DataSync) {
	InitVMPoolInfoCache(s)
	s.InitSync(sync)
}

func (s *VMPoolInfoCache) InitSync(sync DataSync) {
	if sync != nil {
		s.Store = NewVMPoolInfoStore(sync.GetKVStore())
		sync.RegisterCache(s)
	}
}

func InitVMPoolInfoCacheWithStore(cache *VMPoolInfoCache, store VMPoolInfoStore) {
	InitVMPoolInfoCache(cache)
	cache.Store = store
}

// VMPoolInfoObjectUpdater defines a way of updating a specific VMPoolInfo
type VMPoolInfoObjectUpdater interface {
	// Get the current VMPoolInfo
	Get() *VMPoolInfo
	// Update the VMPoolInfo for the specified Fields flags.
	Update(*VMPoolInfo) error
}

// VMPoolInfoSender allows for streaming updates to VMPoolInfo
type VMPoolInfoSender interface {
	// SendUpdate sends the updated object, fields without field flags set will be ignored
	SendUpdate(updateFn func(update *VMPoolInfo) error) error
	// SendState sends an updated state. It will clear any errors unless
	// the WithStateError option is specified.
	SendState(state TrackedState, ops ...SenderOp) error
	// SendStatus appends the status message and sends it.
	SendStatus(updateType CacheUpdateType, message string, ops ...SenderOp) error
	// SendStatusIgnoreErr is the same as SendStatus but without error return
	// and without options to be compatible with older code.
	SendStatusIgnoreErr(updateType CacheUpdateType, message string)
}

// VMPoolInfoSenderHelper implements VMPoolInfoSender
type VMPoolInfoSenderHelper struct {
	updater VMPoolInfoObjectUpdater
}

func (s *VMPoolInfoSenderHelper) SetUpdater(updater VMPoolInfoObjectUpdater) {
	s.updater = updater
}

// SendUpdate sends only the updated fields set by the Fields flags.
func (s *VMPoolInfoSenderHelper) SendUpdate(updateFn func(update *VMPoolInfo) error) error {
	obj := s.updater.Get()
	if err := updateFn(obj); err != nil {
		return err
	}
	return s.updater.Update(obj)
}

// SendState sends an updated state
func (s *VMPoolInfoSenderHelper) SendState(state TrackedState, ops ...SenderOp) error {
	opts := GetSenderOptions(ops...)
	obj := s.updater.Get()
	obj.Fields = []string{
		VMPoolInfoFieldState,
		VMPoolInfoFieldErrors,
		VMPoolInfoFieldStatus,
	}
	s.applyOpts(obj, opts)

	if opts.stateErr != nil {
		obj.Errors = []string{opts.stateErr.Error()}
	}
	obj.State = state
	obj.Status.SetTask(TrackedState_CamelName[int32(state)])
	return s.updater.Update(obj)
}

// SendStatus appends the status message and sends it.
func (s *VMPoolInfoSenderHelper) SendStatus(updateType CacheUpdateType, message string, ops ...SenderOp) error {
	opts := GetSenderOptions(ops...)
	obj := s.updater.Get()
	obj.Fields = []string{
		VMPoolInfoFieldStatus,
	}
	s.applyOpts(obj, opts)

	switch updateType {
	case UpdateTask:
		obj.Status.SetTask(message)
	case UpdateStep:
		obj.Status.SetStep(message)
	}
	return s.updater.Update(obj)
}

func (s *VMPoolInfoSenderHelper) SendStatusIgnoreErr(updateType CacheUpdateType, message string) {
	s.SendStatus(updateType, message)
}

func (s *VMPoolInfoSenderHelper) applyOpts(obj *VMPoolInfo, opts *SenderOptions) {
	if opts.resetStatus {
		obj.Fields = append(obj.Fields, VMPoolInfoFieldStatus)
		obj.Status.StatusReset()
	}
}

// VMPoolInfoCacheUpdater implements VMPoolInfoSender via a cache
// that can send data over notify.
type VMPoolInfoCacheUpdater struct {
	VMPoolInfoSenderHelper
	ctx   context.Context
	key   VMPoolKey
	cache *VMPoolInfoCache
}

func NewVMPoolInfoCacheUpdater(ctx context.Context, cache *VMPoolInfoCache, key VMPoolKey) *VMPoolInfoCacheUpdater {
	s := &VMPoolInfoCacheUpdater{
		ctx:   ctx,
		key:   key,
		cache: cache,
	}
	s.SetUpdater(s)
	return s
}

func (s *VMPoolInfoCacheUpdater) Get() *VMPoolInfo {
	obj := VMPoolInfo{}
	if !s.cache.Get(&s.key, &obj) {
		obj.Key = s.key
	}
	return &obj
}

func (s *VMPoolInfoCacheUpdater) Update(obj *VMPoolInfo) error {
	s.cache.Update(s.ctx, obj, 0)
	return nil
}

type VMPoolInfoSendAPI interface {
	Send(*VMPoolInfo) error
}

// VMPoolInfoSendUpdater implements VMPoolInfoObjectUpdater via a generic
// send API. To allow for building up the list of status messages
// which need to accumulate over time, we keep a local copy of
// the object.
type VMPoolInfoSendUpdater struct {
	VMPoolInfoSenderHelper
	ctx    context.Context
	sender VMPoolInfoSendAPI
	local  VMPoolInfo
	mux    sync.Mutex
}

func NewVMPoolInfoSendUpdater(ctx context.Context, sender VMPoolInfoSendAPI, key VMPoolKey) *VMPoolInfoSendUpdater {
	s := &VMPoolInfoSendUpdater{
		ctx:    ctx,
		sender: sender,
	}
	s.local.Key = key
	s.SetUpdater(s)
	return s
}

func (s *VMPoolInfoSendUpdater) Get() *VMPoolInfo {
	s.mux.Lock()
	defer s.mux.Unlock()
	cp := VMPoolInfo{}
	cp.DeepCopyIn(&s.local)
	return &cp
}

func (s *VMPoolInfoSendUpdater) Update(obj *VMPoolInfo) error {
	s.mux.Lock()
	s.local.DeepCopyIn(obj)
	s.mux.Unlock()
	return s.sender.Send(obj)
}

// VMPoolInfoPrintUpdater just prints the updates
type VMPoolInfoPrintUpdater struct {
	VMPoolInfoSenderHelper
}

func NewVMPoolInfoPrintUpdater() *VMPoolInfoPrintUpdater {
	s := &VMPoolInfoPrintUpdater{}
	s.SetUpdater(s)
	return s
}

func (s *VMPoolInfoPrintUpdater) Get() *VMPoolInfo {
	return &VMPoolInfo{}
}

func (s *VMPoolInfoPrintUpdater) Update(obj *VMPoolInfo) error {
	fmt.Printf("%v\n", obj)
	return nil
}

func WaitForVMPoolInfo(ctx context.Context, key *VMPoolKey, store VMPoolStore, targetState TrackedState, transitionStates map[TrackedState]struct{}, errorState TrackedState, successMsg string, send func(*Result) error, crmMsgCh <-chan *redis.Message) error {
	var lastMsgCnt int
	var err error

	handleTargetState := func() {
		if targetState == TrackedState_NOT_PRESENT {
			send(&Result{Message: TrackedState_CamelName[int32(targetState)]})
		}
		if successMsg != "" && send != nil {
			send(&Result{Message: successMsg})
		}
	}

	// State updates come via Redis, since they are bundled with status updates.
	// However, the Redis channel is set up after the Etcd transaction to commit
	// the state change (i.e. CREATE_REQUESTED) in order to treat Etcd as the
	// source of truth for concurrent changes, so there is a small timing window
	// where the state may be updated by the info (from CRM) before the Redis
	// subscription is set up. So here our initial state needs to come from Etcd
	// in case both it and Redis were updated before the crmMsgCh was set up.
	curState := TrackedState_NOT_PRESENT
	buf := VMPool{}
	if store.Get(ctx, key, &buf) {
		curState = buf.State
	}
	if curState == targetState {
		handleTargetState()
		return nil
	}

	if crmMsgCh == nil {
		log.SpanLog(ctx, log.DebugLevelApi, "wait for VMPoolInfo func missing crmMsgCh", "key", key)
		return fmt.Errorf("wait for VMPoolInfo missing redis message channel")
	}

	for {
		select {
		case chObj := <-crmMsgCh:
			if chObj == nil {
				// Since msg chan is a receive-only chan, it will return nil if
				// connection to redis server is disrupted. But the object might
				// still be in progress. Hence, just show a message about the failure,
				// so that user can manually look at object's progress
				if send != nil {
					msg := fmt.Sprintf("Failed to get progress messages. Please use ShowVMPool to check current status")
					send(&Result{Message: msg})
				}
				return nil
			}
			info := VMPoolInfo{}
			err = json.Unmarshal([]byte(chObj.Payload), &info)
			if err != nil {
				return err
			}
			curState = info.State
			log.SpanLog(ctx, log.DebugLevelApi, "Received crm update for VMPoolInfo", "key", key, "obj", info)
			if send != nil {
				for ii := lastMsgCnt; ii < len(info.Status.Msgs); ii++ {
					send(&Result{Message: info.Status.Msgs[ii]})
				}
				lastMsgCnt = len(info.Status.Msgs)
			}

			switch info.State {
			case errorState:
				errs := strings.Join(info.Errors, ", ")
				if len(info.Errors) == 1 {
					err = fmt.Errorf("%s", errs)
				} else {
					err = fmt.Errorf("Encountered failures: %s", errs)
				}
				return err
			case targetState:
				handleTargetState()
				return nil
			}
		case <-ctx.Done():
			if _, found := transitionStates[curState]; found {
				// no success response, but state is a valid transition
				// state. That means work is still in progress.
				// Notify user that this is not an error.
				// Do not undo since CRM is still busy.
				if send != nil {
					msg := fmt.Sprintf("Timed out while work still in progress state %s. Please use ShowVMPool to check current status", TrackedState_CamelName[int32(curState)])
					send(&Result{Message: msg})
				}
				err = nil
			} else {
				err = fmt.Errorf("Timed out; expected state %s but is %s",
					TrackedState_CamelName[int32(targetState)],
					TrackedState_CamelName[int32(curState)])
			}
			return err
		}
	}
}

func (c *VMPoolInfoCache) UsesOrg(org string) bool {
	return false
}

func (m *VMPoolInfo) GetObjKey() objstore.ObjKey {
	return m.GetKey()
}

func (m *VMPoolInfo) GetKey() *VMPoolKey {
	return &m.Key
}

func (m *VMPoolInfo) GetKeyVal() VMPoolKey {
	return m.Key
}

func (m *VMPoolInfo) SetKey(key *VMPoolKey) {
	m.Key = *key
}

func CmpSortVMPoolInfo(a VMPoolInfo, b VMPoolInfo) bool {
	return a.Key.GetKeyString() < b.Key.GetKeyString()
}

// Helper method to check that enums have valid values
// NOTE: ValidateEnums checks all Fields even if some are not set
func (m *VMPoolInfo) ValidateEnums() error {
	if err := m.Key.ValidateEnums(); err != nil {
		return err
	}
	for _, e := range m.Vms {
		if err := e.ValidateEnums(); err != nil {
			return err
		}
	}
	if _, ok := TrackedState_name[int32(m.State)]; !ok {
		return errors.New("invalid State")
	}
	if err := m.Status.ValidateEnums(); err != nil {
		return err
	}
	return nil
}

func (s *VMPoolInfo) ClearTagged(tags map[string]struct{}) {
	s.Key.ClearTagged(tags)
	if _, found := tags["nocmp"]; found {
		s.NotifyId = 0
	}
	if s.Vms != nil {
		for ii := 0; ii < len(s.Vms); ii++ {
			s.Vms[ii].ClearTagged(tags)
		}
	}
	if _, found := tags["nocmp"]; found {
		s.Errors = nil
	}
	s.Status.ClearTagged(tags)
}

func IgnoreVMPoolInfoFields(taglist string) cmp.Option {
	names := []string{}
	tags := make(map[string]struct{})
	for _, tag := range strings.Split(taglist, ",") {
		tags[tag] = struct{}{}
	}
	if _, found := tags["nocmp"]; found {
		names = append(names, "NotifyId")
	}
	if _, found := tags["timestamp"]; found {
		names = append(names, "Vms.UpdatedAt")
	}
	if _, found := tags["nocmp"]; found {
		names = append(names, "Errors")
	}
	return cmpopts.IgnoreFields(VMPoolInfo{}, names...)
}

var VMStateStrings = []string{
	"VM_FREE",
	"VM_IN_PROGRESS",
	"VM_IN_USE",
	"VM_ADD",
	"VM_REMOVE",
	"VM_UPDATE",
	"VM_FORCE_FREE",
}

const (
	VMStateVM_FREE        uint64 = 1 << 0
	VMStateVM_IN_PROGRESS uint64 = 1 << 1
	VMStateVM_IN_USE      uint64 = 1 << 2
	VMStateVM_ADD         uint64 = 1 << 3
	VMStateVM_REMOVE      uint64 = 1 << 4
	VMStateVM_UPDATE      uint64 = 1 << 5
	VMStateVM_FORCE_FREE  uint64 = 1 << 6
)

var VMState_CamelName = map[int32]string{
	// VM_FREE -> VmFree
	0: "VmFree",
	// VM_IN_PROGRESS -> VmInProgress
	1: "VmInProgress",
	// VM_IN_USE -> VmInUse
	2: "VmInUse",
	// VM_ADD -> VmAdd
	3: "VmAdd",
	// VM_REMOVE -> VmRemove
	4: "VmRemove",
	// VM_UPDATE -> VmUpdate
	5: "VmUpdate",
	// VM_FORCE_FREE -> VmForceFree
	6: "VmForceFree",
}
var VMState_CamelValue = map[string]int32{
	"VmFree":       0,
	"VmInProgress": 1,
	"VmInUse":      2,
	"VmAdd":        3,
	"VmRemove":     4,
	"VmUpdate":     5,
	"VmForceFree":  6,
}

func ParseVMState(data interface{}) (VMState, error) {
	if val, ok := data.(VMState); ok {
		return val, nil
	} else if str, ok := data.(string); ok {
		val, ok := VMState_CamelValue[util.CamelCase(str)]
		if !ok {
			// may have omitted common prefix
			val, ok = VMState_CamelValue["Vm"+util.CamelCase(str)]
		}
		if !ok {
			// may be int value instead of enum name
			ival, err := strconv.Atoi(str)
			val = int32(ival)
			if err == nil {
				_, ok = VMState_CamelName[val]
			}
		}
		if !ok {
			return VMState(0), fmt.Errorf("Invalid VMState value %q", str)
		}
		return VMState(val), nil
	} else if ival, ok := data.(int32); ok {
		if _, ok := VMState_CamelName[ival]; ok {
			return VMState(ival), nil
		} else {
			return VMState(0), fmt.Errorf("Invalid VMState value %d", ival)
		}
	}
	return VMState(0), fmt.Errorf("Invalid VMState value %v", data)
}

func (e *VMState) UnmarshalYAML(unmarshal func(interface{}) error) error {
	var str string
	err := unmarshal(&str)
	if err != nil {
		return err
	}
	val, err := ParseVMState(str)
	if err != nil {
		return err
	}
	*e = val
	return nil
}

func (e VMState) MarshalYAML() (interface{}, error) {
	str := proto.EnumName(VMState_CamelName, int32(e))
	str = strings.TrimPrefix(str, "Vm")
	return str, nil
}

// custom JSON encoding/decoding
func (e *VMState) UnmarshalJSON(b []byte) error {
	var str string
	err := json.Unmarshal(b, &str)
	if err == nil {
		val, err := ParseVMState(str)
		if err != nil {
			return &json.UnmarshalTypeError{
				Value: "string " + str,
				Type:  reflect.TypeOf(VMState(0)),
			}
		}
		*e = VMState(val)
		return nil
	}
	var ival int32
	err = json.Unmarshal(b, &ival)
	if err == nil {
		val, err := ParseVMState(ival)
		if err == nil {
			*e = val
			return nil
		}
	}
	return &json.UnmarshalTypeError{
		Value: "value " + string(b),
		Type:  reflect.TypeOf(VMState(0)),
	}
}

func (e VMState) MarshalJSON() ([]byte, error) {
	str := proto.EnumName(VMState_CamelName, int32(e))
	str = strings.TrimPrefix(str, "Vm")
	return json.Marshal(str)
}

var VMStateCommonPrefix = "Vm"

var VMActionStrings = []string{
	"VM_ACTION_DONE",
	"VM_ACTION_ALLOCATE",
	"VM_ACTION_RELEASE",
}

const (
	VMActionVM_ACTION_DONE     uint64 = 1 << 0
	VMActionVM_ACTION_ALLOCATE uint64 = 1 << 1
	VMActionVM_ACTION_RELEASE  uint64 = 1 << 2
)

var VMAction_CamelName = map[int32]string{
	// VM_ACTION_DONE -> VmActionDone
	0: "VmActionDone",
	// VM_ACTION_ALLOCATE -> VmActionAllocate
	1: "VmActionAllocate",
	// VM_ACTION_RELEASE -> VmActionRelease
	2: "VmActionRelease",
}
var VMAction_CamelValue = map[string]int32{
	"VmActionDone":     0,
	"VmActionAllocate": 1,
	"VmActionRelease":  2,
}

func ParseVMAction(data interface{}) (VMAction, error) {
	if val, ok := data.(VMAction); ok {
		return val, nil
	} else if str, ok := data.(string); ok {
		val, ok := VMAction_CamelValue[util.CamelCase(str)]
		if !ok {
			// may have omitted common prefix
			val, ok = VMAction_CamelValue["VmAction"+util.CamelCase(str)]
		}
		if !ok {
			// may be int value instead of enum name
			ival, err := strconv.Atoi(str)
			val = int32(ival)
			if err == nil {
				_, ok = VMAction_CamelName[val]
			}
		}
		if !ok {
			return VMAction(0), fmt.Errorf("Invalid VMAction value %q", str)
		}
		return VMAction(val), nil
	} else if ival, ok := data.(int32); ok {
		if _, ok := VMAction_CamelName[ival]; ok {
			return VMAction(ival), nil
		} else {
			return VMAction(0), fmt.Errorf("Invalid VMAction value %d", ival)
		}
	}
	return VMAction(0), fmt.Errorf("Invalid VMAction value %v", data)
}

func (e *VMAction) UnmarshalYAML(unmarshal func(interface{}) error) error {
	var str string
	err := unmarshal(&str)
	if err != nil {
		return err
	}
	val, err := ParseVMAction(str)
	if err != nil {
		return err
	}
	*e = val
	return nil
}

func (e VMAction) MarshalYAML() (interface{}, error) {
	str := proto.EnumName(VMAction_CamelName, int32(e))
	str = strings.TrimPrefix(str, "VmAction")
	return str, nil
}

// custom JSON encoding/decoding
func (e *VMAction) UnmarshalJSON(b []byte) error {
	var str string
	err := json.Unmarshal(b, &str)
	if err == nil {
		val, err := ParseVMAction(str)
		if err != nil {
			return &json.UnmarshalTypeError{
				Value: "string " + str,
				Type:  reflect.TypeOf(VMAction(0)),
			}
		}
		*e = VMAction(val)
		return nil
	}
	var ival int32
	err = json.Unmarshal(b, &ival)
	if err == nil {
		val, err := ParseVMAction(ival)
		if err == nil {
			*e = val
			return nil
		}
	}
	return &json.UnmarshalTypeError{
		Value: "value " + string(b),
		Type:  reflect.TypeOf(VMAction(0)),
	}
}

func (e VMAction) MarshalJSON() ([]byte, error) {
	str := proto.EnumName(VMAction_CamelName, int32(e))
	str = strings.TrimPrefix(str, "VmAction")
	return json.Marshal(str)
}

var VMActionCommonPrefix = "VmAction"

func (m *VMPool) IsValidArgsForCreateVMPool() error {
	if m.Vms != nil {
	}
	if m.State != 0 {
		return fmt.Errorf("Invalid field specified: State, this field is only for internal use")
	}
	if m.Errors != nil {
		return fmt.Errorf("Invalid field specified: Errors, this field is only for internal use")
	}
	return nil
}

func (m *VMPool) IsValidArgsForDeleteVMPool() error {
	if m.Vms != nil {
	}
	if m.State != 0 {
		return fmt.Errorf("Invalid field specified: State, this field is only for internal use")
	}
	if m.Errors != nil {
		return fmt.Errorf("Invalid field specified: Errors, this field is only for internal use")
	}
	return nil
}

func (m *VMPool) IsValidArgsForUpdateVMPool() error {
	if m.Vms != nil {
	}
	if m.State != 0 {
		return fmt.Errorf("Invalid field specified: State, this field is only for internal use")
	}
	if m.Errors != nil {
		return fmt.Errorf("Invalid field specified: Errors, this field is only for internal use")
	}
	return nil
}

func (m *VMPoolMember) IsValidArgsForAddVMPoolMember() error {
	return nil
}

func (m *VMPoolMember) IsValidArgsForRemoveVMPoolMember() error {
	if m.Vm.NetInfo.ExternalIp != "" {
		return fmt.Errorf("Invalid field specified: Vm.NetInfo.ExternalIp, this field is only for internal use")
	}
	if m.Vm.NetInfo.InternalIp != "" {
		return fmt.Errorf("Invalid field specified: Vm.NetInfo.InternalIp, this field is only for internal use")
	}
	if m.Vm.Flavor != nil {
		return fmt.Errorf("Invalid field specified: Vm.Flavor, this field is only for internal use")
	}
	return nil
}

func (m *VMNetInfo) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.ExternalIp)
	if l > 0 {
		n += 1 + l + sovVmpool(uint64(l))
	}
	l = len(m.InternalIp)
	if l > 0 {
		n += 1 + l + sovVmpool(uint64(l))
	}
	return n
}

func (m *VM) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.Name)
	if l > 0 {
		n += 1 + l + sovVmpool(uint64(l))
	}
	l = m.NetInfo.Size()
	n += 1 + l + sovVmpool(uint64(l))
	l = len(m.GroupName)
	if l > 0 {
		n += 1 + l + sovVmpool(uint64(l))
	}
	if m.State != 0 {
		n += 1 + sovVmpool(uint64(m.State))
	}
	l = m.UpdatedAt.Size()
	n += 1 + l + sovVmpool(uint64(l))
	l = len(m.InternalName)
	if l > 0 {
		n += 1 + l + sovVmpool(uint64(l))
	}
	if m.Flavor != nil {
		l = m.Flavor.Size()
		n += 1 + l + sovVmpool(uint64(l))
	}
	return n
}

func (m *VMPoolKey) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.Organization)
	if l > 0 {
		n += 1 + l + sovVmpool(uint64(l))
	}
	l = len(m.Name)
	if l > 0 {
		n += 1 + l + sovVmpool(uint64(l))
	}
	return n
}

func (m *VMPool) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.Fields) > 0 {
		for _, s := range m.Fields {
			l = len(s)
			n += 1 + l + sovVmpool(uint64(l))
		}
	}
	l = m.Key.Size()
	n += 1 + l + sovVmpool(uint64(l))
	if len(m.Vms) > 0 {
		for _, e := range m.Vms {
			l = e.Size()
			n += 1 + l + sovVmpool(uint64(l))
		}
	}
	if m.State != 0 {
		n += 1 + sovVmpool(uint64(m.State))
	}
	if len(m.Errors) > 0 {
		for _, s := range m.Errors {
			l = len(s)
			n += 1 + l + sovVmpool(uint64(l))
		}
	}
	if m.CrmOverride != 0 {
		n += 1 + sovVmpool(uint64(m.CrmOverride))
	}
	if m.DeletePrepare {
		n += 2
	}
	return n
}

func (m *VMPoolMember) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = m.Key.Size()
	n += 1 + l + sovVmpool(uint64(l))
	l = m.Vm.Size()
	n += 1 + l + sovVmpool(uint64(l))
	if m.CrmOverride != 0 {
		n += 1 + sovVmpool(uint64(m.CrmOverride))
	}
	return n
}

func (m *VMSpec) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.InternalName)
	if l > 0 {
		n += 1 + l + sovVmpool(uint64(l))
	}
	if m.ExternalNetwork {
		n += 2
	}
	if m.InternalNetwork {
		n += 2
	}
	l = m.Flavor.Size()
	n += 1 + l + sovVmpool(uint64(l))
	return n
}

func (m *VMPoolInfo) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.Fields) > 0 {
		for _, s := range m.Fields {
			l = len(s)
			n += 1 + l + sovVmpool(uint64(l))
		}
	}
	l = m.Key.Size()
	n += 1 + l + sovVmpool(uint64(l))
	if m.NotifyId != 0 {
		n += 1 + sovVmpool(uint64(m.NotifyId))
	}
	if len(m.Vms) > 0 {
		for _, e := range m.Vms {
			l = e.Size()
			n += 1 + l + sovVmpool(uint64(l))
		}
	}
	if m.State != 0 {
		n += 1 + sovVmpool(uint64(m.State))
	}
	if len(m.Errors) > 0 {
		for _, s := range m.Errors {
			l = len(s)
			n += 1 + l + sovVmpool(uint64(l))
		}
	}
	l = m.Status.Size()
	n += 1 + l + sovVmpool(uint64(l))
	return n
}

func sovVmpool(x uint64) (n int) {
	return (math_bits.Len64(x|1) + 6) / 7
}
func sozVmpool(x uint64) (n int) {
	return sovVmpool(uint64((x << 1) ^ uint64((int64(x) >> 63))))
}
func (m *VMNetInfo) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowVmpool
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: VMNetInfo: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: VMNetInfo: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ExternalIp", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ExternalIp = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field InternalIp", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.InternalIp = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipVmpool(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthVmpool
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *VM) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowVmpool
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: VM: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: VM: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Name", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Name = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field NetInfo", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.NetInfo.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field GroupName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.GroupName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field State", wireType)
			}
			m.State = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.State |= VMState(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field UpdatedAt", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.UpdatedAt.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 6:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field InternalName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.InternalName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 7:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Flavor", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Flavor == nil {
				m.Flavor = &FlavorInfo{}
			}
			if err := m.Flavor.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipVmpool(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthVmpool
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *VMPoolKey) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowVmpool
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: VMPoolKey: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: VMPoolKey: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Organization", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Organization = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Name", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Name = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipVmpool(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthVmpool
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *VMPool) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowVmpool
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: VMPool: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: VMPool: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Fields", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Fields = append(m.Fields, string(dAtA[iNdEx:postIndex]))
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Key", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Key.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Vms", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Vms = append(m.Vms, VM{})
			if err := m.Vms[len(m.Vms)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field State", wireType)
			}
			m.State = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.State |= TrackedState(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Errors", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Errors = append(m.Errors, string(dAtA[iNdEx:postIndex]))
			iNdEx = postIndex
		case 7:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field CrmOverride", wireType)
			}
			m.CrmOverride = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.CrmOverride |= CRMOverride(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 8:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field DeletePrepare", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.DeletePrepare = bool(v != 0)
		default:
			iNdEx = preIndex
			skippy, err := skipVmpool(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthVmpool
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *VMPoolMember) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowVmpool
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: VMPoolMember: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: VMPoolMember: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Key", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Key.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Vm", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Vm.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field CrmOverride", wireType)
			}
			m.CrmOverride = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.CrmOverride |= CRMOverride(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipVmpool(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthVmpool
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *VMSpec) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowVmpool
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: VMSpec: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: VMSpec: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field InternalName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.InternalName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ExternalNetwork", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.ExternalNetwork = bool(v != 0)
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field InternalNetwork", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.InternalNetwork = bool(v != 0)
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Flavor", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Flavor.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipVmpool(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthVmpool
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *VMPoolInfo) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowVmpool
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: VMPoolInfo: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: VMPoolInfo: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Fields", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Fields = append(m.Fields, string(dAtA[iNdEx:postIndex]))
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Key", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Key.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field NotifyId", wireType)
			}
			m.NotifyId = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.NotifyId |= int64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Vms", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Vms = append(m.Vms, VM{})
			if err := m.Vms[len(m.Vms)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field State", wireType)
			}
			m.State = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.State |= TrackedState(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 6:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Errors", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Errors = append(m.Errors, string(dAtA[iNdEx:postIndex]))
			iNdEx = postIndex
		case 7:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Status", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthVmpool
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthVmpool
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if err := m.Status.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipVmpool(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthVmpool
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func skipVmpool(dAtA []byte) (n int, err error) {
	l := len(dAtA)
	iNdEx := 0
	depth := 0
	for iNdEx < l {
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return 0, ErrIntOverflowVmpool
			}
			if iNdEx >= l {
				return 0, io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		wireType := int(wire & 0x7)
		switch wireType {
		case 0:
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				iNdEx++
				if dAtA[iNdEx-1] < 0x80 {
					break
				}
			}
		case 1:
			iNdEx += 8
		case 2:
			var length int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowVmpool
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				length |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if length < 0 {
				return 0, ErrInvalidLengthVmpool
			}
			iNdEx += length
		case 3:
			depth++
		case 4:
			if depth == 0 {
				return 0, ErrUnexpectedEndOfGroupVmpool
			}
			depth--
		case 5:
			iNdEx += 4
		default:
			return 0, fmt.Errorf("proto: illegal wireType %d", wireType)
		}
		if iNdEx < 0 {
			return 0, ErrInvalidLengthVmpool
		}
		if depth == 0 {
			return iNdEx, nil
		}
	}
	return 0, io.ErrUnexpectedEOF
}

var (
	ErrInvalidLengthVmpool        = fmt.Errorf("proto: negative length found during unmarshaling")
	ErrIntOverflowVmpool          = fmt.Errorf("proto: integer overflow")
	ErrUnexpectedEndOfGroupVmpool = fmt.Errorf("proto: unexpected end of group")
)
